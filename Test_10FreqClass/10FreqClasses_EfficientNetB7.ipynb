{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10FreqClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path='D:/DatasetMedicalWaste_10FreqClasses/DatasetMedicalWasteCropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset_path='D:/DatasetMedicalWasteCroppedBalanced/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_10FreqClasses/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_10FreqClasses/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_10FreqClasses/DatasetMedicalWasteTestLabeledCropped/belt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=600\n",
    "img_width=600\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1279 files belonging to 10 classes.\n",
      "Using 1024 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2WayFoleyCatheter', 'CottonBall', 'ExtensionTube', 'Glove', 'Mask', 'NGTube', 'Needle', 'OxygenMask', 'Syringe', 'UrineBag']\n",
      "number of class = 10\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_number = len(class_names)\n",
    "print(class_names)\n",
    "print(f'number of class = {class_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1279 files belonging to 10 classes.\n",
      "Using 255 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 507 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1020 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 569 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"vertical\"),\n",
    "  layers.RandomRotation(0.100),\n",
    "  layers.RandomZoom(height_factor=0.025,width_factor=0.025),\n",
    "  #layers.RandomContrast(0.300),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  # ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 600, 600, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# Test -> Fetching Mini Batch\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:-1]: # this is where I changed your code\n",
    "    model.add(layer)    \n",
    "\n",
    "# Freeze the layers \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add 'softmax' instead of earlier 'prediction' layer.\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input,EfficientNetB7\n",
    "\n",
    "efficientnetB0_model = keras.applications.EfficientNetB7(input_shape=(img_height,img_width,3),include_top=True,weights=\"imagenet\",classifier_activation=\"softmax\")\n",
    "\n",
    "efficientnetB0_model_nooutput = efficientnetB0_model.layers[-3].output\n",
    "custom_efficientnetB0_model = Model(inputs = efficientnetB0_model.input, outputs = efficientnetB0_model_nooutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freez Extractor+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 600, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 600, 600, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 600, 600, 3)  7           rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 601, 601, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 300, 300, 64) 1728        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 300, 300, 64) 256         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 300, 300, 64) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 300, 300, 64) 576         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 300, 300, 64) 256         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 300, 300, 64) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 64)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 64)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 16)     1040        block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 64)     1088        block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 300, 300, 64) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 300, 300, 32) 2048        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 300, 300, 32) 128         block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 300, 300, 32) 128         block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 300, 300, 32) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 300, 300, 32) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 300, 300, 32) 128         block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 300, 300, 32) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 300, 300, 32) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 300, 300, 32) 128         block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 300, 300, 32) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 32)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 300, 300, 32) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 300, 300, 32) 128         block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (Dropout)          (None, 300, 300, 32) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 300, 300, 32) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_bn (BatchNormalization) (None, 300, 300, 32) 128         block1d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1d_activation (Activation) (None, 300, 300, 32) 0           block1d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_squeeze (GlobalAvera (None, 32)           0           block1d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_excite (Multiply)    (None, 300, 300, 32) 0           block1d_activation[0][0]         \n",
      "                                                                 block1d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_bn (BatchNormal (None, 300, 300, 32) 128         block1d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1d_drop (Dropout)          (None, 300, 300, 32) 0           block1d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_add (Add)               (None, 300, 300, 32) 0           block1d_drop[0][0]               \n",
      "                                                                 block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 300, 300, 192 6144        block1d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 300, 300, 192 768         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 300, 300, 192 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 301, 301, 192 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 150, 150, 192 1728        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 150, 150, 192 768         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 150, 150, 192 0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 192)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 150, 150, 192 0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 150, 150, 48) 9216        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 150, 150, 48) 192         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 150, 150, 288 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 150, 150, 288 1152        block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 150, 150, 288 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 288)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 150, 150, 288 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 150, 150, 48) 192         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 150, 150, 48) 0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 150, 150, 48) 0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 150, 150, 288 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 150, 150, 288 1152        block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 150, 150, 288 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 288)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 150, 150, 288 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 150, 150, 48) 192         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 150, 150, 48) 0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 150, 150, 48) 0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 150, 150, 288 0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 150, 150, 288 1152        block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 150, 150, 288 0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 288)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 150, 150, 288 0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 150, 150, 48) 192         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (Dropout)          (None, 150, 150, 48) 0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 150, 150, 48) 0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 150, 150, 288 0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 150, 150, 288 1152        block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 150, 150, 288 0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 288)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 150, 150, 288 0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 150, 150, 48) 192         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (Dropout)          (None, 150, 150, 48) 0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 150, 150, 48) 0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_activation (Acti (None, 150, 150, 288 0           block2f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2f_bn (BatchNormalization) (None, 150, 150, 288 1152        block2f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2f_activation (Activation) (None, 150, 150, 288 0           block2f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_squeeze (GlobalAvera (None, 288)          0           block2f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_excite (Multiply)    (None, 150, 150, 288 0           block2f_activation[0][0]         \n",
      "                                                                 block2f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_bn (BatchNormal (None, 150, 150, 48) 192         block2f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2f_drop (Dropout)          (None, 150, 150, 48) 0           block2f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_add (Add)               (None, 150, 150, 48) 0           block2f_drop[0][0]               \n",
      "                                                                 block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_activation (Acti (None, 150, 150, 288 0           block2g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2g_bn (BatchNormalization) (None, 150, 150, 288 1152        block2g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2g_activation (Activation) (None, 150, 150, 288 0           block2g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_squeeze (GlobalAvera (None, 288)          0           block2g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_excite (Multiply)    (None, 150, 150, 288 0           block2g_activation[0][0]         \n",
      "                                                                 block2g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_bn (BatchNormal (None, 150, 150, 48) 192         block2g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2g_drop (Dropout)          (None, 150, 150, 48) 0           block2g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_add (Add)               (None, 150, 150, 48) 0           block2g_drop[0][0]               \n",
      "                                                                 block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 150, 150, 288 1152        block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 150, 150, 288 0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 153, 153, 288 0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 75, 75, 288)  7200        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 75, 75, 288)  1152        block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 75, 75, 288)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 288)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 75, 75, 288)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 75, 75, 80)   23040       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 75, 75, 80)   320         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 75, 75, 480)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 75, 75, 480)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 480)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 75, 75, 480)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 75, 75, 80)   320         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 75, 75, 80)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 75, 75, 80)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 75, 75, 480)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 75, 75, 480)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 480)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 75, 75, 480)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 75, 75, 80)   320         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 75, 75, 80)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 75, 75, 80)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 75, 75, 480)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 75, 75, 480)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 480)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 75, 75, 480)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 75, 75, 80)   320         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (Dropout)          (None, 75, 75, 80)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 75, 75, 80)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 75, 75, 480)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 75, 75, 480)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 480)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 75, 75, 480)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 75, 75, 80)   320         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (Dropout)          (None, 75, 75, 80)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 75, 75, 80)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_activation (Acti (None, 75, 75, 480)  0           block3f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3f_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3f_activation (Activation) (None, 75, 75, 480)  0           block3f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_squeeze (GlobalAvera (None, 480)          0           block3f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_excite (Multiply)    (None, 75, 75, 480)  0           block3f_activation[0][0]         \n",
      "                                                                 block3f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_bn (BatchNormal (None, 75, 75, 80)   320         block3f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3f_drop (Dropout)          (None, 75, 75, 80)   0           block3f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_add (Add)               (None, 75, 75, 80)   0           block3f_drop[0][0]               \n",
      "                                                                 block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_activation (Acti (None, 75, 75, 480)  0           block3g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3g_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3g_activation (Activation) (None, 75, 75, 480)  0           block3g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_squeeze (GlobalAvera (None, 480)          0           block3g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_excite (Multiply)    (None, 75, 75, 480)  0           block3g_activation[0][0]         \n",
      "                                                                 block3g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_bn (BatchNormal (None, 75, 75, 80)   320         block3g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3g_drop (Dropout)          (None, 75, 75, 80)   0           block3g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_add (Add)               (None, 75, 75, 80)   0           block3g_drop[0][0]               \n",
      "                                                                 block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 75, 75, 480)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 77, 77, 480)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 38, 38, 480)  4320        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 38, 38, 480)  1920        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 38, 38, 480)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 480)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 38, 38, 480)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 38, 38, 160)  76800       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 38, 38, 160)  640         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 38, 38, 960)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 38, 38, 960)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 960)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 38, 38, 960)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 38, 38, 160)  640         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 38, 38, 160)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 38, 38, 160)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 38, 38, 960)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 38, 38, 960)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 960)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 38, 38, 960)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 38, 38, 160)  640         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 38, 38, 160)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 38, 38, 160)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 38, 38, 960)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 38, 38, 960)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 960)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 38, 38, 960)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 38, 38, 160)  640         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 38, 38, 160)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 38, 38, 160)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 38, 38, 960)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 38, 38, 960)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 960)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 38, 38, 960)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 38, 38, 160)  640         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 38, 38, 160)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 38, 38, 160)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 38, 38, 960)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 38, 38, 960)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 960)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 38, 38, 960)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 38, 38, 160)  640         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (Dropout)          (None, 38, 38, 160)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 38, 38, 160)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 38, 38, 960)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 38, 38, 960)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 960)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 38, 38, 960)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 38, 38, 160)  640         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (Dropout)          (None, 38, 38, 160)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 38, 38, 160)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_activation (Acti (None, 38, 38, 960)  0           block4h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4h_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4h_activation (Activation) (None, 38, 38, 960)  0           block4h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_squeeze (GlobalAvera (None, 960)          0           block4h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_excite (Multiply)    (None, 38, 38, 960)  0           block4h_activation[0][0]         \n",
      "                                                                 block4h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_bn (BatchNormal (None, 38, 38, 160)  640         block4h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4h_drop (Dropout)          (None, 38, 38, 160)  0           block4h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_add (Add)               (None, 38, 38, 160)  0           block4h_drop[0][0]               \n",
      "                                                                 block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_activation (Acti (None, 38, 38, 960)  0           block4i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4i_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4i_activation (Activation) (None, 38, 38, 960)  0           block4i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_squeeze (GlobalAvera (None, 960)          0           block4i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_excite (Multiply)    (None, 38, 38, 960)  0           block4i_activation[0][0]         \n",
      "                                                                 block4i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_bn (BatchNormal (None, 38, 38, 160)  640         block4i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4i_drop (Dropout)          (None, 38, 38, 160)  0           block4i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_add (Add)               (None, 38, 38, 160)  0           block4i_drop[0][0]               \n",
      "                                                                 block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_activation (Acti (None, 38, 38, 960)  0           block4j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4j_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4j_activation (Activation) (None, 38, 38, 960)  0           block4j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_squeeze (GlobalAvera (None, 960)          0           block4j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_excite (Multiply)    (None, 38, 38, 960)  0           block4j_activation[0][0]         \n",
      "                                                                 block4j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_bn (BatchNormal (None, 38, 38, 160)  640         block4j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4j_drop (Dropout)          (None, 38, 38, 160)  0           block4j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_add (Add)               (None, 38, 38, 160)  0           block4j_drop[0][0]               \n",
      "                                                                 block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 38, 38, 960)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 38, 38, 960)  24000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 38, 38, 960)  3840        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 38, 38, 960)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 960)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 38, 38, 960)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 38, 38, 224)  215040      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 38, 38, 224)  896         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 38, 38, 1344) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 38, 38, 1344) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1344)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 38, 38, 224)  896         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 38, 38, 224)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 38, 38, 224)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 38, 38, 1344) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 38, 38, 1344) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1344)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 38, 38, 224)  896         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 38, 38, 224)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 38, 38, 224)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 38, 38, 1344) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 38, 38, 1344) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1344)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 38, 38, 224)  896         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 38, 38, 224)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 38, 38, 224)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 38, 38, 1344) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 38, 38, 1344) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1344)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 38, 38, 224)  896         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 38, 38, 224)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 38, 38, 224)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 38, 38, 1344) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 38, 38, 1344) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1344)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 38, 38, 224)  896         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (Dropout)          (None, 38, 38, 224)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 38, 38, 224)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 38, 38, 1344) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 38, 38, 1344) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1344)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 38, 38, 224)  896         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (Dropout)          (None, 38, 38, 224)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 38, 38, 224)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_activation (Acti (None, 38, 38, 1344) 0           block5h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5h_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5h_activation (Activation) (None, 38, 38, 1344) 0           block5h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_squeeze (GlobalAvera (None, 1344)         0           block5h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5h_activation[0][0]         \n",
      "                                                                 block5h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_bn (BatchNormal (None, 38, 38, 224)  896         block5h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5h_drop (Dropout)          (None, 38, 38, 224)  0           block5h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_add (Add)               (None, 38, 38, 224)  0           block5h_drop[0][0]               \n",
      "                                                                 block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_activation (Acti (None, 38, 38, 1344) 0           block5i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5i_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5i_activation (Activation) (None, 38, 38, 1344) 0           block5i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_squeeze (GlobalAvera (None, 1344)         0           block5i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5i_activation[0][0]         \n",
      "                                                                 block5i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_bn (BatchNormal (None, 38, 38, 224)  896         block5i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5i_drop (Dropout)          (None, 38, 38, 224)  0           block5i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_add (Add)               (None, 38, 38, 224)  0           block5i_drop[0][0]               \n",
      "                                                                 block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_activation (Acti (None, 38, 38, 1344) 0           block5j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5j_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5j_activation (Activation) (None, 38, 38, 1344) 0           block5j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_squeeze (GlobalAvera (None, 1344)         0           block5j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5j_activation[0][0]         \n",
      "                                                                 block5j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_bn (BatchNormal (None, 38, 38, 224)  896         block5j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5j_drop (Dropout)          (None, 38, 38, 224)  0           block5j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_add (Add)               (None, 38, 38, 224)  0           block5j_drop[0][0]               \n",
      "                                                                 block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 38, 38, 1344) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 41, 41, 1344) 0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 19, 19, 1344) 33600       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 19, 19, 1344) 5376        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 19, 19, 1344) 0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1344)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 19, 19, 1344) 0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 19, 19, 384)  516096      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 19, 19, 2304) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 19, 19, 2304) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 2304)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 19, 19, 384)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 19, 19, 384)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 19, 19, 2304) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 19, 19, 2304) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 2304)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 19, 19, 384)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 19, 19, 384)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 19, 19, 2304) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 19, 19, 2304) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 2304)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 19, 19, 384)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 19, 19, 384)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 19, 19, 2304) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 19, 19, 2304) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 2304)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 19, 19, 384)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 19, 19, 384)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 19, 19, 2304) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 19, 19, 2304) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 2304)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 19, 19, 384)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 19, 19, 384)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 19, 19, 2304) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 19, 19, 2304) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 2304)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (Dropout)          (None, 19, 19, 384)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 19, 19, 384)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 19, 19, 2304) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 19, 19, 2304) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 2304)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (Dropout)          (None, 19, 19, 384)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 19, 19, 384)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 19, 19, 2304) 0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 19, 19, 2304) 0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 2304)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (Dropout)          (None, 19, 19, 384)  0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 19, 19, 384)  0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_activation (Acti (None, 19, 19, 2304) 0           block6j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6j_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6j_activation (Activation) (None, 19, 19, 2304) 0           block6j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_squeeze (GlobalAvera (None, 2304)         0           block6j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6j_activation[0][0]         \n",
      "                                                                 block6j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6j_drop (Dropout)          (None, 19, 19, 384)  0           block6j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_add (Add)               (None, 19, 19, 384)  0           block6j_drop[0][0]               \n",
      "                                                                 block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6k_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_activation (Acti (None, 19, 19, 2304) 0           block6k_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6k_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6k_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6k_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6k_activation (Activation) (None, 19, 19, 2304) 0           block6k_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_squeeze (GlobalAvera (None, 2304)         0           block6k_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6k_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6k_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6k_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6k_activation[0][0]         \n",
      "                                                                 block6k_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6k_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6k_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6k_drop (Dropout)          (None, 19, 19, 384)  0           block6k_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_add (Add)               (None, 19, 19, 384)  0           block6k_drop[0][0]               \n",
      "                                                                 block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6l_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_activation (Acti (None, 19, 19, 2304) 0           block6l_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6l_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6l_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6l_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6l_activation (Activation) (None, 19, 19, 2304) 0           block6l_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_squeeze (GlobalAvera (None, 2304)         0           block6l_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6l_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6l_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6l_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6l_activation[0][0]         \n",
      "                                                                 block6l_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6l_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6l_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6l_drop (Dropout)          (None, 19, 19, 384)  0           block6l_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_add (Add)               (None, 19, 19, 384)  0           block6l_drop[0][0]               \n",
      "                                                                 block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6m_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_activation (Acti (None, 19, 19, 2304) 0           block6m_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6m_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6m_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6m_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6m_activation (Activation) (None, 19, 19, 2304) 0           block6m_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_squeeze (GlobalAvera (None, 2304)         0           block6m_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6m_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6m_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6m_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6m_activation[0][0]         \n",
      "                                                                 block6m_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6m_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6m_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6m_drop (Dropout)          (None, 19, 19, 384)  0           block6m_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_add (Add)               (None, 19, 19, 384)  0           block6m_drop[0][0]               \n",
      "                                                                 block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6m_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 19, 19, 2304) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 20736       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 19, 19, 2304) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 2304)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 19, 19, 2304) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 19, 19, 640)  1474560     block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 19, 19, 3840) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 19, 19, 3840) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3840)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 19, 19, 640)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 19, 19, 640)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 19, 19, 3840) 0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 19, 19, 3840) 0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3840)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (Dropout)          (None, 19, 19, 640)  0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 19, 19, 640)  0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_activation (Acti (None, 19, 19, 3840) 0           block7d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7d_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7d_activation (Activation) (None, 19, 19, 3840) 0           block7d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_squeeze (GlobalAvera (None, 3840)         0           block7d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7d_activation[0][0]         \n",
      "                                                                 block7d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7d_drop (Dropout)          (None, 19, 19, 640)  0           block7d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_add (Add)               (None, 19, 19, 640)  0           block7d_drop[0][0]               \n",
      "                                                                 block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 19, 19, 2560) 1638400     block7d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 19, 19, 2560) 10240       top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 19, 19, 2560) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2560)         0           top_activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 64,097,687\n",
      "Trainable params: 0\n",
      "Non-trainable params: 64,097,687\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "custom_efficientnetB0_model.trainable = False\n",
    "for layer in custom_efficientnetB0_model.layers:\n",
    "    layer.trainable = False\n",
    "## Freez\n",
    "#custom_inceptionv3_model.layers[-1].trainable = True\n",
    "#custom_inceptionv3_model.layers[-2].trainable = True\n",
    "#custom_inceptionv3_model.layers[-3].trainable = True\n",
    "print(custom_efficientnetB0_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(custom_efficientnetB0_model, to_file=\"InceptionRemoveOutput.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Feature Extractor\n",
    "model.add(custom_efficientnetB0_model)\n",
    "# Classifier\n",
    "#DeepDense\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(len(class_names), activation='softmax', trainable=True))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 2560)              64097687  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2622464   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 66,730,401\n",
      "Trainable params: 2,632,714\n",
      "Non-trainable params: 64,097,687\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = ['1WayConnectorforFoley', '2WayConnectorforFoley', '2WayFoleyCatheter', '3WayConnectorforFoley', '3Waystopcock', 'AlcoholBottle', 'AlcoholPad', 'BootCover', 'CottonBall', 'CottonSwap', 'Dilator', 'DisposableInfusionSet', 'ExtensionTube', 'FaceShield', 'FrontLoadSyringe', 'GauzePad', 'Glove', 'GuideWire', 'LiquidBottle', 'Mask', 'NGTube', 'NasalCannula', 'Needle', 'OxygenMask', 'PPESuit', 'PharmaceuticalProduct', 'Pill', 'PillBottle', 'PrefilledHumidifier', 'PressureConnectingTube', 'ReusableHumidifier', 'SodiumChlorideBag', 'SterileHumidifierAdapter', 'SurgicalBlade', 'SurgicalCap', 'SurgicalSuit', 'Syringe', 'TrachealTube', 'UrineBag', 'Vaccinebottle', 'WingedInfusionSet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[-1]._name = 'Classifier'\n",
    "#model.layers[-2]._name = 'InceptionV3'\n",
    "#print(len(model.layers))\n",
    "#tf.keras.utils.plot_model(model, to_file=\"Incepv3_FreezExtractorOurOutputLayer.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/2000\n",
      "32/32 [==============================] - 109s 3s/step - loss: 0.2320 - accuracy: 0.9355 - val_loss: 0.0144 - val_accuracy: 0.9961\n",
      "Epoch 2/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 3/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 4/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0147 - val_accuracy: 0.9961\n",
      "Epoch 5/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 6/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 7/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 8/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7204e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 9/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 10/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2087e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 11/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5918e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5536e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5275e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.2994e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9638e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 16/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9158e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8608e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4134e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1774e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9144e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 21/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6158e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8907e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2805e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3649e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5178e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4104e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2278e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3775e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4316e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5812e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4390e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1057e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7977e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5654e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7161e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1481e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7199e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9220e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0473e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6886e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6895e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6042e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3439e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.7344e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9374e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7554e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3795e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8014e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2581e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2176e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2376e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8660e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3116e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5238e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3349e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8807e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5943e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5092e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2499e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2581e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7722e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8171e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6705e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2533e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0373e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8931e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8521e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.3435e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 69/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.4890e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 70/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8828e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 71/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6512e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 72/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3307e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 73/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7670e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 74/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4356e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 75/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2214e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 76/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5364e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 77/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8759e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 78/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2096e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 79/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1894e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 80/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6778e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 81/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5905e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 82/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5807e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 83/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8707e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 84/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6426e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 85/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0685e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 86/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9743e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 87/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7882e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 88/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5780e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 89/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5275e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 90/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2432e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 91/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8255e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 92/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8535e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 93/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2337e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 94/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6670e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 95/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4282e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 96/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2882e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 97/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7126e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 98/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0471e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 99/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3768e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 100/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6813e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 101/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4786e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 102/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7370e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 103/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9018e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 104/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5648e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 105/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8832e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 106/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5451e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 107/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5092e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 108/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4095e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 109/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2502e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 110/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3381e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 111/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2997e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 112/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2630e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 113/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3577e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 114/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.5239e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 115/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2753e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 116/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1051e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 117/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8471e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 118/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.2913e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 119/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1836e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 120/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3620e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 121/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4447e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 122/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5184e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 123/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0977e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 124/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3746e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 125/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1302e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 126/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3160e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 127/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1176e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 128/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9577e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 129/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0324e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 130/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1318e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 131/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.1983e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 132/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4749e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 133/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2216e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 134/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1681e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 135/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2744e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 136/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7049e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 137/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.0723e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 138/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1635e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 139/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1523e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 140/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4839e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 141/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2921e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 142/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2448e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 143/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.4191e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 144/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.7843e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 145/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3870e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 146/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0352e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 147/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7937e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 148/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1021e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 149/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2347e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 150/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0267e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 151/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0064e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 152/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0510e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 153/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.7340e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 154/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3206e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 155/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.9423e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 156/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4604e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 157/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4805e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 158/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.5578e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 159/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5971e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 160/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4216e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 161/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8740e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 162/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9233e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 163/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4008e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 164/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6269e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 165/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0983e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 166/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3954e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 167/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.9026e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 168/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.6485e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 169/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.0853e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 170/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5130e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 171/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8587e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 172/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4958e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 173/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2719e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 174/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8339e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 175/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1155e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 176/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6219e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 177/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8378e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 178/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5048e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 179/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3484e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 180/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2633e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 181/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4397e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 182/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4753e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 183/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3805e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 184/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0852e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 185/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9773e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 186/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5595e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 187/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1422e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 188/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3884e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 189/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7926e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 190/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3090e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 191/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2170e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 192/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.3737e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 193/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.4782e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 194/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 7.1833e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 195/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5876e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 196/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7591e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 197/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0107e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 198/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6167e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 199/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4577e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 200/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3084e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1390e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 202/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.0573e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 203/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4979e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 204/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5926e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 205/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3969e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 206/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8920e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 207/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4736e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 208/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5346e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 209/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9165e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 210/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1806e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 211/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2427e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 212/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3464e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 213/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0102e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 214/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9329e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 215/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9414e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 216/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8841e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 217/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2946e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 218/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7011e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 219/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.2511e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 220/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2007e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 221/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8736e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 222/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6338e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 223/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9961e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 224/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7587e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 225/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8680e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 226/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.7386e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 227/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2882e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 228/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5715e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 229/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8322e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 230/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.0444e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 231/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8523e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 232/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1852e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 233/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3292e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 234/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5347e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 235/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2191e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 236/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7241e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 237/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1141e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 238/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4146e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 239/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5591e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 240/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5932e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 241/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7338e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 242/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2118e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 243/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6214e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 244/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6151e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 245/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8457e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 246/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3956e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 247/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2407e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 248/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.2683e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 249/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.0080e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 250/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5168e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 251/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8680e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 252/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4150e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 253/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0751e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 254/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2443e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 255/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8121e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 256/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0284e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 257/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0537e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 258/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1490e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 259/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4572e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 260/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1073e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 261/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6615e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 262/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7404e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 263/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3257e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 264/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1461e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 265/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3618e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 266/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2748e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 267/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3893e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 268/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0235e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 269/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1892e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 270/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6995e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 271/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8635e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 272/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2028e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 273/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5850e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 274/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7387e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 275/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.0087e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 276/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0385e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 277/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2510e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 278/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6210e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 279/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2116e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 280/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4967e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 281/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0986e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 282/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4512e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 283/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5044e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 284/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9426e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 285/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9900e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 286/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1174e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 287/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9887e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 288/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1560e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 289/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2760e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 290/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.1169e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 291/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0820e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 292/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7880e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 293/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4494e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 294/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1308e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 295/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8460e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 296/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8243e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 297/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6561e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 298/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5845e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 299/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8256e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 300/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8248e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 301/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4003e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 302/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4287e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 303/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0422e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 304/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9957e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 305/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5112e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 306/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5857e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 307/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4543e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 308/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.1289e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 309/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5195e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 310/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4537e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 311/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6877e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 312/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1091e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 313/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8985e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 314/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.2057e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 315/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.0844e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 316/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9567e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 317/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3078e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 318/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4672e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 319/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0915e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 320/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4836e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 321/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6928e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 322/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6786e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 323/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9851e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 324/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.7684e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 325/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.1540e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 326/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0025e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 327/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9334e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 328/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2341e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 329/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5630e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 330/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1499e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 331/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2542e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 332/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2269e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 333/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8045e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 334/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3596e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 335/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0631e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 336/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1939e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 337/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9683e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 338/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9820e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 339/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4754e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 340/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9352e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 341/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8845e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 342/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4779e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 343/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3431e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 344/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7732e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 345/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0863e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 346/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0337e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 347/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5150e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 348/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3955e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 349/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2625e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 350/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7055e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 351/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1085e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 352/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6859e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 353/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6080e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 354/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5625e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 355/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4327e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 356/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4216e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 357/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5594e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 358/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2036e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 359/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3637e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 360/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1150e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 361/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5832e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 362/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6552e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 363/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5939e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 364/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9348e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 365/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7554e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 366/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3484e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 367/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8271e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 368/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3842e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 369/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.1257e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 370/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4361e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 371/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6467e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 372/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2352e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 373/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4247e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 374/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0164e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 375/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0476e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 376/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4461e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 377/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4726e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 378/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5023e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 379/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3810e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 380/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9398e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 381/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0885e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 382/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7420e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 383/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0683e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 384/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8557e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 385/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6011e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 386/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6225e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 387/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5488e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 388/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 9.8924e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 389/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6129e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 390/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4729e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 391/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1808e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 392/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5898e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 393/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4445e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 394/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5152e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 395/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1919e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 396/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3306e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 397/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5191e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 398/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1365e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 399/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3691e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 400/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6986e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3544e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 402/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6326e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 403/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3288e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 404/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0797e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 405/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5861e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 406/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.7112e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 407/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1098e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 408/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5454e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 409/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1560e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 410/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4523e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 411/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0579e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 412/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3435e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 413/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2498e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 414/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8754e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 415/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3087e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 416/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6827e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 417/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1322e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 418/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7510e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 419/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7766e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 420/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0281e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 421/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5683e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 422/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.0352e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 423/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2944e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 424/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4646e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 425/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0878e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 426/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6839e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 427/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1620e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 428/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0477e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 429/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6731e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 430/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0279e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 431/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2607e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 432/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6739e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 433/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8355e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 434/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0600e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 435/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0590e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 436/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.3622e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 437/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 7.6196e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 438/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.8795e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 439/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.5350e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 440/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2236e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 441/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5255e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 442/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0048e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 443/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5352e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 444/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8369e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 445/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6256e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 446/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4326e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 447/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4266e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 448/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8641e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 449/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2201e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 450/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2407e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 451/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 452/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1271e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 453/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3468e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 454/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7997e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 455/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9244e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 456/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1924e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 457/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5083e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 458/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2279e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 459/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6728e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 460/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5349e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 461/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9786e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 462/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 9.0419e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 463/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5094e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 464/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 9.4259e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 465/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4058e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 466/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7576e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 467/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2468e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 468/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3619e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 469/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2828e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 470/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1472e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 471/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3987e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 472/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0660e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 473/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1449e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 474/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2112e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 475/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2224e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 476/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8094e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 477/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0776e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 478/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.5336e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 479/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1276e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 480/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7464e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 481/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8441e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 482/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3357e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 483/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8230e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 484/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1011e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 485/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.9436e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 486/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1893e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 487/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6064e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 488/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3416e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 489/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.5744e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 490/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5283e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 491/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9447e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 492/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.6652e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 493/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 7.6365e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 494/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1130e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 495/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1959e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 496/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4127e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 497/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1213e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 498/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1470e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 499/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.2654e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 500/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2049e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 501/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6199e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 502/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0047e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 503/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4317e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 504/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5969e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 505/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6494e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 506/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1419e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 507/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7042e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 508/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5316e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 509/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2423e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 510/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8434e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 511/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.7978e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 512/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5200e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 513/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4053e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 514/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8095e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 515/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6688e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 516/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4902e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 517/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7847e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 518/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.1277e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 519/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9495e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 520/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.1005e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 521/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.7762e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 522/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1966e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 523/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8677e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 524/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8779e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 525/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8051e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 526/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8589e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 527/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.7735e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 528/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1794e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 529/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5416e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 530/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6221e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 531/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8727e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 532/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.6581e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 533/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4059e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 534/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.0206e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 535/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.0709e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 536/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.8994e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 537/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.5980e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 538/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1031e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 539/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0437e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 540/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5660e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 541/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7641e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 542/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0342e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 543/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4072e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 544/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.1178e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 545/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6834e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 546/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3335e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 547/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8636e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 548/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7120e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 549/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0735e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 550/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7249e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 551/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 552/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0414e-06 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 553/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3960e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 554/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2522e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 555/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1662e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 556/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9396e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 557/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8704e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 558/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4384e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 559/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6299e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 560/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9964e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 561/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5263e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 562/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4046e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 563/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4389e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 564/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0304e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 565/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2520e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 566/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4367e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 567/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9292e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 568/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1166e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 569/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.9566e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 570/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.3402e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 571/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1372e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 572/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.3797e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 573/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1083e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 574/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0618e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 575/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3271e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 576/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1512e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 577/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0851e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 578/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1647e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 579/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5662e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 580/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9562e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 581/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5887e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 582/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8470e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 583/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.9646e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 584/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.7454e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 585/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3610e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 586/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5097e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 587/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5143e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 588/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3986e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 589/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0894e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 590/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2671e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 591/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0056e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 592/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7842e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 593/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2227e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 594/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6040e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 595/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6548e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 596/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4460e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 597/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5834e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 598/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8068e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 599/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8005e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 600/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8873e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0768e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 602/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7215e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 603/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5626e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 604/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3990e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 605/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7767e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 606/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7921e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 607/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.8328e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 608/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.3933e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 609/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0521e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 610/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8436e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 611/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1534e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 612/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7256e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 613/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5492e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 614/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4765e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 615/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5814e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 616/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3865e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 617/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.9642e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 618/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.2405e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 619/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1317e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 620/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8349e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 621/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7156e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 622/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8418e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 623/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7157e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 624/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3236e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 625/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2917e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 626/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8603e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 627/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5765e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 628/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4218e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 629/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1310e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 630/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8926e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 631/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.8403e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 632/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.7859e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 633/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2856e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 634/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5127e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 635/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1930e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 636/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7795e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 637/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2922e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 638/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7092e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 639/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7187e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 640/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8767e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 641/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1019e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 642/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7039e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 643/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7520e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 644/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3141e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 645/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2243e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 646/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0558e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 647/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7730e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 648/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5885e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 649/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9783e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 650/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9477e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 651/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3226e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 652/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9581e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 653/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5472e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 654/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9536e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 655/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0307e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 656/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.4737e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 657/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.1127e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 658/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3329e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 659/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7520e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 660/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9738e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 661/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7694e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 662/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8703e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 663/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6920e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 664/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.0693e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 665/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6675e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 666/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0676e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 667/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.3188e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 668/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3875e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 669/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4871e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 670/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3574e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 671/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8586e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 672/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7710e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 673/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7318e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 674/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2867e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 675/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9435e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 676/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0333e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 677/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1569e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 678/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6163e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 679/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8477e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 680/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1772e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 681/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8349e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 682/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6607e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 683/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2247e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 684/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8112e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 685/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4853e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 686/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4267e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 687/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8100e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 688/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7347e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 689/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1814e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 690/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7697e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 691/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 7.3316e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 692/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5935e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 693/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0068e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 694/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1867e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 695/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9817e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 696/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8646e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 697/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.9862e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 698/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9511e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 699/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8788e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 700/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2025e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 701/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9128e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 702/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2602e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 703/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4143e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 704/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2606e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 705/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.3906e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 706/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.3573e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 707/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.5842e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 708/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.3177e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 709/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.6096e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 710/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8457e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 711/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9820e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 712/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4556e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 713/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7821e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 714/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1534e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 715/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1995e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 716/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6537e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 717/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5783e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 718/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6606e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 719/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6702e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 720/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4602e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 721/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8028e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 722/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8331e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 723/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7115e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 724/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8982e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 725/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8053e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 726/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1097e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 727/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7710e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 728/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8191e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 729/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5067e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 730/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.9658e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 731/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6313e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 732/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1006e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 733/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4255e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 734/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5770e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 735/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7769e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 736/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6239e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 737/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4715e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 738/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5303e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 739/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4744e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 740/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4160e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 741/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3970e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 742/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9742e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 743/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6577e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 744/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0672e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 745/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9797e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 746/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0575e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 747/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2105e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 748/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5587e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 749/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4323e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 750/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7621e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 751/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0263e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 752/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5151e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 753/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7652e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 754/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9476e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 755/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6450e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 756/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1043e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 757/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5210e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 758/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3107e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 759/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2796e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 760/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7195e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 761/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1604e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 762/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0437e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 763/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0092e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 764/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3724e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 765/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.1012e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 766/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9269e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 767/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1630e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 768/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4575e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9961\n",
      "Epoch 769/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7374e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9961\n",
      "Epoch 770/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5521e-06 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9961\n",
      "Epoch 771/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6599e-06 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9961\n",
      "Epoch 772/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9903e-06 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9961\n",
      "Epoch 773/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0738e-06 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9961\n",
      "Epoch 774/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3557e-06 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9961\n",
      "Epoch 775/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3536e-06 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9961\n",
      "Epoch 776/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7388e-06 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9961\n",
      "Epoch 777/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3359e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9961\n",
      "Epoch 778/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5709e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9961\n",
      "Epoch 779/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.2988e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9961\n",
      "Epoch 780/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.5781e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9961\n",
      "Epoch 781/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8397e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9961\n",
      "Epoch 782/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9807e-06 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9961\n",
      "Epoch 783/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0534e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9961\n",
      "Epoch 784/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5614e-06 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9961\n",
      "Epoch 785/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.1308e-06 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9961\n",
      "Epoch 786/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5098e-06 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9961\n",
      "Epoch 787/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9354e-06 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9961\n",
      "Epoch 788/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2448e-06 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9961\n",
      "Epoch 789/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2752e-06 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9961\n",
      "Epoch 790/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0490e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 791/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7069e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 792/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8038e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 793/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8494e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 794/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8424e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 795/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0714e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 796/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4761e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 797/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6208e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 798/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.0650e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 799/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0262e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 800/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2039e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8707e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 802/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3285e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 803/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.5893e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 804/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1554e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 805/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5515e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 806/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8606e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 807/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8004e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 808/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0071e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 809/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9838e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 810/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8245e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 811/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7912e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 812/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0315e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 813/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8924e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 814/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3957e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 815/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1905e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 816/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5703e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 817/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1406e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 818/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1266e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 819/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8714e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 820/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8217e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 821/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7503e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 822/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6405e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 823/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7881e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 824/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5142e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 825/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2161e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 826/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4005e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 827/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.8469e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 828/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8083e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 829/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6742e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 830/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3306e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 831/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3909e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 832/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9137e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 833/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5511e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 834/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5684e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 835/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3293e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 836/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9131e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 837/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5553e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 838/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4032e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 839/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5896e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 840/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3129e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 841/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8126e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 842/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7045e-06 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9961\n",
      "Epoch 843/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2099e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 844/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8430e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 845/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1346e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 846/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4495e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 847/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7665e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 848/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2361e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 849/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5891e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 850/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2838e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 851/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8002e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 852/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.9869e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 853/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7657e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 854/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.8680e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 855/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.8723e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 856/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.8471e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 857/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5602e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 858/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8113e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 859/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2697e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 860/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3675e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 861/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.6553e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 862/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8388e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 863/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7547e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 864/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7291e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 865/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6004e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 866/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4999e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 867/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0077e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 868/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4915e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 869/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5659e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 870/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9426e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 871/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1429e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 872/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0097e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 873/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8712e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 874/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2912e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 875/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0991e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 876/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.1017e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 877/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4358e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 878/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1449e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 879/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5875e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 880/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7837e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 881/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7148e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 882/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2014e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 883/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2525e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 884/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2965e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 885/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0392e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 886/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4564e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 887/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2451e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 888/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6400e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 889/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1755e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 890/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1303e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 891/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8866e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 892/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0397e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 893/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7266e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 894/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5262e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 895/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5733e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 896/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8337e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 897/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2889e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 898/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6857e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 899/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0568e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 900/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6659e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 901/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8327e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 902/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8954e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 903/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6116e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 904/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2330e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 905/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6767e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 906/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4454e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 907/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9915e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 908/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5495e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 909/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4690e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 910/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0163e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 911/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9063e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 912/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4898e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 913/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7819e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 914/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2177e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 915/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9815e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 916/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0702e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 917/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7526e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 918/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4932e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 919/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6466e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 920/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7607e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 921/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9479e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 922/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5693e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 923/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4903e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 924/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3289e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 925/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7842e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 926/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2162e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 927/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6641e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 928/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0075e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 929/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2745e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 930/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0775e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 931/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4816e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 932/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5723e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 933/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7602e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 934/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5755e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 935/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9001e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 936/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6119e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 937/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4167e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 938/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4230e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 939/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6441e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 940/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2406e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 941/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1685e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 942/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2439e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 943/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.0028e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 944/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5357e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 945/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9761e-06 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9961\n",
      "Epoch 946/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4896e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 947/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9251e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9961\n",
      "Epoch 948/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6567e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 949/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6648e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 950/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1585e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 951/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.4475e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 952/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0974e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 953/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8076e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 954/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5416e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 955/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1336e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 956/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2740e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9961\n",
      "Epoch 957/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1934e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 958/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2773e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 959/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 9.0349e-07 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 960/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2202e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 961/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8516e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 962/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1929e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 963/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6209e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 964/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5118e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 965/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4128e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 966/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3306e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 967/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3810e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 968/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2600e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 969/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8248e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 970/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6398e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 971/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4814e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 972/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4387e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 973/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2429e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 974/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4502e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 975/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1242e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 976/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.3719e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 977/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2997e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 978/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4011e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 979/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6819e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 980/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2561e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 981/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4282e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 982/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2063e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 983/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.7995e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 984/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.4111e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 985/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.7460e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 986/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.3076e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 987/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5477e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 988/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9406e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 989/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8215e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 990/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3034e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 991/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0256e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 992/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5967e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 993/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0666e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 994/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2651e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 995/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7005e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 996/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3260e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 997/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0184e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 998/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3079e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 999/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0322e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1000/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2355e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 2.7841e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1002/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.2721e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1003/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2299e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1004/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8951e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1005/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5666e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1006/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.8719e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1007/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1648e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1008/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.3801e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1009/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6219e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1010/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5210e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1011/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5087e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1012/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2265e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1013/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9467e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1014/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1774e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1015/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1185e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1016/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5390e-07 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1017/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7641e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1018/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3533e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1019/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3987e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1020/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2473e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1021/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.4325e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1022/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5792e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1023/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9767e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1024/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5821e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1025/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2023e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1026/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2583e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1027/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3141e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1028/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0492e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1029/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0442e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1030/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4391e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1031/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8716e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1032/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8184e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1033/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1898e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1034/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7788e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1035/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3426e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 1036/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1693e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 1037/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3718e-06 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 1038/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1628e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9961\n",
      "Epoch 1039/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2511e-06 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9961\n",
      "Epoch 1040/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3532e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1041/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1434e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1042/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8565e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1043/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6810e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1044/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4668e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1045/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3694e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1046/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0619e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1047/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9197e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1048/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4131e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1049/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3306e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1050/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6984e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1051/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4516e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1052/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1292e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1053/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7261e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1054/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9278e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1055/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4421e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1056/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.6888e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1057/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.4726e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1058/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8428e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1059/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5514e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1060/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0910e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1061/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3423e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1062/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1054e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1063/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2710e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1064/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2124e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1065/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1593e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1066/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3363e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1067/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5531e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1068/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3712e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1069/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4141e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1070/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1890e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1071/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2817e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1072/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7715e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1073/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8322e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1074/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.7168e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1075/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0165e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1076/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3864e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1077/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9352e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1078/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.9811e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1079/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3735e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1080/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1912e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1081/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7752e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1082/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5995e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1083/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4265e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1084/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1935e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1085/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3241e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1086/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0090e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1087/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5116e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1088/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6081e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1089/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3024e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1090/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5519e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1091/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3003e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1092/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5145e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1093/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5168e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1094/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3981e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1095/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1096/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8254e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1097/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3824e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1098/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7136e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1099/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5265e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1100/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4231e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1101/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4086e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1102/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4376e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1103/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6763e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1104/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6983e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1105/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.2271e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1106/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9944e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1107/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.4708e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1108/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2415e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1109/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7427e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1110/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7229e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1111/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.5004e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1112/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9861e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1113/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8727e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1114/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4936e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1115/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1758e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1116/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3083e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1117/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4586e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1118/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1494e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1119/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2543e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1120/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4223e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1121/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1271e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1122/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5145e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1123/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.5330e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1124/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7816e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1125/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9857e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1126/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2424e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1127/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1681e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1128/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4270e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1129/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.9727e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1130/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4060e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1131/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8625e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1132/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7019e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1133/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1348e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1134/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 9.9007e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1135/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7878e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1136/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6549e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1137/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1337e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1138/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4702e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1139/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2242e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1140/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5343e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1141/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7274e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1142/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6321e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1143/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5086e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1144/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1814e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1145/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.6340e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1146/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7947e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1147/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3678e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1148/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2187e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1149/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8673e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1150/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0321e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1151/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5972e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1152/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5033e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1153/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7997e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1154/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.3584e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1155/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.0751e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1156/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7516e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1157/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3523e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1158/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3210e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1159/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1048e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1160/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1366e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1161/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5574e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1162/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3806e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1163/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4971e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1164/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3190e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1165/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.9671e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1166/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1747e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1167/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8279e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1168/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7683e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1169/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0079e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1170/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0389e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1171/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1746e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1172/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0373e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1173/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1833e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1174/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1046e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1175/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0038e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1176/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3982e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1177/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0461e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 1178/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5314e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 1179/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.0444e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1180/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.2572e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1181/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3224e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1182/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3876e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1183/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4908e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1184/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6301e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1185/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.2991e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1186/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3121e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1187/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4464e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1188/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6797e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1189/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5727e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1190/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0497e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 1191/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1863e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1192/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0631e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1193/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3164e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1194/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6890e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1195/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4554e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1196/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0022e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1197/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.0360e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1198/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2254e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1199/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0092e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1200/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0307e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6179e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1202/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.1593e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1203/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9624e-07 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1204/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6658e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1205/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6685e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1206/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7473e-07 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9961\n",
      "Epoch 1207/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3978e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1208/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5960e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1209/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1005e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1210/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3225e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1211/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9231e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1212/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9509e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1213/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5944e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1214/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2166e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1215/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2313e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1216/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8754e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1217/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0265e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1218/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3957e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1219/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4482e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1220/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3586e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1221/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4318e-07 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1222/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3290e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1223/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1224/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9355e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1225/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3000e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1226/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5335e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1227/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.3084e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1228/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8836e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1229/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 9.6192e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1230/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.6891e-07 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1231/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1073e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9961\n",
      "Epoch 1232/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9567e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1233/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.8416e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1234/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4132e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1235/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7043e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1236/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2046e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1237/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1897e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1238/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3303e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9961\n",
      "Epoch 1239/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3698e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1240/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7960e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1241/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3764e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1242/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9054e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1243/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8857e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1244/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8405e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1245/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.2442e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1246/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0089e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1247/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0271e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1248/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7577e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1249/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4676e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1250/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8334e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1251/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.9709e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1252/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.1768e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1253/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.0758e-06 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1254/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.6170e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1255/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5387e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1256/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8392e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1257/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5854e-07 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9961\n",
      "Epoch 1258/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9569e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1259/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7264e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1260/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 7.4015e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1261/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0115e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1262/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1842e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1263/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9833e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1264/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8485e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1265/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4003e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1266/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1906e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1267/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0381e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1268/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1561e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1269/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2538e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1270/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9450e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1271/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4467e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1272/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3954e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1273/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4561e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1274/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1254e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1275/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8537e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1276/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.3678e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1277/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6042e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1278/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1490e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9961\n",
      "Epoch 1279/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7877e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1280/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3606e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1281/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.2943e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1282/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 7.9657e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1283/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4392e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1284/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4930e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1285/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1255e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1286/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7078e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1287/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1045e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1288/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8310e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1289/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6415e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1290/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3806e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1291/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7823e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1292/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1967e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1293/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4413e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1294/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5965e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1295/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5304e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1296/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2772e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1297/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9972e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1298/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1706e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1299/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6504e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1300/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.2561e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1301/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 1.3047e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1302/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2918e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1303/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1746e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1304/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2945e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1305/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3323e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1306/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8442e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1307/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1907e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1308/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6153e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1309/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.1544e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1310/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7227e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1311/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6319e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1312/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1386e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1313/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3188e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1314/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4772e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1315/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3875e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1316/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8856e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1317/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4234e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1318/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8580e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1319/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4527e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1320/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2841e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1321/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2282e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1322/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1323e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1323/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4575e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1324/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.8404e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1325/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7923e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1326/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2327e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1327/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3827e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1328/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6410e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1329/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9138e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1330/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4477e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1331/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.9625e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1332/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5227e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1333/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5622e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1334/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4657e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1335/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8784e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1336/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1384e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1337/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7405e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1338/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4072e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1339/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4953e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1340/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8929e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1341/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3865e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1342/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3850e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1343/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3767e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1344/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7799e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1345/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8129e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1346/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.0239e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1347/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2254e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1348/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9370e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1349/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.0568e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1350/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.9323e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1351/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1273e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1352/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6531e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1353/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0662e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1354/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3841e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1355/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0827e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1356/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3546e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1357/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1230e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1358/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2479e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1359/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4948e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1360/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5396e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1361/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3446e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1362/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2027e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1363/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6948e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1364/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6261e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1365/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8669e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1366/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3457e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1367/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4904e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1368/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7392e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1369/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1652e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1370/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2258e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1371/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.0628e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1372/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1313e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1373/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1364e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1374/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8242e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1375/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4528e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1376/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0356e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1377/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2723e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1378/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2630e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1379/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4283e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1380/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0157e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1381/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1757e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1382/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6961e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1383/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3818e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1384/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4901e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1385/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3818e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1386/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1798e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1387/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3495e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1388/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6736e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1389/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7122e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1390/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4259e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1391/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0978e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1392/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8568e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1393/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1127e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1394/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8276e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1395/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6426e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1396/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5761e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1397/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0314e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1398/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.5413e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1399/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1960e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1400/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3904e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1401/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 3.2398e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1402/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.3515e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1403/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1569e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "Epoch 1404/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.0402e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1405/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6065e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1406/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9729e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1407/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0528e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1408/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1397e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "Epoch 1409/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.4685e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1410/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7426e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1411/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9592e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1412/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4280e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1413/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9247e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1414/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6337e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1415/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3574e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1416/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9848e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1417/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2373e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1418/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2514e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1419/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6294e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1420/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5352e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1421/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8452e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1422/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 1.3170e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1423/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5378e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1424/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6427e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1425/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4081e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1426/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2013e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1427/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1102e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1428/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2141e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1429/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0432e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1430/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0176e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1431/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8939e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1432/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1141e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1433/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6953e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1434/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0780e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1435/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4260e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1436/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5704e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1437/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7705e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1438/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3200e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1439/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4100e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1440/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.9537e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1441/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7287e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1442/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.2371e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1443/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9510e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1444/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1487e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1445/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9347e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1446/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.0765e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1447/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 1.0678e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1448/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.9499e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1449/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0664e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1450/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1361e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1451/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2456e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1452/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8066e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1453/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4412e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1454/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1558e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1455/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0679e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1456/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7832e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1457/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6515e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1458/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8497e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1459/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8052e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1460/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7135e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1461/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7960e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1462/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0788e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1463/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3073e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1464/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7264e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1465/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1001e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1466/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7473e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1467/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5355e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1468/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4449e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1469/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7043e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1470/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1184e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1471/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.5428e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1472/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7984e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1473/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0302e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1474/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.7830e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1475/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5064e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1476/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7072e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1477/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0439e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1478/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8603e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1479/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6291e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1480/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6473e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1481/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4620e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1482/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0686e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1483/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2491e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1484/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6449e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1485/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.8168e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1486/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9382e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1487/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4846e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1488/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3792e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1489/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4899e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1490/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8987e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1491/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6947e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1492/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2912e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1493/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2223e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1494/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6786e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1495/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.3288e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1496/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 9.9974e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1497/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0325e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1498/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4505e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1499/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0070e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1500/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1080e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1501/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8148e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1502/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8335e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1503/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3290e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1504/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9883e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1505/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4106e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1506/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.3394e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1507/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4953e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1508/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1991e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1509/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6892e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1510/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6822e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1511/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0810e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1512/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5062e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1513/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2830e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1514/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6077e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1515/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7202e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1516/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.1625e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1517/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7788e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1518/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2187e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1519/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.5261e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1520/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2612e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1521/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3502e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1522/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1676e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1523/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3124e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1524/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6181e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1525/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2712e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1526/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1531e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1527/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7904e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1528/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2848e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1529/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1583e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1530/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8003e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1531/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.6532e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1532/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7426e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1533/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6053e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1534/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3492e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1535/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0209e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1536/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3224e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1537/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6363e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1538/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1479e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1539/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6822e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1540/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8929e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1541/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4878e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1542/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5923e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1543/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5725e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1544/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.6318e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1545/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.5250e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1546/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.6402e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1547/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0244e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1548/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.0522e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1549/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7357e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1550/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5891e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1551/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5891e-07 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1552/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1335e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1553/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2502e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1554/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9395e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1555/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4553e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1556/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1409e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1557/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7334e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1558/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7986e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1559/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7846e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1560/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6231e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1561/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8101e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1562/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7019e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 1563/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7858e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1564/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9197e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1565/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3550e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1566/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5886e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1567/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4190e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1568/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.7760e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1569/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.3923e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1570/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.0801e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1571/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7763e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1572/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1467e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1573/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9197e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1574/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1478e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1575/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3337e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1576/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6324e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1577/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.5027e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1578/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5110e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1579/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7903e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1580/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.8344e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1581/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9360e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1582/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7961e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1583/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7507e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1584/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4961e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1585/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0978e-07 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 1586/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5388e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 1587/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6961e-07 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 1588/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7940e-07 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 1589/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7997e-07 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 1590/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4015e-07 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 1591/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2061e-07 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 1592/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4329e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1593/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.3620e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1594/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2992e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1595/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1805e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1596/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1176e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1597/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.5540e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1598/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3851e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1599/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5045e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1600/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9232e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.0337e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1602/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2524e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1603/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5157e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1604/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4983e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1605/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6844e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1606/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.4760e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1607/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5774e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1608/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7927e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1609/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5340e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1610/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.1967e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1611/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2643e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1612/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2386e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1613/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3550e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1614/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9200e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1615/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7881e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1616/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.4563e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1617/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 5.1058e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1618/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0245e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1619/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1129e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1620/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3795e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1621/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3062e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1622/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5940e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1623/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1964e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1624/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2561e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1625/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 4.8695e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1626/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3958e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1627/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8637e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1628/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9742e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1629/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6996e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1630/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9823e-07 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 1631/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8265e-07 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 1632/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6309e-06 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 1633/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8137e-07 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 1634/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6391e-07 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 1635/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.3199e-07 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 1636/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8055e-07 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 1637/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2072e-07 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 1638/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5788e-06 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1639/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1164e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1640/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6263e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1641/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.5320e-06 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1642/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.0373e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1643/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.6170e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1644/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.6344e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1645/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6006e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1646/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4609e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1647/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9232e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1648/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2037e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1649/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1269e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1650/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6775e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1651/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9232e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1652/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7077e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1653/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9918e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1654/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3840e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1655/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4750e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1656/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0116e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1657/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5596e-06 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1658/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.1827e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1659/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4715e-07 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 1660/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3956e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1661/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2424e-06 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1662/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8381e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1663/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7800e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1664/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.0720e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1665/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.3283e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1666/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9510e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1667/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6903e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1668/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4561e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1669/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4447e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1670/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.0370e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1671/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.6783e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1672/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1222e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1673/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3188e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1674/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2095e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1675/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4389e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1676/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.2888e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1677/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7800e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1678/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2852e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1679/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2887e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1680/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5568e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1681/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7495e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1682/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4864e-06 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1683/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6976e-06 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1684/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5471e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1685/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.8010e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1686/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.3189e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1687/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3375e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1688/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1700e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1689/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5949e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1690/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.5006e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1691/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.2054e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1692/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8417e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1693/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2299e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1694/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9371e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1695/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7357e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1696/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2897e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1697/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0175e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1698/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7344e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1699/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8323e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1700/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8207e-07 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9961\n",
      "Epoch 1701/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.4187e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9961\n",
      "Epoch 1702/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6740e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1703/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8277e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1704/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2433e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1705/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5270e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1706/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.6787e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1707/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8554e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1708/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.3740e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1709/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4447e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1710/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2269e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1711/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4051e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1712/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4016e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1713/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3613e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1714/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 8.9397e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1715/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 6.0043e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1716/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8359e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1717/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4901e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1718/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1269e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1719/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6868e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1720/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1814e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1721/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0872e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1722/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4435e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1723/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2782e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1724/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7730e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1725/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3641e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1726/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8254e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1727/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3935e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1728/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.6476e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1729/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2293e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1730/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2374e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1731/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1397e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1732/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5018e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1733/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7660e-07 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9961\n",
      "Epoch 1734/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.9763e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1735/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0524e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1736/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1944e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1737/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1060e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1738/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7788e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1739/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.9383e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1740/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.9286e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1741/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.9171e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1742/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8393e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1743/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7322e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1744/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1630e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1745/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2408e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1746/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3414e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1747/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0361e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1748/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1012e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1749/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1199e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1750/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0221e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1751/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3679e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1752/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5936e-07 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 1753/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4391e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1754/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1603e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1755/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.0206e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1756/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6157e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1757/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8102e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "Epoch 1758/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5239e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1759/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1013e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "Epoch 1760/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1292e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1761/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0171e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1762/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6391e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1763/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 6.0708e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1764/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.0105e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1765/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.0883e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1766/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8277e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1767/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3333e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "Epoch 1768/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.1162e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9961\n",
      "Epoch 1769/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5657e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1770/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3737e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1771/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2712e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1772/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4736e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1773/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9403e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1774/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0284e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1775/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8777e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1776/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8277e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1777/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0337e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1778/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8044e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1779/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1606e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1780/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2154e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1781/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9324e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1782/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.9410e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1783/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3772e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1784/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7523e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1785/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.5188e-06 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1786/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3807e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1787/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7812e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1788/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.2259e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1789/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 7.7564e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1790/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 2.7299e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1791/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 5.7973e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1792/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.7602e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1793/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9884e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1794/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6985e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1795/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7427e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1796/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8859e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1797/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5425e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1798/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8487e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1799/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2747e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1800/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.7824e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.4971e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1802/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1520e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1803/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9976e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1804/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2468e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1805/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0014e-06 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1806/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8533e-07 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 1807/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4103e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1808/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8090e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1809/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6566e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1810/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3516e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1811/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.4795e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1812/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 1.4401e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1813/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4575e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1814/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3253e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1815/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8335e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1816/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3283e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1817/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7299e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1818/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1129e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1819/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 8.5427e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1820/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3725e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1821/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1327e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1822/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.1893e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1823/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8413e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1824/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.6403e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1825/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.1164e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1826/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4342e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1827/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6426e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1828/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3043e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1829/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1688e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1830/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8894e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1831/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2638e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1832/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8941e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1833/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6764e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1834/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3225e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1835/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.4435e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1836/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5611e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1837/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.2921e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1838/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3749e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1839/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.5737e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1840/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7276e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1841/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5831e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1842/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8486e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1843/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1571e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1844/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8602e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1845/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.1010e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1846/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6027e-07 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 1847/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9418e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1848/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0732e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1849/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8859e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1850/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.3133e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1851/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.6185e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1852/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4238e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1853/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4544e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1854/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3806e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1855/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2421e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1856/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1350e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1857/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7450e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1858/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 7.2100e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1859/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7810e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1860/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.2701e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1861/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.4819e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1862/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.0011e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1863/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 9.8443e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1864/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2922e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1865/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6973e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1866/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0920e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1867/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2112e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1868/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.0847e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1869/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.3491e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1870/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1871/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7555e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1872/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4656e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1873/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8999e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1874/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7949e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1875/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3120e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1876/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8021e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1877/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8231e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1878/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9115e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1879/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1071e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1880/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8987e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1881/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6484e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1882/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6786e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1883/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5320e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1884/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.4808e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1885/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.5343e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1886/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 1.1481e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1887/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8556e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1888/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.1093e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1889/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.2281e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1890/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7974e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1891/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6740e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1892/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0128e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1893/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5704e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1894/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4492e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1895/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8253e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1896/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2584e-07 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9961\n",
      "Epoch 1897/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4416e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1898/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1420e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1899/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.9741e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1900/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6636e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1901/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6145e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1902/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9277e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1903/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.1770e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1904/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.5457e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1905/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.8936e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1906/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0861e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1907/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.2805e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1908/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1327e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1909/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.1489e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1910/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3201e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1911/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6356e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1912/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3667e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1913/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6614e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1914/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.7031e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1915/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6706e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1916/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.6857e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1917/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7427e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1918/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.4898e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1919/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4924e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1920/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3695e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1921/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1246e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1922/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3958e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1923/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0419e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1924/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1944e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1925/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.1278e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1926/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2217e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1927/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.9661e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1928/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.8566e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1929/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8812e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1930/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8894e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1931/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4210e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1932/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.9022e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1933/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.9872e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1934/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 1.8335e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1935/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.0047e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1936/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.9021e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1937/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.8603e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1938/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.8975e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1939/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.7178e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1940/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.5821e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1941/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.5552e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1942/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3772e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1943/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4249e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1944/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.5146e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1945/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7055e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1946/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2503e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1947/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1083e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1948/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.6971e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1949/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.8963e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1950/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.2264e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1951/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3876e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1952/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.7485e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1953/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7066e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1954/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.2703e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1955/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4552e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1956/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.4536e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1957/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0500e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1958/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 5.3370e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1959/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0245e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1960/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.6878e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1961/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.4179e-07 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 1962/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.7658e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1963/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.9266e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1964/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.4933e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1965/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3632e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1966/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.4063e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1967/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3678e-07 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 1968/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2852e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1969/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6403e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1970/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 6.9124e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1971/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1851e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1972/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.1467e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1973/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.3457e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1974/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 5.6871e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1975/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0850e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1976/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.7531e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1977/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 3.0652e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1978/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.7392e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1979/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.6961e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1980/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.2604e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1981/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2468e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1982/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.0931e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1983/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 4.9650e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1984/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.8172e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1985/2000\n",
      "32/32 [==============================] - 75s 2s/step - loss: 4.6971e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1986/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4668e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1987/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 3.1548e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1988/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.4366e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1989/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.2119e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1990/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 1.2515e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1991/2000\n",
      "32/32 [==============================] - 74s 2s/step - loss: 2.4971e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1992/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3353e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1993/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7916e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1994/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.7346e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1995/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 4.0849e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1996/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3481e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1997/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.3295e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 1998/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0140e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 1999/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.0454e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "Epoch 2000/2000\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2.3551e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "save_model_interval = 200\n",
    "checkpoint_filepath = path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch{epoch:04d}.pb' # -val_acc{val_accuracy:.2f}\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    period=save_model_interval,\n",
    "    save_best_only=False)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                  patience=5, min_lr=0.00001,cooldown=1, verbose=1)\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "history = model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS, callbacks=[model_checkpoint_callback,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.subplot(1, 2, 2)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0078 - accuracy: 0.9961\n",
      "test_indoor_ds_results:test loss, test acc: [0.007760495413094759, 0.9960552453994751]\n"
     ]
    }
   ],
   "source": [
    "#indoor testset\n",
    "test_indoor_ds_results = model.evaluate(test_indoor_ds)\n",
    "print(\"test_indoor_ds_results:test loss, test acc:\", test_indoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 63s 2s/step - loss: 0.0770 - accuracy: 0.9824\n",
      "test_outdoor_ds_results:test loss, test acc: [0.07703875005245209, 0.9823529124259949]\n"
     ]
    }
   ],
   "source": [
    "#outdoor testset\n",
    "test_outdoor_ds_results = model.evaluate(test_outdoor_ds)\n",
    "print(\"test_outdoor_ds_results:test loss, test acc:\", test_outdoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 35s 2s/step - loss: 0.6430 - accuracy: 0.8805\n",
      "test_belt_ds_results:test loss, test acc: [0.6429727077484131, 0.880492091178894]\n"
     ]
    }
   ],
   "source": [
    "#belt testset\n",
    "test_belt_ds_results = model.evaluate(test_belt_ds)\n",
    "print(\"test_belt_ds_results:test loss, test acc:\", test_belt_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/10Freq_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read path of trained model\n",
    "import os, os.path\n",
    "trained_path = path_to_model\n",
    "models_paths = []\n",
    "for name_folder in os.listdir(trained_path):\n",
    "    if os.path.isdir(os.path.join(trained_path, name_folder)):\n",
    "        models_paths.append(os.path.join(trained_path, name_folder))\n",
    "models_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_105008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_191681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_110893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_210309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_210076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_109956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_222751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_223358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_214449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_215725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_227560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_204809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_219887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_105680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_109340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_217484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_107731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_169809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_114021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_226019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_112809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_206459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_112229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_226953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_104387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_110669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_200647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_105896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_219949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_222922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_104560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_115258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_115482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_203595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_208488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_104784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_227124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_110353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_220323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_196322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_108851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_105232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_107772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_113349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_107548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_197183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_198011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_114810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_109523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_200040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_221708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_108220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_106395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_201254) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_108128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_114469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_223965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_107298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_196089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_105100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_222144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_107507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_108668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_109248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_103814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_220930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_226626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_112005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_111796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_107108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_114153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_224805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_114428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_208255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_210683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_201861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_114902) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_227186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_205852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_112677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_216706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_113033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_203050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_111697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_203657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_111076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_109299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_107996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_207648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_104336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_105456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_226393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_104835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_225350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_228167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_214278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_103599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_111025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_104219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_216099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_112636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_109681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_108352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_113797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_216270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_207274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_209640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_109905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_115126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_106120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_225786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_108627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_110577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_207041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_198826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_221101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_197637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_216332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_103947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_113573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_112901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_197121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_217920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_216877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_110404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_107240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_212504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_114601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_106171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_224743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_218720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_175963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_113705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_223529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_104120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_113756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_209033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_79438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_111913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_202988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_199433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_105779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_111755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_213064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_111341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_204638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_104428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_199200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_221537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_107067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_218153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_205478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_106344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_220556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_110129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_209702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_115085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_214511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_211290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_202428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_218527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_106792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_107456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_196729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_199807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_113125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_115350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_111249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_201192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_201628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_109472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_212068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_112453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_105988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_225179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_107016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_209095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_105507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_113257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_105283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_212737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_206652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_198593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_108800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_113481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_107955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_113532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_115034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_109024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_104652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_215118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_109564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_198764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_106436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_209469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_204264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_219109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_104178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_106843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_228400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_111524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_221163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_222377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_211461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_103440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_114861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_110180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_106660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_108179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_106884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_207819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_115309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_113980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_114204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_109116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_208426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_110852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_201021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_210247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_213904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_213297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_111473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_212130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_110628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_109773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_109732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_215492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_219716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_108892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_217313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_207212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_105947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_107680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_104611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_112412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_114652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_219280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_110221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_223591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_215663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_203424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_103389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_113308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_108576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_213842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_211897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_110801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_224136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_222984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_111300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_103773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_112188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_113929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_114245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_204871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_212675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_110445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_103988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_224572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_206023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_103640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_213671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_205416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_105548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_109997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_107339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_112137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_111964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_216939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_222315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_228774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_205245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_106212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_200414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_210916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_210854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_226564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_112361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_105324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_207881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_208862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_204031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_217546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_198266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_196260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_201799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_108403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_103481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_185549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_204202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_108444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_202235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_228338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_105738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_219342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_218091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_202817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_227731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_211523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_112860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_227793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_196667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_104876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_114377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_206714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_224198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_111117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_225957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_214885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_198204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_206085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_197575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_213235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_220494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_215056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_113084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_114693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_199371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_200585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_112585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_105059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_106619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_111565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_106568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_225412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_218782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_199978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_221770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_107904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_109075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_202490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0130 - accuracy: 0.9961\n",
      "32/32 [==============================] - 58s 2s/step - loss: 0.0780 - accuracy: 0.9775\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3956 - accuracy: 0.8963\n",
      "Epoch200 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.977450966835022 \n",
      " test_belt_acc=0.8963093161582947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_394706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_400962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_292917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_291225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_408828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_299390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_288718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_292535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_410042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_395546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_290072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_395313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_288626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_405186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_403390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_295906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_291897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_294261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_391260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_299838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_289665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_412797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_299614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_300139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_412361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_398301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_291016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_397134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_396091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_289797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_405124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_294760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_296130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_413404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_291632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_406400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_390046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_296354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_393492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_399079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_385651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_296537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_297201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_292029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_290337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_393725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_294709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_295010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_300271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_406945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_403957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_394332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_298769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_289357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_299482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_410416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_398534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_291184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_396760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_409980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_392449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_386429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_385884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_298138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_406774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_293416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_288677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_293233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_298718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_295458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_400293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_403764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_388661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_297242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_296710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_399748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_289051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_299889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_402550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_396527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_294353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_376918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_297649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_402783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_290296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_290693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_300719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_290561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_290744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_388832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_297374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_391889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_298993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_407614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_293457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_401336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_299930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_386865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_388287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_390653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_412423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_390108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_292345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_292576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_400729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_297598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_299706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_411630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_300047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_400900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_388225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_294801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_403157) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_394270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_298097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_393056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_289848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_300495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_404579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_294485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_389268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_291673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_290021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_300322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_401507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_385215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_396153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_297150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_296761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_294088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_293813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_295641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_411801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_297033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_298321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_297873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_382812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_293365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_409809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_298494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_412968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_383830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_290113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_299665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_299166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_381904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_295417) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_404346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_397741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_294129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_294536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_300546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_296992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_298942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_299217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_387098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_290785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_397974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_293009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_292744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_291408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_292785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_407552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_291133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_397912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_291805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_298046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_361200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_409202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_355046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_409373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_292968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_290245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_299258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_295682) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_387727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_407988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_382874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_387472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_290975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_400122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_406338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_398908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_293192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_292253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_289010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_292693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_296038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_289573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_292121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_289456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_288877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_392511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_381497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_411863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_289184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_294577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_381559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_289415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_402114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_411194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_396698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_294969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_296934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_298270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_399141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_413575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_381326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_382420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_410649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_391089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_411023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_408595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_295865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_389875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_297425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_289225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_400355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_298810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_290469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_412190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_387036) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_386491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_293864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_409435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_385044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_413030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_405560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_389439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_394877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_300587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_297466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_297914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_300363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_264675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_384608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_399515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_383503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_395484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_403328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_388894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_394099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_293905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_292477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_291856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_399686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_402176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_297822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_383248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_397367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_414011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_298362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_404517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_384437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_408221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_405793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_387665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_381966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_404953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_405731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_296578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_299441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_388054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_298545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_294918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_370786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_392278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_382358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_393118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_296262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_295590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_406167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_293589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_384001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_385822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_390715) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_390482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_391951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_385277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_295193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_294037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_411256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_407381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_384670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_293681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_289624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_386258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_296486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_291581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_398472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_293141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_389501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_407007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_298586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_295366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_391696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_296802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_392885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_297690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_413637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_295142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_292304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_292080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_294312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_293640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_395920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_291449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_290520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_410587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_295234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_384063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_296313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_408159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_299034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_404019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_291357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_288836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_290917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_408766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_295814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_391322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_394939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_397305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_296089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_383441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_289889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_401943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_402721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_393663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_401569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_300098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0117 - accuracy: 0.9961\n",
      "32/32 [==============================] - 58s 2s/step - loss: 0.0693 - accuracy: 0.9814\n",
      "18/18 [==============================] - 33s 2s/step - loss: 0.4432 - accuracy: 0.8875\n",
      "Epoch400 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9813725352287292 \n",
      " test_belt_acc=0.8875219821929932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_476235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_485541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_481573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_583520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_485266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_592164) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_474229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_481797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_577108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_588547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_485358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_474055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_584127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_571041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_577730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_594421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_485490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_584298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_597409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_598016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_597020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_474270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_479704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_474675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_482153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_581917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_571710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_474634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_595261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_595635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_476194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_568031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_583753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_480137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_589736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_481532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_475556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_568722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_578944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_587333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_485714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_477912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_579925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_576541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_588376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_449894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_598856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_484477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_586181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_474884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_484925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_479796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_576308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_590172) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_475464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_480453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_583131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_480809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_584967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_481929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_479348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_480860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_573444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_589798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_476004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_485582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_596849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_584905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_570434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_577170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_572946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_475739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_587162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_585512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_478900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_572084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_581372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_477472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_580532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_571648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_484884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_596242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_481980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_574658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_479572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_571103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_577668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_484833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_476136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_599230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_478411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_593814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_482461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_581139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_483581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_479307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_480677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_570496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_586726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_568093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_569049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_569220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_485765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_478360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_591386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_479124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_567123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_478808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_567577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_473896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_477754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_477696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_480901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_593207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_479256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_478859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_587395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_479032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_484609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_594047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_580158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_480229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_575701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_580703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_477299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_483316) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_582353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_582960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_573506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_475067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_562137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_569656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_588609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_475515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_546419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_584360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_572317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_475780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_568467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_592833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_478635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_478004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_474444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_583193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_479755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_477024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_597642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_485806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_567639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_576479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_581310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_568660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_476668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_596413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_597082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_593985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_593440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_474843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_484253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_480361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_597580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_566545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_475912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_483092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_585948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_474792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_589176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_479928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_481756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_478228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_483805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_484385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_481125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_483489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_483540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_592226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_479979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_579551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_581979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_595199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_573273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_587769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_576915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_483988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_482420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_483133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_477795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_479531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_596475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_582524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_591619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_476851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_586119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_569827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_477564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_575094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_478676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_588002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_595806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_595868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_591993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_476403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_475291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_482868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_480412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_595028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_479480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_566778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_484161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_477523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_482817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_475332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_580765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_584734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_483937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_479083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_480636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_574720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_572884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_484436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_478187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_482021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_483713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_574487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_591012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_579318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_474403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_569282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_476892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_482644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_481705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_475963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_475108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_484029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_485057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_482593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_484701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_577497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_482369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_477075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_571477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_476444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_481257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_481308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_586555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_593378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_483764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_573880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_480188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_476576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_589565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_598794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_485938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_574051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_481033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_572691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_477963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_590343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_588983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_481481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_482211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_540265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_578882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_591557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_482252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_569889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_598623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_483041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_575265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_580096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_590779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_587940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_480585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_483265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_575327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_477340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_574113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_578275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_578104) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_484660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_485317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_476352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_475240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_473937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_594592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_485149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_478452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_485108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_484212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_481084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_481349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_477248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_476800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_579489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_590405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_475016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_585574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_570870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_570263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_474096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_566716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_483357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_586788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_482685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_482909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_598249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_590950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_598187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_578711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_477116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_478584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_475688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_572255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_594654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_575934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_585341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_582586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_583691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_474576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_589238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_480020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_473845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_578337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_592771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_575872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_478136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_581746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_592600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_567185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_476627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_556005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0095 - accuracy: 0.9961\n",
      "32/32 [==============================] - 57s 2s/step - loss: 0.0657 - accuracy: 0.9824\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.4799 - accuracy: 0.8858\n",
      "Epoch600 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9823529124259949 \n",
      " test_belt_acc=0.885764479637146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_664137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_662485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_780265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_757554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_660925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_669897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_666993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_669622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_755671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_771418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_662088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_670121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_755500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_667606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_671002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_662933) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_770578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_752360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_763948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_781650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_774475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_769971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_660121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_776794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_765769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_667657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_662261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_664045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_665165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_659133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_662991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_663821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_776187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_771963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_669846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_778677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_760331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_768757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_661681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_755126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_664941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_777401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_779051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_764119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_663465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_663373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_670294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_758743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_782319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_659466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_759350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_757321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_666046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_769535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_782879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_779222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_763341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_759895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_663241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_668105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_752015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_766002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_670819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_773613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_670595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_783424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_776249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_760938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_755733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_758121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_660528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_758510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_660304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_751782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_784031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_663689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_766376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_767216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_761171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_660701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_660793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_669001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_661431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_666138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_725502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_780436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_663597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_773239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_659640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_666494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_669449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_666097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_666810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_666586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_731656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_766609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_767823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_779891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_776623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_754286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_670554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_777837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_756107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_669673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_761716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_762152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_667390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_668594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_758183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_668146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_666362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_668950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_765333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_755064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_778070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_782646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_753330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_751953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_752876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_665466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_773846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_767154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_662801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_661149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_662709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_775642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_759724) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_756278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_668726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_663032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_669938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_775580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_783860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_761545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_779284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_752814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_669225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_760502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_753897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_776856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_670778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_667922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_665425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_666545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_772632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_762345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_659681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_754457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_783253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_765395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_660569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_668054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_780872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_770749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_635131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_668370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_774973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_753268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_766547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_777463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_661589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_780498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_666270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_756714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_762407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_782817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_662536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_756885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_667448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_669174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_768368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_659333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_669398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_770204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_667217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_661373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_756340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_667830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_760564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_662037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_779829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_768430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_778444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_670503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_775409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_659292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_661640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_665873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_665914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_781105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_663913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_660345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_772025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_753704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_762734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_753959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_664992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_768928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_767590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_758681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_669714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_774802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_667489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_769597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_670162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_766983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_762967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_764555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_660080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_661905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_764788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_663648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_747374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_764726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_665649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_776016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_777230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_670386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_768990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_762905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_759288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_669490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_660976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_784093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_773784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_778008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_773006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_660477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_664493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_665257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_761778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_741242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_668329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_759957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_661864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_773177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_778615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_667698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_670345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_664717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_772570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_659174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_764181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_667881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_665822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_774413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_664768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_661813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_771356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_667258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_759117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_663872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_768197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_662129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_667166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_665216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_666769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_662312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_771792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_784467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_774220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_663149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_775035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_659082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_661017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_765162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_669266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_659912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_665690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_670070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_668818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_781712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_761109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_664320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_664809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_770142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_661200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_666321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_664544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_665374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_757928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_779658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_667034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_757492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_663200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_659871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_765940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_668553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_665033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_660752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_752422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_767761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_660029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_661241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_661472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_781043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_662577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_663424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_781479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_772399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_664585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_769364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_782257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_754519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_671175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_671043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_664361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_763574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_670951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_668278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_668777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_666718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_666942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_756947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_664096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_670727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_662760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_770811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_665598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_771185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_668502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_662353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_659813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_660253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_659507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_664269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_783486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_782086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_754893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_669042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_763512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0110 - accuracy: 0.9961\n",
      "32/32 [==============================] - 57s 2s/step - loss: 0.0665 - accuracy: 0.9824\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.5237 - accuracy: 0.8858\n",
      "Epoch800 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9823529124259949 \n",
      " test_belt_acc=0.885764479637146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_854503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_938567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_848610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_937190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_968490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_850229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_846709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_849333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_945801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_946346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_948749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_939134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_854951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_943747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_853963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_846610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_820368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_854859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_950025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_966949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_855740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_847101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_944354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_849730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_848834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_957869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_854727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_952827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_848478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_947971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_855964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_937597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_853067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_846918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_852495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_849150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_850886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_845765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_962700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_851823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_845358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_845149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_949418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_954772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_939196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_850611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_846162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_952220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_961253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_957029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_945568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_845989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_855134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_967323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_969268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_939756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_856056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_849954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_960817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_848437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_963681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_963074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_953605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_944587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_951846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_926479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_961486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_845714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_965502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_944525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_960210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_946953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_937019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_946175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_846668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_844918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_954834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_853159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_844411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_845108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_847997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_968723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_963852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_964459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_940363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_939694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_851558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_845050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_959083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_948142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_846437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_851283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_943420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_851110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_851375) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_956593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_949185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_968054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_966716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_960646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_960039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_853515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_942791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_941515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_853790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_855399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_959650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_949963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_844703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_964895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_852627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_854055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_848661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_847325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_848038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_947582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_854411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_945132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_848885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_846386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_962467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_953060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_966342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_848926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_852230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_958243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_952391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_966280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_965128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_910739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_956655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_845317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_852685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_851782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_848386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_851507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_850453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_845490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_849822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_939523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_955379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_963307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_852454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_952998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_848228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_951613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_849598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_962031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_850703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_854187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_937659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_943165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_940737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_853291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_940130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_849781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_952453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_855582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_958850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_847498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_850494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_847366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_856015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_947015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_852726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_846213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_849109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_942184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_845938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_853566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_847549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_853383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_847590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_957636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_953994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_856412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_960879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_947644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_951006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_942729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_844529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_959457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_967556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_850270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_940908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_954165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_966887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_853739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_852935) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_951177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_850046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_965066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_849557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_846478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_855307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_916893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_850927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_950632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_855358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_958476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_847050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_945739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_957200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_853831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_855175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_955815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_948204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_855623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_852047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_955986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_846826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_948578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_846030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_851599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_961424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_845806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_955208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_938051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_959021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_852179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_852843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_855791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_844319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_968116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_941577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_856280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_937252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_846254) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_965673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_855531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_854014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_845266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_946408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_851955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_847773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_945194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_944961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_849506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_938941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_844877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_852403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_942122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_851059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_852894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_968661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_960272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_854686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_851334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_953667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_854635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_958414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_847814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_957807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_943980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_941951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_846877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_959712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_845541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_951239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_948811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_962638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_951784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_850402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_855083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_964521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_954601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_854910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_855832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_947389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_848170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_957262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_853118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_956048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_965735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_848702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_849058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_950399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_969097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_941344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_856239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_848269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_856188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_949356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_849374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_962093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_849282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_850662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_955441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_940970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_851151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_844370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_852271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_852006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_845582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_967883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_942558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_940301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_851731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_969330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_847274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_946782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_847142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_847722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_953434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_963245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_853342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_854462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_854238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_850178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_943918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_938505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_853607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_938113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_963914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_943358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_964288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_854279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_850835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_954227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_969704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_850005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_844570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_949792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_847946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_956422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_966109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_844744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_950570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_967494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_932611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_961860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0095 - accuracy: 0.9961\n",
      "32/32 [==============================] - 57s 2s/step - loss: 0.0669 - accuracy: 0.9824\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.5500 - accuracy: 0.8875\n",
      "Epoch1000 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9823529124259949 \n",
      " test_belt_acc=0.8875219821929932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1140009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1033623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1032511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1037640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1149758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1038080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1136414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1133986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1032735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1029807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1036744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1039740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1030345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1126814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1146661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1030503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1138297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1030386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1041069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1029607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1143106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1151517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1130805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1133379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1130198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1041476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1122427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1033234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1032562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1041293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1123742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1147704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1036571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1039648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1129155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1033847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1136476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1034570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1144887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1135636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1037243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1139464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1037864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1040371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1030155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1126145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1133208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1139402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1035639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1037060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1137690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1136243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1150132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1131038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1038976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1138671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1034295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1040636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1140071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1037019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1122896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1134048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1134655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1032287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1035466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1140678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1137083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1151953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1153353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1149525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1040096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1140445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1034163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1033183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1032338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1146116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1036164) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1034967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1135029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1129217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1040320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1111716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1154567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1152186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1037732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1144258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1031847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1154505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1038803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1147875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1131412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1144320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1152124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1142437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1137457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1146054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1143651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1039475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1041028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1039964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1141285) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1152793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1031450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1135200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1035018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1037691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1138904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1150972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1140616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1128595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1131645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1030595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1127421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1135262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1129824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1124931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1031946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1145509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1117848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1135869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1038528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1032063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1036296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1148918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1148311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1139231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1031043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1038355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1031399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1036836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1147268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1132252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1137021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1133815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1039699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1035415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1036795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1032114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1031002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1033674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1142873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1153960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1136850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1030287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1124433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1041252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1127966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1123288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1041649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1095976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1039424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1036123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1030951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1138064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1127795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1148482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1154334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1035848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1141659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1040860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1128984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1037284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1040188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1037416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1125538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1038396) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1032786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1128402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1038620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1141052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1037922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1031267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1147937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1131583) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1031623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1123804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1035283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1029556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1033506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1125600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1125367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1030727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1032603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1144694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1150910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1132019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1037192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1149151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1147097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1124760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1126752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1037467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1034794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1037508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1135807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1130369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1035242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1031715) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1137628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1034387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1130976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1040819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1144087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1150303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1138235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1040977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1124371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1032155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1037963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1036388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1033939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1039251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1139838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1038172) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1128657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1143480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1032379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1036968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1145883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1147330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1149089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1029981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1035507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1005605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1142499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1143044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1146723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1031226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1130431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1035690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1153291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1038304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1039872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1029648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1154941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1040412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1124993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1035059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1031491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1029940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1034519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1153898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1153120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1146490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1148544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1033051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1039200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1032959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1033010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1142266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1126581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1041517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1133441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1151579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1033898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1034743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1034071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1040147) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1134593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1102130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1035191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1035940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1029766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1129762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1039292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1030554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1141892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1041425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1126207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1040768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1127359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1122256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1031905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1033275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1123350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1132190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1038579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1150365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1132881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1036347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1033715) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1125974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1129591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1128028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1141830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1036072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1041201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1150739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1034835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1033407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1149696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1032827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1034611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1034346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1040544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1035731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1151346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1145276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1143713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1152560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1039027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1031175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1144949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1039923) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1122489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1036612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1038752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1124178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1153727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1127188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1145447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1039516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1034122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1030114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1132626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1038131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1033465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1038844) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1132819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1141223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1035899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1030778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1152731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1138842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1031674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1040595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1134422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1036520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1122834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1039068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1030819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0070 - accuracy: 0.9961\n",
      "32/32 [==============================] - 57s 2s/step - loss: 0.0692 - accuracy: 0.9804\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.5916 - accuracy: 0.8787\n",
      "Epoch1200 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9803921580314636 \n",
      " test_belt_acc=0.8787346482276917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1219980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1224753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1311211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1216952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1219807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1221757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1216687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1316820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1214793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1223368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1218743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1226530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1327503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1325853) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1335602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1328343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1318118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1215218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1321480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1320266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1315061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1319052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1327067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1324141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1220520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1338528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1336209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1332567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1318616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1322258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1221584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1333548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1218512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1331353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1281213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1226306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1331898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1225425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1287367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1219583) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1219176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1214844) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1329324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1330124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1217392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1226662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1225109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1316275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1226489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1226886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1219135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1330186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1337968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1315435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1339571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1215623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1218023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1224885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1215392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1221360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1339742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1330513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1220428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1320437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1321651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1334388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1218860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1331960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1313894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1219848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1216728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1313265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1218911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1322865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1311989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1333781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1323472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1326522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1313832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1324468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1216412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1328110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1226265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1321044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1225832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1314221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1326289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1336754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1215524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1220031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1317427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1316213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1309415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1333174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1220703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1322087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1311382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1315606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1224712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1223765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1223592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1319659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1331120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1328717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1222256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1224213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1217575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1219400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1296953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1224977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1225160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1320873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1215177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1312051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1220255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1325246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1222073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1316882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1225781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1329557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1324079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1216860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1309608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1225608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1314828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1324701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1331291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1312425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1314454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1217748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1215791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1226005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1222297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1315668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1330684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1327736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1309997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1217300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1219084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1218471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1221849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1319830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1224488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1303085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1218196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1338590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1317863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1218247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1218644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1222032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1312658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1313639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1225201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1308979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1223409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1316042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1310837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1216056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1317489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1325308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1312596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1326896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1323908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1318678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1332505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1334995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1333112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1216015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1219624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1226754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1218064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1313203) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1223317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1217351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1337361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1222480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1222704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1329931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1223989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1308133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1223633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1335369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1224661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1337190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1224264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1215832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1322694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1338964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1218420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1334933) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1220876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1224081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1221981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1336816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1215003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1226713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1314999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1219756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1328281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1322320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1190842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1216911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1318056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1328888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1218702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1310604) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1320499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1217616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1221401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1221085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1219359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1321106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1334155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1338357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1310230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1221625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1220968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1339804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1330746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1222928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1215964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1327129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1337423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1222653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1336583) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1221533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1308525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1307664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1222969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1219308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1226097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1224936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1319892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1220652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1220744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1317256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1216463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1216239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1220296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1309041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1226438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1335976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1225384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1220479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1322927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1220927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1217972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1224437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1221177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1325915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1223857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1323534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1218952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1326460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1221309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1339197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1340178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1217142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1217183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1225557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1215582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1216280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1308071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1221808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1335540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1328950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1333719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1313032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1329495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1217799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1219532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1222521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1311444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1308587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1324639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1215351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1307726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1331727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1225333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1226056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1217084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1334762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1334326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1318445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1222877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1319223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1223816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1224529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1217840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1336147) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1314392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1221136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1325682) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1224305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1222205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1338030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1220072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1226214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1217524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1216636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1327674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1216504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1215044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1337797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1216188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1307493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1311818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1310775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1223159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1319285) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1332334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1339135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1323301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1225873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1325075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1225649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1215740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1223541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1309670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1222429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1321713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1316649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1332941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1224040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1223101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1223200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1220204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1214885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1222745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1310168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1218288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0085 - accuracy: 0.9980\n",
      "32/32 [==============================] - 57s 2s/step - loss: 0.0682 - accuracy: 0.9833\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.5610 - accuracy: 0.8840\n",
      "Epoch1400 \n",
      " test_indoor_acc=0.9980276226997375 \n",
      " test_outdoor_acc=0.9833333492279053 \n",
      " test_belt_acc=0.8840070366859436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1504448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1522648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1503903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1524189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1502652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1410782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1408102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1407878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1511514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1404533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1518399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1408593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1403248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1404360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1401637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1409041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1410161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1510533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1499617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1511078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1523815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1515349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1402800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1401861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1511140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1403024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1511747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1515738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1495393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1503281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1497043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1498490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1405704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1410385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1512354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1500660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1510300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1409886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1410650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1514549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1506876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1404136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1411938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1411663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1493358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1514113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1402085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1512899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1404757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1400402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1517792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1519380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1408858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1410874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1507545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1401240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1403289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1407746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1508759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1492718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1514782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1500053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1520827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1411490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1506938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1411230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1410202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1410609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1520158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1400228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1521201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1407033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1405928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1405653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1403472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1512961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1406534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1520220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1406310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1497276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1509133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1401189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1410334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1504510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1407970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1523193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1521808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1405297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1503670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1516516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1408384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1408153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1494204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1409082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1405521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1408634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1401016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1519613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1409306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1505491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1523753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1409754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1501500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1524360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1402525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1401413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1492889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1411714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1408425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1506705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1522041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1518337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1515971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1505662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1406361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1411887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1505055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1503841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1494640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1518944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1400443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1493750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1400617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1401729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1407074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1522586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1403927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1518773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1508152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1515156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1403197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1405073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1518166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1524422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1517123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1403513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1508090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1507312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1502107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1401688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1512728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1400807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1402136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1499446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1494895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1514720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1509366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1411322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1495829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1406626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1406101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1400110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1520594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1507919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1501438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1402367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1502714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1523582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1497883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1497650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1407206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1403421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1507483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1516345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1407257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1404981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1506098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1400848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1513568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1407298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1520765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1402408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1506269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1506331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1497214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1515411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1496669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1519987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1472592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1510907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1403065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1409713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1515909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1410110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1509693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1499679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1500286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1406585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1519006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1376067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1400269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1409489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1508697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1407481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1513942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1517730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1405969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1508526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1493296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1519551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1499119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1497821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1516952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1409978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1404401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1517185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1402749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1402973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1410833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1496000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1495455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1504884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1500831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1524967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1411755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1499057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1513335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1408817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1409662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1501267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1403968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1409937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1408326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1512121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1512292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1410426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1408766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1404584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1411281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1496436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1509304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1404085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1411439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1405877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1406152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1521434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1403737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1505117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1496062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1524796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1402177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1521979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1498257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1407929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1412111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1521372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1402841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1509864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1502045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1405745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1501874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1405256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1405032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1514175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1410558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1509926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1411979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1408194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1495222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1409265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1400576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1406850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1404177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1488310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1498864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1411057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1503088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1405480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1492951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1405429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1409438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1407654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1407430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1523022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1407705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1406758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1525029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1401505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1400749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1511685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1401057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1523255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1401912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1522415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1411006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1500224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1402576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1402309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1405205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1403645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1404849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1409214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1404309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1408990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1400069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1517559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1411098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1408542) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1525403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1411531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1498428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1513506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1493812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1505724) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1466438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1496607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1403869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1494833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1406809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1406193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1406982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1494266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1504277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1400018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1401281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1510471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1401953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1400965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1482178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1403696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1502481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1406402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1500893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1402617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1503343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1404625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1516578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1409530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1404808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1401464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1407522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0071 - accuracy: 0.9961\n",
      "32/32 [==============================] - 58s 2s/step - loss: 0.0676 - accuracy: 0.9824\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.6221 - accuracy: 0.8805\n",
      "Epoch1600 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9823529124259949 \n",
      " test_belt_acc=0.880492091178894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1699957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1681844) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1686130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1681906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1585506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1700648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1585639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1703403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1595174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1690121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1594278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1700586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1585813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1693763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1587813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1590534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1684356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1593871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1595215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1591863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1710033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1702967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1591430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1706438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1590666) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1687111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1589322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1594502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1592535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1590941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1705457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1592311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1696315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1686068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1594950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1590218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1587762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1597348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1594054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1688518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1587098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1596243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1592219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1590269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1689140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1704243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1686504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1706064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1594543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1594767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1586742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1667415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1596467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1698805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1588750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1592891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1596019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1699179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1589164) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1589994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1697965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1690961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1591771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1697529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1591389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1591206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1692720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1690292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1686675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1679877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1588658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1597124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1587373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1700975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1595123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1707278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1593115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1594726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1687718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1699412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1684854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1587986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1690899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1594991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1589638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1588078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1693389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1704010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1700019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1708990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1586874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1689514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1697358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1587604) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1685461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1684916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1586701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1588882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1707045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1593779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1690354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1698572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1586253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1588933) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1587414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1694541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1683494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1682451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1694603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1594003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1706671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1587149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1681673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1680459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1586477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1686737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1696751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1688580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1587546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1683665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1706609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1683727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1695537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1586966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1679049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1593662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1683120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1591995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1594319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1678126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1702360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1699786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1592087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1585680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1678188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1593431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1707216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1701815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1693156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1596518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1596335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1709052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1596768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1702422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1691506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1704788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1704181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1704850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1595846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1708492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1586518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1585347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1590442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1678533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1595398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1595347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1589106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1590758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1592718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1595795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1708259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1708819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1707885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1595663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1705831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1590890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1592046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1589373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1590310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1702796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1683058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1705224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1594675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1695708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1590717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1703636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1595622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1561304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1682887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1705395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1596727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1585986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1590045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1592494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1688907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1586294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1685290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1677955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1588210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1682280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1593621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1687889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1595439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1589597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1594899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1701582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1588485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1593563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1693327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1587190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1692549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1687344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1707652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1593830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1591165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1586202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1699350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1595571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1597216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1701208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1591822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1710204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1688325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1596294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1585255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1703574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1588434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1682513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1680630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1694930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1706002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1710640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1586426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1585465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1701753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1589546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1591338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1695770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1585854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1694370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1589205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1596900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1691568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1698743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1684294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1696377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1696144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1592667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1709426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1707823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1590982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1657829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1698198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1708430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1588526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1592759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1594451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1691335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1586650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1678595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1704617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1687282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1596676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1681237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1673547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1692113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1709597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1681066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1703029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1587854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1680132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1691942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1590493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1693934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1685897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1591598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1593339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1586085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1698136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1696984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1701146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1651675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1695101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1684101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1591547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1596111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1709659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1586925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1596070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1588261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1593390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1596559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1592942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1596951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1679441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1687951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1692782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1592443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1592270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1589862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1689685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1710266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1597175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1693996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1690728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1588709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1696922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1680070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1594227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1679503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1681299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1591639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1678987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1589770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1595887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1596992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1590086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1593207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1697591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1593166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1585306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1684683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1586044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1591114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1594095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1589414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1588974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1702189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1689747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1592983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1700393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1589821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1680692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1588037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1587645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1588302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1685523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1689078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1587322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1695163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1692175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 33s 2s/step - loss: 0.0063 - accuracy: 0.9961\n",
      "32/32 [==============================] - 58s 2s/step - loss: 0.0696 - accuracy: 0.9833\n",
      "18/18 [==============================] - 33s 2s/step - loss: 0.6356 - accuracy: 0.8770\n",
      "Epoch1800 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9833333492279053 \n",
      " test_belt_acc=0.8769771456718445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1774610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1873188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1895270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1868731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1777507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1779556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1881988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1773274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1772559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1891846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1877350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1777772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1779688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1872955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1892889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1775455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1779780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1770743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1776575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1770917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1775007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1863425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1882828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1775547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1782137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1891301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1867750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1777324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1867688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1775771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1890025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1782412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1779067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1884587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1778128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1864224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1779240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1869593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1870760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1780004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1895877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1780360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1874922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1779016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1889480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1881614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1865307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1886212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1882159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1781572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1778352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1779963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1779739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1772783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1885023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1779291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1871134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1779108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1772335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1880945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1887426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1867081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1875529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1781032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1864678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1774211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1890087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1777904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1778668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1775903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1885823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1885256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1865929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1771439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1874751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1891239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1865369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1880774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1777456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1746541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1895503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1879607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1778220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1775506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1772999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1866303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1892453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1887052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1876136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1877412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1876198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1874377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1894834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1889247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1781480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1880338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1873755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1884042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1777100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1770492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1777680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1866536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1879778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1893122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1894663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1777059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1883980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1778800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1777731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1771281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1770876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1778899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1774875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1777008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1893060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1863192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1884649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1774343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1781256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1780859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1779515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1781964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1868964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1772162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1893729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1877957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1895441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1890461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1864286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1780900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1771979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1876805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1771714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1873817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1781083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1782361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1878393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1868902) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1780676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1888266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1875965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1780635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1770702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1774651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1894289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1781124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1777996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1773987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1891068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1774401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1874315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1776626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1870091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1772427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1782229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1869338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1773895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1775954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1772610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1780228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1782188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1868124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1894227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1875591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1773223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1778444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1892515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1781348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1871974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1836912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1780187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1777548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1782585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1865114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1869531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1888811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1887659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1893496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1872348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1863832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1875358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1886383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1781307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1886819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1889418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1885885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1883202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1775323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1781704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1885194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1774834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1773539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1778179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1883435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1776219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1778627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1873126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1771223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1774170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1775099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1772882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1782453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1873562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1773671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1773315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1771755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1867517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1876743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1771322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1880167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1864740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1773763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1843066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1770584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1776443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1881552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1773091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1780452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1772841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1872581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1892282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1779332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1880400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1868357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1774119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1779464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1891908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1780411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1774559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1879840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1781755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1778403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1771490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1866910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1877786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1871367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1879171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1852652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1780584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1773498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1858784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1770543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1863363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1888640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1776667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1775679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1879233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1780136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1771887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1870153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1877179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1888873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1772386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1870698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1772203) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1773447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1776784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1883373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1881007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1882766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1887597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1771663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1776127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1778858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1890632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1874144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1774442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1775231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1890694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1886990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1878626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1773050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1773722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1878564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1772111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1866474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1865696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1888204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1782005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1869920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1781913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1775058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1881381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1775995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1894896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1774783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1775282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1884416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1771531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1776351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1781796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1878019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1882221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1871912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1888033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1773946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1883809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1867143) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1771050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1777283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1771091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1781531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1872519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1889854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1871305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1871741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1780808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1891675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1776876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1775730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1776835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1886445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1863770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1882595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1870527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1776402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1777955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1874984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1778576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1894056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1779912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1876572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1777232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1868295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1893667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1772651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1771938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1776178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1885630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1865867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1879000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 42s 2s/step - loss: 0.0078 - accuracy: 0.9961\n",
      "32/32 [==============================] - 58s 2s/step - loss: 0.0770 - accuracy: 0.9824\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.6430 - accuracy: 0.8805\n",
      "Epoch2000 \n",
      " test_indoor_acc=0.9960552453994751 \n",
      " test_outdoor_acc=0.9823529124259949 \n",
      " test_belt_acc=0.880492091178894\n"
     ]
    }
   ],
   "source": [
    "test_indoor_acc = []\n",
    "test_outdoor_acc = []\n",
    "test_belt_acc = []\n",
    "test_indoor_loss = []\n",
    "test_outdoor_loss = []\n",
    "test_belt_loss = []\n",
    "\n",
    "for lm_idx,plmodel in enumerate(models_paths):\n",
    "    loaded_model=tf.keras.models.load_model(plmodel)\n",
    "    ## -> keep loss / acc in each epoch\n",
    "    #indoor\n",
    "    test_indoor_results = loaded_model.evaluate(test_indoor_ds)\n",
    "    test_indoor_loss.append(test_indoor_results[0]) # append loss\n",
    "    test_indoor_acc.append(test_indoor_results[1]) # append acc\n",
    "    #outdoor\n",
    "    test_outdoor_results = loaded_model.evaluate(test_outdoor_ds)\n",
    "    test_outdoor_loss.append(test_outdoor_results[0]) # append loss\n",
    "    test_outdoor_acc.append(test_outdoor_results[1]) # append acc\n",
    "    #belt\n",
    "    test_belt_results = loaded_model.evaluate(test_belt_ds)\n",
    "    test_belt_loss.append(test_belt_results[0]) # append loss\n",
    "    test_belt_acc.append(test_belt_results[1]) # append acc\n",
    "    # printout\n",
    "    lm_idx_show = (lm_idx+1) * save_model_interval\n",
    "    print(f\"Epoch{lm_idx_show:03d} \\n test_indoor_acc={test_indoor_acc[lm_idx]} \\n test_outdoor_acc={test_outdoor_acc[lm_idx]} \\n test_belt_acc={test_belt_acc[lm_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "test_avg_acc = []\n",
    "for i in range(len(test_indoor_acc)):\n",
    "    tmp_avg = (test_indoor_acc[i] + test_outdoor_acc[i] + test_belt_acc[i]) / 3.0\n",
    "    test_avg_acc.append(tmp_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(200, 2200, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Testing(EvaluationModel) Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss / acc in each epoch graph ploting\n",
    "#EPOCHS = 400\n",
    "import matplotlib.pyplot as plt\n",
    "epochs_range = range(save_model_interval,EPOCHS+save_model_interval,save_model_interval)\n",
    "print(epochs_range)\n",
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, test_indoor_acc, label='IndoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_outdoor_acc, label='OutdoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_belt_acc, label='OnConveyorBeltDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_avg_acc, label='Average Tesing Accuracy',linewidth=3)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Testing(EvaluationModel) Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max acc -> 0.9566051761309305\n",
      "max index -> 0\n",
      "The [Epoch] of max acc -> 200\n"
     ]
    }
   ],
   "source": [
    "#Find Max Index and Value\n",
    "print(f\"max acc -> {max(test_avg_acc)}\")\n",
    "max_index = test_avg_acc.index(max(test_avg_acc))\n",
    "print(f\"max index -> {max_index}\")\n",
    "print(f\"The [Epoch] of max acc -> {(max_index+1)*save_model_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAATbCAYAAAAOI6VQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACgTElEQVR4nOzdd3iN9//H8dedQRYhsfcmi9h7tIrSVs2q6kBbuocq+rVXF0V10WFVN906UDXa2gSJvfcK2Tv5/P5I5GcLwp3kPB/XlYtzzj1e50468rre9+dYxhgBAAAAAAAgb3OyOwAAAAAAAABuPUogAAAAAAAAB0AJBAAAAAAA4AAogQAAAAAAABwAJRAAAAAAAIADoAQCAAAAAABwAJRAAADgiizLirEsq1I2HauoZVnbLctyz47jXeU8syzLGneLjt3LsqyFt+LY2cGyrN6WZf2TxW0zr5NlWTUty/rv1qYDAAB2owQCACCXyihozn2lWZYVf97jXjdwvKWWZT1x/nPGGC9jzN5sijxE0ixjTPx550u46H38kk3nummWZVWwLMtYluVy7jljzBfGmLbZeOyNFz1fxLKsJMuy9t/sOa6HMWazpAjLsu670jaX+/kAAAC5CyUQAAC5VEZB42WM8ZJ0UNJ95z33hd35zmdZVn5Jj0mae9FLz53/PowxVywh8igPy7ICz3v8kKR9NmX5QlJ/m84NAABuA0ogAADyGMuynCzLGmJZ1h7LssIty/rWsiyfjNfcLMuam/F8hGVZay3LKm5Z1nhJzSW9nzGR837G9sayrCoZf59lWdYHlmUtsCwr2rKs1ZZlVT7vvG0ty9phWVakZVkfWpa17LzJkYaSIowxh7P4HrZZlnXveY9dLMs6ZVlWnYzH31mWdTzjXMstywq4wnEuuT3qovd0j2VZGy3LirIs65BlWaPO23R5xp8RGdek8cXHsyyrScY1jMz4s8l5ry21LGusZVn/ZlyvhZZlFbko4udKL8fOeVTSnIvy+mUcK8KyrDDLsjqe95qvZVk/Z+RfI6nyRfvWsCxrkWVZZzK+Nw9c7jplWCqpdUZhl2UZP2/DLMs6YFnWScuy5liW5Z3x2mV/3jJe621Z1t6Ma7PvRqbXAADA9aEEAgAg73leUidJLSWVknRW0gcZrz0myVtSWUm+kp6SFG+MGSpphf5/Mue5Kxz7QUmjJRWWtFvSeCn9NiZJ8yS9lnHcHZKanLdfUMZzWfWVpJ7nPW4n6bQxZkPG498lVZVUTNIGpU+x3IhYpRcvhSTdI+lpy7I6ZbzWIuPPQhnXZOX5O2YUawskTVX6e54kaYFlWb7nbfaQpD4ZOfNJGnjR+edKetCyLGfLsvwleUlafd45XCX9ImlhxjGel/SFZVnVMzb5QFKCpJKS+mZ8ndvXU9IiSV9m7PugpA8zznMJY8wRScmSql/u9avonfF1h6RKGe/h/YzXLvvzlpFtqqT2xpgCSv9ZCbnO8wIAgOtECQQAQN7zlKShxpjDxphESaMkdctY2yZZ6b+MVzHGpBpj1htjoq7j2D8YY9YYY1KUXrwEZzzfQVKYMeb7jNemSjp+3n6FJEVf5nhTMyZEzn2NzXj+S0kdLcvyyHj8kNKLIUmSMWaGMSb6vPdX69z0yfUwxiw1xmwxxqRlrIvzldLLs6y4R9IuY8znxpgUY8xXkrZLOv+WtpnGmJ0Z6yB9q/+/XuccVno5dpfSy6jPL3q9kdJLlTeNMUnGmCWSfpXU07IsZ0ldJY0wxsQaY0IlzT5v33sl7TfGzMzIt1HSfEndr/KeopX+vboevSRNMsbsNcbEKL0IfDALP29pkgIty3I3xhwzxoRd53kBAMB1ogQCACDvKS/ph3PFiqRtklIlFVd6yfCnpK8tyzpqWdbbGdMmWXV+sROn9IJCSp84OnTuBWOMUXrBcc5ZSQUuc7wXjDGFzvsanrH/7ozc92UUQR2VXgwpY2rmzYzb3aIk7c841sW3Wl2TZVkNLcv6O+NWs0ilF2hZPU4pSQcueu6ApNLnPb7S9TrfHKVP0vTUpSVQKUmHjDFplzlHUUkuOu+6X5SnvKSG55dsSi9sSlz5LamApIirvH45F1+HAxm5rvjzZoyJldRD6df7WMYthjWu87wAAOA6UQIBAJD3HFL6bTbnlytuxpgjxphkY8xoY4y/0m/BuVfpEyiSZG7inMcklTn3wLIs6/zHkjZLqnadxzx3S9j9krZmFENS+lTQ/UqfnvGWVOHcaS9zjFhJ56aJZFnWxQXIl5J+llTWGOMtadp5x7nW9Tiq9KLlfOUkHbnGfhebr/Spor3GmIOXOUdZy7LO/3+2c+c4JSlF6bdanf/aOYckLbvo58DLGPP05UJYllVa6besXc9te+cynn8dymXkOnG1nzdjzJ/GmDZKv5Vtu6RPrvO8AADgOlECAQCQ90yTNN6yrPKSZFlWUcuy7s/4+x2WZQVl3EoUpfTbdc5NmZxQ+pouN2KBpCDLsjpl3Ab0rC6cOFkjqVBG0ZBVX0tqK+lpZUwBZSggKVFSuNILntevcoxNkgIsywq2LMtN6beOna+ApDPGmATLshoovWA655TSr82VrslvkqpZlvWQlb5wdQ9J/kq/XSvLMqZi7pR0uY9fX630CaJBlmW5WpbVSum3m31tjEmV9L2kUZZleWSs9XP+ItO/ZuR7JGNfV8uy6luW5XeFKC0lLcm4xe5KXDIWez735ar0su5ly7IqWpblpfTvxzfGmJQr/bxZ6YuR35+xNlCipBj9/88hAAC4RSiBAADIe95V+nTLQsuyoiWtUvqnc0npxcw8pf9Cvk3SMv3/LUjvKn3toLOWZU29nhMaY04rfa2Zt5VezvhLWqf0X/BljEmSNEvSwxfteu7TyM59rT/vmMckrVT6BMk35+0zR+m3HB2RtDXj/V0p105JYyQtlrRL0j8XbfKMpDEZ12mE0tftObdvnNIXvv4343aqRhcdO1zpky2vZLznQZLuzbgW18UYs84Ys+cyzycpvfRpL+m0pA8lPWqM2Z6xyXNKv8XsuNKv78zz9o1Weon2oNKndY5LekvSlT79q5fSC8Sr+UhS/HlfMyXNUPrP0HKlf7x9gtIXsJau/PPmJGlARq4zSi+gLjuhBAAAso+Vfss+AABA9sm4femwpF7GmL8zniuq9E8gq52xUDJyCMuyakqaboxpbHcWAABw61ACAQCAbGFZVjul374UL+lVpd8SVonCBwAAIGfgdjAAAJBdGkvao/Tblu6T1IkCCAAAIOdgEggAAAAAAMABMAkEAAAAAADgACiBAAAAAAAAHICLXScuUqSIqVChgl2nBwAAAAAAyHPWr19/2hhT9HKv2VYCVahQQevWrbPr9AAAAAAAAHmOZVkHrvQat4MBAAAAAAA4AEogAAAAAAAAB0AJBAAAAAAA4ABsWxMIAAAAAIDskpycrMOHDyshIcHuKMBt4ebmpjJlysjV1TXL+1ACAQAAAAByvcOHD6tAgQKqUKGCLMuyOw5wSxljFB4ersOHD6tixYpZ3o/bwQAAAAAAuV5CQoJ8fX0pgOAQLMuSr6/vdU++UQIBAAAAAPIECiA4khv5eacEAgAAAAAgG3h5eV3X9kuXLtW9996bLedeunSpvL29Vbt2bVWvXl0tWrTQr7/+mvn6jh071KpVKwUHB8vPz0/9+vW7YP8tW7YoODhYwcHB8vHxUcWKFRUcHKy77roryxmmTZumOXPmZMv7adWqldatW5ctx8L/Y00gAAAAAABysZSUFElS8+bNM4ufkJAQderUSe7u7mrdurVeeOEFvfzyy7r//vslpZc+5wsKClJISIgkqXfv3rr33nvVrVu368rx1FNP3eQ7wa3GJBAAAAAAANlo6dKlatWqlbp166YaNWqoV69eMsZIkv744w/VqFFDderU0ffff5+5z5kzZ9SpUyfVrFlTjRo10ubNm6/6/KhRo/TII4+oadOmeuSRRy7JEBwcrBEjRuj999+XJB07dkxlypTJfD0oKChL72XhwoVq3Lix6tSpo+7duysmJkaSNGTIEPn7+6tmzZoaOHBgZqaJEydKSp/kGTx4sBo0aKBq1appxYoVkqS4uDg98MAD8vf3V+fOndWwYcMsT/xc6VosW7Ysc4qpdu3aio6O1rFjx9SiRQsFBwcrMDAw8/yOjkkgAAAAAECeMvqXMG09GpWtx/QvVVAj7wvI8vYbN25UWFiYSpUqpaZNm+rff/9VvXr19OSTT2rJkiWqUqWKevTokbn9yJEjVbt2bf34449asmSJHn30UYWEhFzxeUnaunWr/vnnH7m7u2vp0qWXZKhTp44mTJggSXr55Zd15513qkmTJmrbtq369OmjQoUKXfU9nD59WuPGjdPixYvl6empt956S5MmTdKzzz6rH374Qdu3b5dlWYqIiLjs/ikpKVqzZo1+++03jR49WosXL9aHH36owoULa+vWrQoNDVVwcHCWr+mVrsXEiRP1wQcfqGnTpoqJiZGbm5s+/vhjtWvXTkOHDlVqaqri4uKyfJ68jEkgAAAAAACyWYMGDVSmTBk5OTkpODhY+/fv1/bt21WxYkVVrVpVlmXp4Ycfztz+n3/+yZzoufPOOxUeHq6oqKgrPi9JHTt2lLu7+xUznJs+kqQ+ffpo27Zt6t69u5YuXapGjRopMTHxqu9h1apV2rp1q5o2barg4GDNnj1bBw4ckLe3t9zc3PT444/r+++/l4eHx2X379KliySpbt262r9/f+b7fPDBByVJgYGBqlmz5lUznO9K16Jp06YaMGCApk6dqoiICLm4uKh+/fqaOXOmRo0apS1btqhAgQJZPk9exiQQAAAAACBPuZ6JnVslf/78mX93dnbOXLcnO3l6el719Y0bN8rPzy/zcalSpdS3b1/17dtXgYGBCg0NVd26da+4vzFGbdq00VdffXXJa2vWrNFff/2lefPm6f3339eSJUsu2ebcNbhV7/+cIUOG6J577tFvv/2mpk2b6s8//1SLFi20fPlyLViwQL1799aAAQP06KOP3rIMuQWTQAAAAAAA3AY1atTQ/v37tWfPHkm6oFxp3ry5vvjiC0npawoVKVJEBQsWvOLz17J582aNHTtWzz77rKT0tYiSk5MlScePH1d4eLhKly591WM0atRI//77r3bv3i1Jio2N1c6dOxUTE6PIyEh16NBBkydP1qZNm7J8DZo2bapvv/1WUvrtbBcvUH01V7oWe/bsUVBQkAYPHqz69etr+/btOnDggIoXL64nn3xSTzzxhDZs2JDl8+RlTAIBAAAAAHAbnFur5p577pGHh4eaN2+u6OhoSemLKvft21c1a9aUh4eHZs+efdXnL2fFihWqXbu24uLiVKxYMU2dOlWtW7eWlL7A84svvig3NzdJ0oQJE1SiRImr5i1atKhmzZqlnj17Zt46Nm7cOBUoUED333+/EhISZIzRpEmTsnwNnnnmGT322GPy9/dXjRo1FBAQIG9v78tue88998jV1VWS1LhxY02fPv2y12LKlCn6+++/5eTkpICAALVv315ff/21JkyYIFdXV3l5eWXbR9fndtb59wjeTvXq1TNZXQEcAAAAAICr2bZt2wW3PiFnSk1NVXJystzc3LRnzx7ddddd2rFjh/Lly2d3tFzpcj/3lmWtN8bUu9z2TAIBAAAAAIDbIi4uTnfccYeSk5NljNGHH35IAXQbUQIBAAAAAIDbokCBAuKuIPuwMDQAAAAAAIADoAQCAAAAAABwAJRAAAAAAAAADoASCAAAAAAAwAFQAgEAAAAAkA0OHz6s+++/X1WrVlXlypX14osvKikp6Zr7vf7661d8bdSoUZo4cWK25Bs1apRKly6t4OBgVa1aVV26dNHWrVszX//1119Vu3Zt1apVS/7+/po+ffoF+8+cOVPBwcEKDg5Wvnz5FBQUpODgYA0ZMiTLGZ544okLznkzvLy8suU4joQSCAAAAACAm2SMUZcuXdSpUyft2rVLO3fuVExMjIYOHXrNfa9WAmWXlJQUSdLLL7+skJAQ7dq1Sz169NCdd96pU6dOKTk5Wf369dMvv/yiTZs2aePGjWrVqtUFx+jTp49CQkIUEhKiUqVK6e+//1ZISIjefPPNLOf49NNP5e/vn51vDdeBEggAAAAAgJu0ZMkSubm5qU+fPpIkZ2dnTZ48WTNmzFBcXJxmzZql5557LnP7e++9V0uXLtWQIUMUHx+v4OBg9erVS5I0fvx4VatWTc2aNdOOHTsy9wkJCVGjRo1Us2ZNde7cWWfPnr3q861atdJLL72kevXq6d13370kc48ePdS2bVt9+eWXio6OVkpKinx9fSVJ+fPnV/Xq1bP03idMmKD69eurZs2aGjlypCQpNjZW99xzj2rVqqXAwEB98803mZnOfUS8l5eXhg4dqlq1aqlRo0Y6ceKEJGnPnj1q1KiRgoKCNGzYsOua+LnStZg6dar8/f1Vs2ZNPfjgg5KkZcuWZU421a5dW9HR0Vk+T27lYncAAAAAAACy1e9DpONbsveYJYKk9leeeAkLC1PdunUveK5gwYIqV66cdu/efcX93nzzTb3//vsKCQmRJK1fv15ff/21QkJClJKSojp16mQe99FHH9V7772nli1basSIERo9erSmTJlyxeclKSkpKbN0GTVq1CXnr1OnjrZv3y4fHx917NhR5cuXV+vWrXXvvfeqZ8+ecnK6+uzIwoULtWvXLq1Zs0bGGHXs2FHLly/XqVOnVKpUKS1YsECSFBkZecm+sbGxatSokcaPH69Bgwbpk08+0bBhw/Tiiy/qxRdfVM+ePTVt2rSrnv9iV7oWb775pvbt26f8+fMrIiJCkjRx4kR98MEHatq0qWJiYuTm5nZd58qNmAQCAAAAACCHWLFihTp37iwPDw8VLFhQHTt2lJReokRERKhly5aSpMcee0zLly+/4vPn9OjR46rnM8Zk/v3TTz/VX3/9pQYNGmjixInq27fvNfMuXLhQCxcuVO3atTMLpV27dikoKEiLFi3S4MGDtWLFCnl7e1+yb758+XTvvfdKkurWrav9+/dLklauXKnu3btLkh566KFrZjjnateiZs2a6tWrl+bOnSsXl/R5mKZNm2rAgAGaOnWqIiIiMp/Py/L+OwQAAAAAOJarTOzcKv7+/po3b94Fz0VFRengwYOqUqWKNm/erLS0tMzXEhISbksuT0/Pq76+ceNG1atXL/NxUFCQgoKC9Mgjj6hixYqaNWvWVfc3xui1115T//79L3ltw4YN+u233zRs2DC1bt1aI0aMuOB1V1dXWZYlKf32uXPrFt0KCxYs0PLly/XLL79o/Pjx2rJli4YMGaJ77rlHv/32m5o2bao///xTNWrUuGUZcgImgQAAAAAAuEmtW7dWXFyc5syZI0lKTU3VK6+8ot69e8vDw0MVKlRQSEiI0tLSdOjQIa1ZsyZzX1dXVyUnJ0uSWrRooR9//FHx8fGKjo7WL7/8Ikny9vZW4cKFtWLFCknS559/rpYtW17x+ayYP3++Fi5cqJ49eyomJkZLly7NfC0kJETly5e/5jHatWunGTNmKCYmRpJ05MgRnTx5UkePHpWHh4cefvhhvfrqq9qwYUOWMklSo0aNNH/+fEnS119/neX9rnQtzl3zO+64Q2+99ZYiIyMVExOjPXv2KCgoSIMHD1b9+vW1ffv2LJ8rt2ISCAAAAACAm2RZln744Qc988wzGjt2rNLS0tShQ4fMT/5q2rSpKlasKH9/f/n5+alOnTqZ+/br1081a9ZUnTp19MUXX6hHjx6qVauWihUrpvr162duN3v2bD311FOKi4tTpUqVNHPmzKs+fzmTJ0/W3LlzFRsbq8DAQC1ZskRFixZVdHS03n77bfXv31/u7u7y9PS85hSQJLVt21bbtm1T48aNJaUv9jx37lzt3r1br776qpycnOTq6qqPPvooy9dyypQpevjhhzV+/Hjdfffdl72VTJLi4uJUpkyZzMcDBgy47LVITU3Vww8/rMjISBlj9MILL6hQoUIaPny4/v77bzk5OSkgIEDt27fPcsbcyjr//r/bqV69eubc4lQAAAAAANyMbdu2yc/Pz+4YyAZxcXFyd3eXZVn6+uuv9dVXX+mnn36yO1aOdLmfe8uy1htj6l1ueyaBAAAAAABAjrF+/Xo999xzMsaoUKFCmjFjht2R8gxKIAAAAAAAkGM0b95cmzZtsjtGnsTC0AAAAAAAAA6AEggAAAAAAMABUAIBAAAAAAA4AEogAAAAAAAAB0AJBAAAAABANjh8+LDuv/9+Va1aVZUrV9aLL76opKSka+4XExOj/v37q3Llyqpbt65atWql1atX34bEN693796qWLGigoODVaNGDY0ePTpL+8ybN0+SNGXKFMXFxWW+VqFCBQUFBSkoKEj+/v4aNmyYEhISJElpaWl64YUXFBgYqKCgINWvX1/79u274NidO3dWcHCwqlSpIm9vbwUHBys4OFj//fdflt7P0aNH1a1bt6y+/auaNWuWnnvuuWw5VnahBAIAAAAA4CYZY9SlSxd16tRJu3bt0s6dOxUTE6OhQ4dec98nnnhCPj4+2rVrl9avX6+ZM2fq9OnTtyH1zUlNTZUkTZgwQSEhIQoJCdHs2bMvKWau5uISSJL+/vtvbdmyRWvWrNHevXvVv39/SdI333yjo0ePavPmzdqyZYt++OEHFSpU6IJ9f/jhB4WEhOjTTz9V8+bNM3M1adIkS3lKlSqVWVDlRZRAAAAAAADcpCVLlsjNzU19+vSRJDk7O2vy5MmaMWOG4uLiNGvWLHXp0kV33323qlatqkGDBkmS9uzZo9WrV2vcuHFyckr/Fb1ixYq65557JEmTJk1SYGCgAgMDNWXKFEnS/v375efnpyeffFIBAQFq27at4uPjtX37djVo0CAz0/79+xUUFCRJWr9+vVq2bKm6deuqXbt2OnbsmPbs2aM6depkbr9r167Mx3/99Zdq166toKAg9e3bV4mJiZLSJ3UGDx6sOnXq6LvvvrvgGpyb2PH09LziOc83depUHT16VHfccYfuuOOOS66pl5eXpk2bph9//FFnzpzRsWPHVLJkyczrVKZMGRUuXPia35tTp06pa9euql+/vurXr69///1XkrRs2bLMSaHatWsrOjpa+/fvV2BgoCRd8XsmSZ999pmqVaumBg0a6Mknn7yuiZ/LfU9jY2N1zz33qFatWgoMDNQ333wjSRoyZIj8/f1Vs2ZNDRw4MMvnuBKXmz4CAAAAAAA5yFtr3tL2M9uz9Zg1fGpocIPBV3w9LCxMdevWveC5ggULqly5ctq9e7ckKSQkRBs3blT+/PlVvXp1Pf/88woLC1NwcLCcnZ0vOea5qaDVq1fLGKOGDRuqZcuWKly4sHbt2qWvvvpKn3zyiR544AHNnz9fDz/8sJKSkrRv3z5VrFhR33zzjXr06KHk5GQ9//zz+umnn1S0aFF98803Gjp0qGbMmCFvb2+FhIQoODhYM2fOVJ8+fZSQkKDevXvrr7/+UrVq1fToo4/qo48+0ksvvSRJ8vX11YYNGyRJf/zxh1599VWNGzdOu3fv1gsvvKBixYpd9ZznvPDCC5o0aZL+/vtvFSlS5LLXtWDBgqpYsaJ27dqlBx54QM2aNdOKFSvUunVrPfzww6pdu/Y1v3cvvviiXn75ZTVr1kwHDx5Uu3bttG3bNk2cOFEffPCBmjZtqpiYGLm5uV2y7+W+Z87Ozho7dqw2bNigAgUK6M4771StWrWumeNq39O9e/eqVKlSWrBggSQpMjJS4eHh+uGHH7R9+3ZZlqWIiIgsneNqmAQCAAAAAOA2aN26tby9veXm5iZ/f38dOHDgqtv/888/6ty5szw9PeXl5aUuXbpoxYoVkpS5Do8k1a1bV/v375ckPfDAA5lTJOdKoB07dig0NFRt2rRRcHCwxo0bp8OHD0tKvxVt5syZSk1N1TfffKOHHnpIO3bsUMWKFVWtWjVJ0mOPPably5dn5urRo8cFOc/dDnb8+HH99ddf+u+//656zutljJGUPvmzY8cOvfHGG3JyclLr1q31119/XXP/xYsX67nnnlNwcLA6duyoqKgoxcTEqGnTphowYICmTp2qiIgIubhcOidzue/ZmjVr1LJlS/n4+MjV1VXdu3fP8nu50vc0KChIixYt0uDBg7VixQp5e3tnnvfxxx/X999/Lw8Pj6xftCtgEggAAAAAkKdcbWLnVvH3979kLZmoqCgdPHhQVapU0YYNG5Q/f/7M15ydnZWSkqKAgABt2rRJqampl50GupKLjxUfHy8pvaDp3r27unTpIsuyVLVqVW3ZskUBAQFauXLlJcfp2rWrRo8erTvvvFN169aVr6/vNcuac7d7XczLy0utWrXSP//8o/bt21/xnNfj3C1a5wqp/Pnzq3379mrfvr2KFy+uH3/8Ua1bt77qMdLS0rRq1apLJn2GDBmie+65R7/99puaNm2qP//885JtLvc9uxWqVaumDRs26LffftOwYcPUunVrjRgxQmvWrNFff/2lefPm6f3339eSJUtu6jxMAgEAAAAAcJNat26tuLg4zZkzR1L6osmvvPKKevfufdUJjsqVK6tevXoaOXJk5sTL/v37tWDBAjVv3lw//vij4uLiFBsbqx9++EHNmze/ao7KlStn3q50bmKnevXqOnXqVGYhk5ycrLCwMEmSm5ub2rVrp6effjpzPaPq1atr//79mbexff7552rZsuU1r0FKSopWr16typUrX/Wc5ytQoICio6Mve7yYmBg988wz6tSpkwoXLqwNGzbo6NGjktKLnc2bN6t8+fLXzNW2bVu99957mY9DQkIkpa/HFBQUpMGDB6t+/fravj1rtxDWr19fy5Yt09mzZ5WSkqL58+dnaT9JV/yeHj16VB4eHnr44Yf16quvasOGDYqJiVFkZKQ6dOigyZMna9OmTVk+z5VQAgEAAAAAcJMsy9IPP/yg7777TlWrVlW1atXk5uam119//Zr7fvrppzpx4oSqVKmiwMBA9e7dW8WKFVOdOnXUu3dvNWjQQA0bNtQTTzyRpTVwevTooblz5+qBBx6QJOXLl0/z5s3T4MGDVatWrUs+Mr1Xr15ycnJS27ZtJaUXQzNnzlT37t0VFBQkJycnPfXUU1c836uvvqrg4GDVrFlTQUFB6tKlyzXPeU6/fv109913X7Aw9B133KHAwEA1aNBA5cqV0/Tp0yVJJ0+e1H333afAwEDVrFlTLi4uWVqQeerUqVq3bp1q1qwpf39/TZs2TVL6J5OdO5arq6vat29/zWNJUunSpfW///1PDRo0UNOmTVWhQgV5e3tfdttZs2apTJkymV/FihW77Pd0y5YtatCggYKDgzV69GgNGzZM0dHRuvfee1WzZk01a9ZMkyZNylK+q7HONY23W7169cy6detsOTcAAAAAIG/Ztm2b/Pz87I6RK02cOFGRkZEaO3as3VFyjZiYGHl5eSklJUWdO3dW37591blz59ue43I/95ZlrTfG1Lvc9qwJBAAAAACAg+rcubP27Nlz02vNOJpRo0Zp8eLFSkhIUNu2bdWpUye7I2UJJRAAAAAAAA7qhx9+sDtCrjRx4kS7I9wQ1gQCAAAAAABwAJRAAAAAAIA8wa41bwE73MjPOyUQAAAAACDXc3NzU3h4OEUQHIIxRuHh4XJzc7uu/VgTCAAAAACQ65UpU0aHDx/WqVOn7I6CHM7IKM2kKS0tTakmNfOrgGsBWZZld7wsc3NzU5kyZa5rH0ogAAAAAECu5+rqqooVK9odAzYzxuhMwhmdiDuh47HHM/88/+8n404qOS35gv1cnVy1oPMClfQqaVPy24MSCAAAAAAA5HjGGEUkRlxS6pxf9JyMO6mktKQL9nNxclFxj+Iq7lFctYrWUnHP4irhUSL9T88SKu5RXD5uPnKy8v6KOZRAAAAAAADAVsYYRSZG6njccZ2IzSh1zv09488TcSeUmJp4wX4ulouKeRRTCc8SCioSlF7qZJQ85/7uKAVPVlACAQAAAACAW8YYo6ikqMvennV+yZOQmnDBfs6Wc2bB4+/rrzvL3aniHunTO+cmeHzdfSl4rgMlEAAAAAAAuCHnCp7Lrb1zruQ5EXdC8SnxF+znbDmrqEdRlfAooRo+NdSqTKsLbs8q4VlCvm6+cnZytumd5U2UQAAAAAAA4BLGGEUnR2fennWloufigsfJclJR96Iq7llc1QpXU4syLTKLnXO3ahVxL0LBYwNKIAAAAAAAHFBMUsxl1945v+SJS4m7YB8ny0lF3IuohEcJVS1cVc1KN7vg9qwSnukFj4sTdUNOxHcFAAAAAIA8JjY5Nr3MySh3LpjeyXguNjn2gn0sWZkTPJULVVaTUk0uKHdKeJaQr7uvXJ1cbXpXuFmUQAAAAAAA5CJxyXGXn+A5b5InJjnmgn0sWfJ191UJjxKq6F1RjUo1uuRj0ot6FKXgyeMogQAAAAAAyCHikuMuWG/ncmvwRCdFX7Kfr5uvSniWULkC5dSgRIMLJniKexZXMfdicnWm4HF0lEAAAAAAANwG8SnxV1x759xzUUlRl+zn4+ajEp4lVLZAWdUvUf+Sj0kv7lGcggdZQgkEAAAAAMBNSkhJyPxI9Mw1eC66VSsyMfKS/XzcfFTco7hKe5VW3WJ1L/mY9OIexZXPOZ8N7wh5ESUQAAAAAADX4UTsCYWFhyn0dKi2hm/VtjPbdCbhzCXbFc5fWMU9i6ukZ0kFFwu+cJFljxIq5llM+Z3z2/AO4KgogQAAAAAAuIIzCWcUdjpMoeGh2np6q8LCw3Qq/pQkydlyVpVCVdSyTEuVLVD2gpKnmEcxubm42ZweuBAlEAAAAAAAkqKSohR2Okxh4WHaGr5VoadDdSz2mKT0T9eq6F1RjUo2UkCRAAX4Bqi6T3W5u7jbnBrIOkogAAAAAIDDiUuO09bw9MmesPAwhZ0O08Hog5mvly1QVrWK1lIvv17y9/WXn4+fvPJ52ZgYuHmUQAAAAACAPC0hJUE7zu7InPIJOx2mvZF7ZWQkSSU8SyjAN0Cdq3aWv6+/AnwD5J3f2+bUQPajBAIAAAAA5BnJqcnaFbErs+wJCw/T7rO7lWJSJEm+br4KLBKodhXaKaBIgPx9/VXEvYjNqYHbgxIIAAAAAJArpaSlaF/kPoWeDs1cx2fHmR1KSkuSJBXMV1CBRQLVJ7CPAnwDFFAkQMU9isuyLJuTA/agBAIAAAAA5HhpJk0Hog5cMOGz/cx2xafES5I8XT3l7+uvh/weyly4uYxXGQof4DyUQAAAAACAHMUYoyMxRy5YtHlr+FbFJMdIktyc3VTDp4a6VO2SOeFToWAFOVlONicHcjZKIAAAAACArU7EnlBYeJhCT4dmfmJXRGKEJMnFyUXVC1dXh4odFFgkUP6+/qpcqLJcnPh1Frhe/FMDAAAAALhtziScUdjpMIWGh2rr6fTC51T8KUmSs+WsyoUq685yd6ZP+PgGqGrhqsrnnM/m1EDeQAkEAAAAALglopKiMtfv2Rq+VaGnQ3Us9pgkyZKlCt4V1Khko8w1fKr7VJe7i7vNqYG8ixIIAAAAAHDT4pLjMm/lOreOz8Hog5mvly1QVrWK1tJDNdIXbvbz8ZNXPi8bEwOOhxIIAAAAAHBdElIStOPsjswpn7DTYdobuVdGRpJUwrOEAnwD1KlKp8wpH+/83janBkAJBAAAAAC4ouTUZO2K2HXBR7PvPrtbKSZFkuTj5qPAIoFqV6GdAooEyN/XX0Xci9icGsDlUAIBAAAAACRJqWmp2hu5V6GnQzPX8dlxZoeS0pIkSQXzFVSAb4D6BPbJ/Gj24h7FZVmWzckBZAUlEAAAAAA4oDSTpoNRBxUaHpo54bP9zHbFp8RLkjxdPeXv66+H/B7KLHzKeJWh8AFyMUogAAAAAMjjjDE6EnPkgkWbt4ZvVUxyjCTJzdlNNXxqqEvVLpmFT4WCFeRkOdmcHEB2ogQCAAAAgDzmROwJhYWHKfR0aOYndkUkRkiSXJxcVL1wdXWo2EGBRQLl7+uvyoUqy8WJXw+BvI5/ygEAAAAgFzuTcEZhp8MUGh6qrafTC59T8ackSc6WsyoXqqw7yt6hwCKBCvANUNXCVZXPOZ/NqQHYgRIIAAAAAHKJqKSozPV7toZvVejpUB2LPSZJsmSpgncFNSrZKPNj2av7VJe7i7vNqQHkFJRAAAAAAJADxSXHZd7KdW4dn4PRBzNfL+NVRrWK1tJDNR5SQJEA+fn4ySufl42JAeR0lEAAAAAAYLOElATtOLsjc8on7HSY9kbulZGRJJXwLKEA3wB1qtIpc8rHO7+3zakB5DaUQAAAAABgk5ikGL32z2v65/A/SjEpkiQfNx8FFglU2wptMxduLuJexOakAPICSiAAAAAAsEF4fLieXvy0dp3dpV5+vVS7WG0FFAlQcY/isizL7ngA8iBKIAAAAAC4zY7FHFO/Rf10PPa43r3zXbUo08LuSAAcACUQAAAAANxGeyP2qt+ifopLjtP0NtNVp3gduyMBcBCUQAAAAABwm4SeDtXTi5+Ws+WsmXfPVHWf6nZHAuBAnOwOAAAAAACOYPWx1Xr8z8fl6eqpOe3nUAABuO0ogQAAAADgFvvrwF96evHTKuVVSnPaz1G5guXsjgTAAVECAQAAAMAt9MOuHzRg2QD5+fpp1t2zVMyjmN2RADgo1gQCAAAAgFtkdthsTVw3UU1KNdHkVpPl4ephdyQADowSCAAAAACymTFG7254V5+FfqZ2FdrpjWZvyNXZ1e5YABwcJRAAAAAAZKPUtFSNWz1O83bOU/dq3TW04VA5OznbHQsAKIEAAAAAILskpSbptRWvaeGBhXoy6Ek9X/t5WZZldywAkEQJBAAAAADZIi45Ti/9/ZJWHlupgfUG6rGAx+yOBAAXoAQCAAAAgJsUmRipZ/56RqGnQzWmyRh1rtrZ7kgAcAlKIAAAAAC4CSdiT+ipxU/pQNQBTWo1Sa3LtbY7EgBcFiUQAAAAANygg1EH1W9RP51NOKtpd01Tg5IN7I4EAFdECQQAAAAAN2DHmR3qv6i/Uk2qZrSboYAiAXZHAoCrcrI7AAAAAADkNhtObFCfP/rIxclFs9vPpgACkCtQAgEAAADAdVh+eLn6L+ovX3dffd7+c1XyrmR3JADIEkogAAAAAMiiX/f+qheXvKiK3hU1u/1slfQqaXckAMgySiAAAAAAyIIvt32p11a8ptrFa2tGuxnycfOxOxIAXBcWhgYAAACAqzDGaNrmafow5EO1KttKE1tOVH7n/HbHAoDrRgkEAAAAAFeQZtL09tq39cW2L9SxckeNbjJaLk78GgUgd+LfXgAAAABwGclpyRrx7wj9uvdXPeL/iAbWGygnixU1AORelEAAAAAAcJGElAQNXDZQyw4v0wu1X9ATQU/Isiy7YwHATaEEAgAAAIDzRCdF67m/ntPGkxs1vNFwPVD9AbsjAUC2oAQCAAAAgAyn40/r6cVPa/fZ3Xq7xdu6u+LddkcCgGxDCQQAAAAAko7EHFG/hf10Kv6U3mv9npqVbmZ3JADIVpRAAAAAABzenog96reon+JT4vVxm48VXCzY7kgAkO0ogQAAAAA4tM2nNuuZv56Rq5OrZt09S9UKV7M7EgDcEny+IQAAAACHtfLoSj2x8AkVcC2gOe3nUAAByNMogQAAAAA4pEUHFunZv55VmQJlNKf9HJUtUNbuSABwS1ECAQAAAHA483fO18BlAxXgG6CZ7WaqqEdRuyMBwC3HmkAAAAAAHMqM0BmavH6ympZuqkktJ8nD1cPuSABwW1ACAQAAAHAIxhhNXj9ZM8Nmqn2F9hrfbLxcnV3tjgUAt02WbgezLOtuy7J2WJa127KsIVfY5gHLsrZalhVmWdaX2RsTAAAAAG5calqqRq0cpZlhM9Wjeg+90fwNCiAADueak0CWZTlL+kBSG0mHJa21LOtnY8zW87apKuk1SU2NMWctyyp2qwIDAAAAwPVISk3S4OWDtfjgYvWv2V/PBj8ry7LsjgUAt11WbgdrIGm3MWavJFmW9bWk+yVtPW+bJyV9YIw5K0nGmJPZHRQAAAAArldscqxe/PtFrT62WoPqD9Ij/o/YHQkAbJOV28FKSzp03uPDGc+dr5qkapZl/WtZ1irLsu7OroAAAAAAcCMiEiL05MInte74Oo1vNp4CCIDDy66FoV0kVZXUSlIZScstywoyxkScv5FlWf0k9ZOkcuXKZdOpAQAAAOBCx2OPq/+i/jocfViTW03WHeXusDsSANguK5NARySVPe9xmYznzndY0s/GmGRjzD5JO5VeCl3AGPOxMaaeMaZe0aJFbzQzAAAAAFzR/sj9evT3R3Ui7oSmtZlGAQQAGbJSAq2VVNWyrIqWZeWT9KCkny/a5kelTwHJsqwiSr89bG/2xQQAAACAa9sWvk2P/fGYElMTNaPdDNUvUd/uSACQY1yzBDLGpEh6TtKfkrZJ+tYYE2ZZ1hjLsjpmbPanpHDLsrZK+lvSq8aY8FsVGgAAAAAutu74OvX9s6/yO+fX7Ltny9/X3+5IAJCjWMYYW05cr149s27dOlvODQAAACBvWXpoqQYuG6hSXqX0cZuPVcKzhN2RAMAWlmWtN8bUu9xrWbkdDAAAAAByrF/2/KKX/n5JVQpV0ey7Z1MAAcAVZNengwEAAADAbTd361y9tfYtNSzRUO/e+a48XT3tjgQAORYlEAAAAIBcxxijDzd9qGmbpql1udZ6q8Vbyu+c3+5YAJCjUQIBAAAAyFXSTJreWP2Gvt7xtTpX6awRjUfIxYlfbQDgWvg3JQAAAIBcIzktWUP/Garf9/2u3gG9NaDuAFmWZXcsAMgVKIEAAAAA5ArxKfEasHSA/jnyj16q85IeD3rc7kgAkKtQAgEAAADI8aKSovTcX88p5GSIRjQeoe7VutsdCQByHUogAAAAADna6fjT6r+ov/ZG7tXElhPVtkJbuyMBQK7kZHcAAAAA2MMYox93/6j+i/rrm+3fKCElwe5IwCUORx/Wo78/qkPRh/RB6w8ogADgJjAJBAAA4ID2R+7X2FVjteb4Gvm4+ei/o//pw00f6qEaD+nBGg/KO7+33REB7Tq7S/0X9VdiaqI+afuJahWtZXckAMjVmAQCAABwIMmpyZq+abq6/txV28K3aXij4fr7gb81o90M+fv66/2Q99VmXhu9vfZtHY89bndcOLCQkyHq/UdvWbI0++7ZFEAAkA0sY4wtJ65Xr55Zt26dLecGAABwRBtObNCYlWO0J3KP2lVop8H1B6uoR9ELttlxZodmhc3S7/t+lyVLHSp1UJ+APqpSuIpNqeGI/jvyn15a+pKKuhfV9DbTVaZAGbsjAUCuYVnWemNMvcu+RgkEAACQt0UlRWny+smat3OeSnmW0tBGQ9WiTIur7nM05qjmbJ2j73d9r/iUeLUs01J9A/uqTvE6tyk1HNUf+//QayteU2XvyprWZpqKuBexOxIA5CqUQAAAAA7IGKM/9/+pN9e8qbOJZ/WI3yN6JvgZebh6ZPkYEQkR+mrHV/pq21c6m3hWwUWD1Sewj1qVbSUni5UFkL2+2/mdxq4cq9rFauu91u+pYL6CdkcCgFyHEggAAMDBHI05qnGrxmnFkRXy9/XXyMYj5e/rf8PHi0+J14+7f9TssNk6EnNElbwrqXdAb91b6V65OrtmY3I4ImOMPgv9TO9ueFctyrTQxJYT5e7ibncsAMiVKIEAAAAcREpair7Y9oU+CPlAkvR87efVs0ZPuThlz4fCpqSlaOH+hZoROkM7zu5QMfdiesT/EXWr1k1e+byy5RxwLMYYvbPuHc3eOlsdKnbQuGbj5OpEsQgAN4oSCAAAwAGEhYdp9H+jte3MNrUs01JDGw5VSa+St+RcxhitPLpSM0JnaPXx1SrgWkA9avRQL79erOGCLEtJS9HolaP14+4f1bNGTw1pMITbDAHgJlECAQAA5GFxyXF6b+N7+nL7l/J189WQBkPUpnwbWZZ1W84fejpUM0JnaPGBxXJ1clXHKh3VO6C3yhcsf1vOj9wpMTVRg5YN0pJDS/RMrWf0VK2nbtvPLADkZZRAAAAAedTSQ0s1fvV4nYg9oQeqP6AX67yoAvkK2JLlYNRBzQqbpZ92/6TktGTdVf4u9Q3sq8AigbbkQc4VmxyrF5a8oDXH12hIgyHq5dfL7kgAkGdQAgEAAOQxJ+NO6s01b2rRgUWqUqiKRjYeqeBiwXbHkiSdjj+tL7d9qa93fK3opGg1KNFAfQP7qkmpJkx6QGcSzuiZxc9o+5ntGtdsnO6tdK/dkQAgT6EEAgAAyCPSTJq+2/GdpmyYoqTUJD1V6yn1DuidIz+hKzY5VvN2ztOcrXN0Mu6kqheurj6BfdSuQrtsW6gaucvx2ON6cuGTOhZ7TJNaTVKLMi3sjgQAeQ4lEAAAQB6w6+wujV45WptObVLDkg01otEIlStYzu5Y15ScmqwF+xZoZuhM7Y3cq9JepfWo/6PqXLUzHwPuQPZF7lO/Rf0UkxSj91u/r7rF69odCQDyJEogAACAXCwhJUEfb/5YM0Nnyiufl16t/6ruq3Rfrru1Ks2kadmhZZoROkMhp0JUKH8hPVTjIfWs0VOF3ArZHQ+3UFh4mJ5e9LQsy9L0NtNVw6eG3ZEAIM+iBAIAAMilVh1bpbErx+pg9EF1rNxRA+sNVGG3wnbHumkbT27UjC0ztPTwUrm7uKtzlc56LOAxlfIqZXc0ZLO1x9fq+SXPyzuftz5u+zGfGgcAtxglEAAAQC5zJuGMJq6dqF/2/qJyBcppROMRaliyod2xst3us7s1K2yWFuxdICOjuyverT4BfVTdp7rd0ZANlhxcoleXvaqyBcpqepvpKu5Z3O5IAJDnUQIBAADkEsYY/bznZ01cN1ExSTHqE9hH/Wr2k5uLm93Rbqnjscf1+dbPNW/nPMWlxKlp6aZ6PPBx1SteL9fd9oZ0P+3+SSP/G6kA3wB90PoDbvkDgNuEEggAACAXOBB1QGNXjtXq46sVXDRYIxuPVJXCVeyOdVtFJkbq2x3fau62uTqTcEZBRYLUN7Cv7ih7h5ydnO2OhyyaEzZHE9ZNUKOSjfTuHe/Kw9XD7kgA4DAogQAAAHKw5NRkzQidoY83f6z8zvn1Ut2X1K1aNzlZTnZHs01CSoJ+3vOzZoXN0qHoQ6pQsIIeC3hM91W+T/md89sdD1dgjNF7G9/TJ1s+UZvybfRm8zeVzzmf3bEAwKFQAgEAAORQG09u1Oj/RmtP5B61Ld9WQxoMUVGPonbHyjFS01K1+OBizQidoa3hW1XEvYge9ntYD1R/QAXyFbA7Hs6Tmpaq11e/rm93fquuVbtqeKPhTG8BgA0ogQAAAHKYqKQoTVk/Rd/t/E4lPUtqWKNhalGmhd2xcixjjFYfX60ZW2Zo5bGV8nT11APVHtDD/g+rmEcxu+M5vOTUZP3vn//pj/1/qG9gX71U5yXWcgIAm1ACAQAA5BDGGC08sFBvrnlTZxLOqJdfLz0X/BxrplyHreFbNSt0lv488KecLWfdV/k+9Q7orYreFe2O5pDikuM0YOkA/Xv0Xw2oO0B9AvvYHQkAHBolEAAAQA5wNOaoxq8er+WHl8vPx08jm6R/chJuzKHoQ5odNls/7v5RSalJuqPsHeob1Fe1itayO5rDiEyM1LN/Pastp7doZOOR6lK1i92RAMDhUQIBAADYKCUtRV9s+0IfhHwgSXou+Dk95PeQXJxcbE6WN5xJOKMvt32pr7Z/paikKNUtXld9A/uqeenm3JJ0C52KO6V+i/rpQNQBvd3ibd1V/i67IwEARAkEAABgm7DwMI3+b7S2ndmmFmVaaGjDoSrlVcruWHlSXHKc5u+arzlb5+h47HFVKVRFfQP76u6Kd8vVydXueHnKoahDenLRkzqTcEZT75yqRiUb2R0JAJCBEggAAOA2i0uO0/sh7+uLbV/Ix81HQxoMUdvybZlMuQ2S05L1x74/NCN0hnZH7FYJzxJ61P9Rda3albWXssGOMzv01OKnlJKWog9bf6igokF2RwIAnIcSCAAA4DZadmiZxq8er2Oxx/RAtQf0Yt0XVTBfQbtjORxjjFYcWaEZoTO0/sR6FcxXUD1r9NRDfg/Jx83H7ni50saTG/XsX8/K3cVdn7T5RJUKVbI7EgDgIpRAAAAAt8GpuFN6c82bWnhgoSp7V9bIJiNVu1htu2NB0qZTmzRjywz9fehv5XPOp05VOumxgMdUtkBZu6PlGv8c+Ucv//2yinsW18dtPua2RgDIoSiBAAAAbqE0k6Z5O+dpyvopSkxNVP9a/dUnoI9cnVmHJqfZG7lXs8Nm6+c9PyvNpKld+XbqE9hHfr5+dkfL0X7f97v+t+J/qlq4qj666yP5uvvaHQkAcAWUQAAAALfI7rO7NXrlaIWcClHDEg01vPFwlS9Y3u5YuIaTcSc1d+tcfbvzW8Umx6pxycbqG9RXDUs0ZN2mi3yz/RuNXz1edYrX0Xt3vqcC+QrYHQkAcBWUQAAAANksISVBH2/+WDPDZsrL1Uuv1n9V91W6jwIhl4lOita3O77V3G1zdTr+tPx9/dUnsI/alGsjZydnu+PZyhijjzd/rPdD3lerMq00oeUEubm42R0LAHANlEAAAADZaPWx1RqzcowORh9Ux8odNbDeQBV2K2x3LNyExNRE/bLnF80Km6UDUQdUtkBZ9Q7orY6VOzpk8ZFm0jRh7QTN3TZX91W6T6ObjparE7c3AkBuQAkEAACQDc4mnNXEdRP1856fVa5AOQ1vPFyNSjayOxayUWpaqv4+9LdmhM7QltNb5OPmo15+vdSjeg955/e2O95tkZKWopH/jdTPe37Ww34P69X6r8rJcrI7FgAgiyiBAAAAboIxRr/s/UUT1k5QTFKM+gT2Ub+a/RxyQsRRGGO07sQ6zQidoX+O/CMPFw91q9ZNj/g/ohKeJeyOd8skpCTo1eWvaumhpXo2+Fn1r9mfWxwBIJehBAIAALhBB6MOasyqMVp9bLVqFa2lkY1HqmrhqnbHwm2048wOzQybqT/2/SFLljpU6qC+gX1VuVBlu6Nlq5ikGD2/5HmtP7Fe/2v4Pz1Y40G7IwEAbgAlEAAAwHVKTk3WrLBZmr55ulydXPVy3ZfVrVo3botxYEdjjmrO1jn6ftf3ik+JV6syrdQnsI/qFK9jd7SbFh4frqcXP61dZ3dpfLPx6lCpg92RAAA3iBIIAADgOoScDNHolaO1O2K32pRvoyENhqiYRzG7YyGHiEiI0Fc7vtKX275URGKEgosGq29gX7Us2zJXloRHY46q/6L+Oh57XJNaTVLzMs3tjgQAuAmUQAAAAFkQlRSld9e/q+92fqfinsU1rOEwtSzb0u5YyKHiU+L1w64fNGfrHB2JOaJK3pXUO6C37q10r1ydc8cnae2N2Kt+i/opLjlOH9z1gWoXq213JADATaIEAgAAuApjjBYdWKQ317yp8IRw9fLrpeeCn5OHq4fd0ZALpKSlaOH+hZoROkM7zu5QMY9ietT/UXWr1k2erp52x7ui0NOhenrx03K2nDW9zXRV96ludyQAQDagBAIAALiCYzHHNH71eC07vEx+Pn4a2WSkAnwD7I6FXMgYo/+O/qcZoTO05vgaFchXQA9Wf1AP+T2kIu5F7I53gdXHVuuFJS+osFthfdLmE5UtWNbuSACAbEIJBAAAcJHUtFR9uf1LvbfxPUnSs8HPqpdfL7k4udicDHlB6OlQzQidocUHFsvVyVX3V7lfvQN6q1zBcnZH018H/tKry19V+YLlNb3NdNa7AoA8hhIIAADgPFvDt2r0ytHaGr5VzUs319BGQ1Xaq7TdsZAHHYg6oFlhs/Tz7p+VnJasu8rfpccDH1dAEXumzX7Y9YNGrRyloCJB+qD1B/LO721LDgDArUMJBAAAIKUvfhvygeZum6vC+QtrSMMhale+nSzLsjsa8rjT8af1xbYv9M32bxSdHK2GJRqqb2BfNS7V+Lb9/M0KnaV31r+jJqWaaHKryax5BQB5FCUQAABweMsPL9e4VeN0LPaYulfrrpfqvqSC+QraHQsOJiYpRvN2ztPnWz/XyfiTquFTQ30C+qhthba37FZEY4ze3fCuPgv9TO0qtNMbzd7INZ9eBgC4fpRAAADAYZ2OP60317ypP/f/qcrelTWi8QjVKV7H7lhwcEmpSVqwd4Fmhs3Uvsh9Ku1VWo/6P6rOVTvL3cU9286TmpaqcavHad7OeeperbuGNhwqZyfnbDs+ACDnoQQCAAAOJ82kad7OeZqyfooSUxPVr2Y/9Q3sywQEcpQ0k6alh5ZqRugMbTq1SYXzF1ZPv57qWb2nCrkVuqljJ6Um6bUVr2nhgYV6MuhJPV/7eW59BAAHQAkEAAAcyu6zuzVm1RhtPLlRDUo00PBGw1XBu4LdsYCr2nBig2aEztCyw8vk7uKuLlW76FH/R1XKq9R1HysuOU4v/f2SVh5bqYH1BuqxgMduQWIAQE5ECQQAABxCYmqiPt78sWaEzpCnq6cG1huo+yvfz/QDcpVdZ3dpVtgs/bb3NxkZta/YXn0C+6ha4WpZ2j8yMVLPLH5GoeGhGt1ktDpV6XRrAwMAchRKIAAAkOetObZGY1aN0YGoA7qv0n0aWH+gfNx87I4F3LDjscc1Z+sczds5T/Ep8WpWupn6BvZVveL1rlhsnog9oacWP6WDUQf1dsu31bpc69ucGgBgN0ogAACQZ0UkRGjiuon6ac9PKlugrIY3Gq7GpRrbHQvINpGJkfpmxzf6YtsXOpNwRjWL1FSfwD66s9ydcrKcMrc7GHVQ/Rb1U0RihKbeMVUNSjawMTUAwC6UQAAAIM8xxujXvb9qwtoJik6KVp/APupXs5/cXNzsjgbcEgkpCfpp90+aFTZLh2MOq0LBCuod0Fv3Vb5P+yL3qf+i/kozafqozUcK8A2wOy4AwCaUQAAAIE85GHVQY1eN1apjq1SraC2NaDwiy+ulALldalqqFh1cpBlbZmjbmW0q4l5EiSmJ8sznqeltpquSdyW7IwIAbHS1EsjldocBAAC4UclpyZodNlvTNk2Tq5OrhjUcpu7Vu19wSwyQ1zk7OevuCnerXfl2Wn18tWaGztTZhLN69453VdKrpN3xAAA5GCUQAADIFUJOhmj0ytHaHbFbbcq30ZAGQ1TMo5jdsQDbWJalRiUbqVHJRnZHAQDkEpRAAAAgR4tOita7G97Vtzu+VXHP4nrvzvfUqmwru2MBAADkOpRAAAAgRzLGaPHBxXpj9RsKTwhXL79eeq72c/J09bQ7GgAAQK5ECQQAAHKc47HHNX7VeC09vFQ1fGrovTvfU0ARPu0IAADgZlACAQCAHCM1LVVfbv9S7218T5I0sN5A9fLrJRcn/pcFAADgZvF/VAAAIEfYFr5No1eOVlh4mJqXbq6hjYaqtFdpu2MBAADkGZRAAADAVnHJcfow5EPN3TZXhfIX0oSWE9SufDtZlmV3NAAAgDyFEggAANhm+eHlGr9qvI7GHlW3at30Up2X5J3f2+5YAAAAeRIlEAAAuO1Ox5/WW2ve0h/7/1Al70qaffds1Slex+5YAAAAeRolEAAAuG3STJrm75qvyesnKzElUc8GP6u+gX2Vzzmf3dEAAADyPEogAABwW+yJ2KMxK8dow8kNql+ivkY0GqEK3hXsjgUAAOAwKIEAAMAtlZiaqE82f6LPQj+Tp6unxjYdq/sr38/CzwAAALcZJRAAALhl1hxbo7Grxmp/1H7dV+k+Daw/UD5uPnbHAgAAcEiUQAAAINtFJETonfXv6MfdP6psgbKa3ma6mpRqYncsAAAAh0YJBAAAso0xRr/u/VUT1k5QdFK0ngh6Qv1r9pebi5vd0QAAABweJRAAAMgWh6IOaeyqsVp5bKVqFq2pkY1HqlrhanbHAgAAQAZKIAAAcFOS05I1O2y2pm2aJlcnVw1tOFQPVH9ATpaT3dEAAABwHkogAABwQ6KTovXb3t/05fYvtTdyr9qUb6MhDYaomEcxu6MBAADgMiiBAABAlhljFHo6VPN2zdPv+35XfEq8avjU0NQ7puqOcnfYHQ8AAABXQQkEAACuKTopWgv2LtC8nfO04+wOubu4q0PFDupWrZsCfANkWZbdEQEAAHANlEAAAOCyjDHacnqL5u2cpz/2/6H4lHj5+fhpeKPh6lCxg7zyedkdEQAAANeBEggAAFzg3NTPdzu/086zOzOnfrpX666AIgF2xwMAAMANogQCAAAyxmjz6c3pUz/7/lBCaoL8fPw0ovEIdajYQZ6unnZHBAAAwE2iBAIAwIFFJUVlrvWz8+xOebh46N7K92au9QMAAIC8gxIIAAAHY4zRplObNG/nPP25/08lpCbI39dfIxuPVPuK7Zn6AQAAyKMogQAAcBBRSVH6dc+vmrdrnnad3SUPFw/dV/k+da3WlakfAAAAB0AJBABAHnZu6ue7nd9p4f6FSkhNUIBvgEY2HqkOFTvIw9XD7ogAAAC4TSiBAADIgyITI/Xr3l81b+c87Y7YLU9XT3Ws3FFdq3WVv6+/3fEAAABgA0ogAADyiPOnfv7c/6cSUxMV6BuoUY1HqX3F9kz9AAAAODhKIAAAcrnLTf3cX/l+davWTX6+fnbHAwAAQA5BCQQAQC5kjFHIqZDMT/hKTE1UUJEgjW4yWndXuJupHwAAAFyCEggAgFzkclM/nap0Urdq3VTDp4bd8QAAAJCDUQIBAJDDGWO08eRGzds5TwsPLMyc+hnTZIzaVWjH1A8AAACyhBIIAIAcKjIxUr/s+UXzds7Tnsg98nL1YuoHAAAAN4wSCACAHMQYow0nN6RP/exfqKS0JNUsUpOpHwAAANw0SiAAAHKAiIQI/bI3fepnb+Reebl6qUvVLupWrZuq+1S3Ox4AAADyAEogAABsYozR+hPrNW/XPC3avyh96qcoUz8AAAC4NSiBAAC4zSISIvTznp81b9c87YvcpwKuBdS1Wld1rdqVqR8AAADcMpRAAADcBsYYrTuxTvN2ztOiA4uUnJasWkVraWzTsWpXoZ3cXdztjggAAIA8jhIIAIBb6GzC2fSpn53ztD9qvwq4FlD3at3VtVpXVStcze54AAAAcCCUQAAAZLNzUz/f7fxOiw8sVnJasoKLBmtc03FqW6EtUz8AAACwBSUQAADZ5JKpn3wF9ED1B9S1aldVLVzV7ngAAABwcJRAAADchMtN/dQuVltP1nxSbcq3YeoHAAAAOQYlEAAAN+Bswln9tPsnzd81/4Kpn25Vu6lK4Sp2xwMAAAAuQQkEAEAWGWO09vhazds5T4sPpk/91ClWR/1q9lOb8m3k5uJmd0QAAADgiiiBAAC4hjMJZ/Tz7p81b9c8HYg6oIL5CqpH9R7qWrUrUz8AAADINSiBAAC4DGOM1hxfkzn1k5KWojrF6qh/zf5M/QAAACBXogQCAOA84fHhmZ/wdTD6oArmK6gHqz+obtW6qXKhynbHAwAAAG4YJRAAwOGlmbTMqZ+/Dv6VOfXzdPDTalO+jfI757c7IgAAAHDTKIEAAA4rPD5cP+35SfN3ztfB6IPyzu+tnjV6qlvVbqpUqJLd8QAAAIBsRQkEAHAo56Z+vtvxnZYcWqKUtBTVLV6XqR8AAADkeZRAAACHcDr+tH7a/ZPm75qvQ9GH5J3fWw/VeEhdq3VVJW+mfgAAAJD3UQIBAPKsNJOm1cdWa97OeZlTP/WK19Ozwc/qrvJ3MfUDAAAAh0IJBADIc07Hn9aPu3/U/J3zdTjmsArlL8TUDwAAABweJRAAIE9IM2ladWyV5u2cp78P/q0Uk6L6Jerr+drPq3X51kz9AAAAwOFRAgEAcrXLTf308uulrtW6qqJ3RbvjAQAAADkGJRAAINdJM2ladXSV5u36/6mfBiUa6IU6L6h1udbK55zP7ogAAABAjkMJBADINU7Hn9YPu37Q/F3zdSTmiArnL6yH/R9W16pdVcG7gt3xAAAAgByNEggAkKOlmTStPLpS83bO09JDS5ViUtSwREO9VOcl3VnuTqZ+AAAAgCyiBAIA5Ein4k6lr/Vz3tTPI/6PqEvVLkz9AAAAADeAEggAkGOkmTT9d/S/zKmfVJOaPvVT9yXdWZapHwAAAOBmUAIBAGx3Mu5k5id8HY09Kh83Hz0a8Ki6Vu2q8gXL2x0PAAAAyBMogQAAtjmbcFYT103Ugr0L0qd+SjbUgHoDdGfZO+Xq7Gp3PAAAACBPoQQCANhi0YFFGrdqnKKSotTLr5d6VO+hcgXL2R0LAAAAyLMogQAAt9WZhDN6ffXr+nP/n/Lz8dMnbT9RtcLV7I4FAAAA5HmUQACA28IYoz8P/KnXV72umOQYvVD7BfUO7C1XJ277AgAAAG4HSiAAwC13Ov60Xl/9uhYdWKRA30CNbTpWVQpXsTsWAAAA4FAogQAAt4wxRr/v+11vrHlDcclxernuy3rU/1G5OPGfHwAAAOB24//CAQC3xKm4Uxq7aqz+PvS3ahapqbFNx6pSoUp2xwIAAAAcFiUQACBbGWP0695f9eaaN5WYmqhX6r6iR/wfkbOTs93RAAAAAIdGCQQAyDYn405qzMoxWnZ4mYKLBmtM0zGq6F3R7lgAAAAARAkEAMgGxhj9vOdnvbX2LSWnJmtQ/UF6qMZDTP8AAAAAOQglEADgphyPPa7RK0frnyP/qE6xOhrTdIzKFyxvdywAAAAAF6EEAgDcEGOMftj9gyasnaBUk6ohDYaoZ42ecrKc7I4GAAAA4DIogQAA1+1YzDGNWjlK/x39T/VL1NfoxqNVtmBZu2MBAAAAuApKIABAlhljNG/XPL2z7h2lmTQNbThUD1R/gOkfAAAAIBegBAIAZMmRmCMa9d8orTq2Sg1LNNSoJqNUpkAZu2MBAAAAyCJKIADAVaWZNH234ztNWj9JkjS80XB1r9ZdlmXZnAwAAADA9aAEAgBc0aHoQxr13yitOb5GjUs21qgmo1TKq5TdsQAAAADcAEogAMAl0kyavt7+taZsmCIny0mjGo9Sl6pdmP4BAAAAcjFKIADABQ5GHdSI/0Zo/Yn1alq6qUY1HqUSniXsjgUAAADgJlECAQAkpU//fLntS7274V25OrlqbNOxur/y/Uz/AAAAAHkEJRAAQPsj92vEfyO08eRGtSjTQiMajVBxz+J2xwIAAACQjSiBAMCBpaalau62uXpv43vK55xPrzd7XfdWupfpHwAAACAPogQCAAe1N3Kvhv87XJtPbVarsq00otEIFfUoancsAAAAALcIJRAAOJjUtFTN2TpH7298X+6u7nqz+ZvqULED0z8AAABAHkcJBAAOZE/EHg3/d7i2nN6i1uVaa1ijYSriXsTuWAAAAABuA0ogAHAAKWkpmhU2Sx+GfCgvVy9NaDFB7Sq0Y/oHAAAAcCCUQACQx+06u0vD/x2usPAwtS3fVv9r+D/5uvvaHQsAAADAbUYJBAB5VHJasmZsmaFpm6epYL6CmthyotpVaGd3LAAAAAA2oQQCgDxox5kdGv7vcG07s03tK7TXkIZD5OPmY3csAAAAADaiBAKAPCQ5NVmfbvlUH2/+WN75vTWl1RS1Lt/a7lgAAAAAcgBKIADII7aFb9Pwf4drx9kduqfSPRpSf4gKuRWyOxYAAACAHIISCAByueTUZE3fPF2fbflMhdwKaeodU3VHuTvsjgUAAAAgh6EEAoBcLOx0mIb9O0y7I3arY+WOGlR/kLzze9sdCwAAAEAORAkEALlQUmqSpm2aphmhM+Tr5qsPWn+gFmVa2B0LAAAAQA5GCQQAucyWU1s0/N/h2hO5R52rdNbA+gNVMF9Bu2MBAAAAyOEogQAgl0hMTdQHIR9odthsFXUvqo/u+kjNSjezOxYAAACAXIISCABygU2nNmn4v8O1L3KfulbtqlfqvaIC+QrYHQsAAABALkIJBAA5WEJKgt7f+L4+3/a5insU1/S7pqtJ6SZ2xwIAAACQCzllZSPLsu62LGuHZVm7LcsacpnXe1uWdcqyrJCMryeyPyoAOJaNJzeq+y/dNXvrbHWr2k3fd/yeAggAAADADbvmJJBlWc6SPpDURtJhSWsty/rZGLP1ok2/McY8dwsyAoBDiU+J19QNU/XFti9UyquUPmn7iRqVbGR3LAAAAAC5XFZuB2sgabcxZq8kWZb1taT7JV1cAgEAbtK64+s04r8ROhR9SA9Wf1Av131ZHq4edscCAAAAkAdkpQQqLenQeY8PS2p4me26WpbVQtJOSS8bYw5dvIFlWf0k9ZOkcuXKXX9aAMij4pLj9O6Gd/Xl9i9VxquMZrSbofol6tsdCwAAAEAekqU1gbLgF0kVjDE1JS2SNPtyGxljPjbG1DPG1CtatGg2nRoAcre1x9eq689d9eX2L9XLr5fmd5xPAQQAAAAg22VlEuiIpLLnPS6T8VwmY0z4eQ8/lfT2zUcDgLwtLjlOk9ZP0jc7vlG5AuU06+5Zqlu8rt2xAAAAAORRWSmB1kqqallWRaWXPw9Keuj8DSzLKmmMOZbxsKOkbdmaEgDymFXHVmnkvyN1LPaYHvF/RM/Xfl7uLu52xwIAAACQh12zBDLGpFiW9ZykPyU5S5phjAmzLGuMpHXGmJ8lvWBZVkdJKZLOSOp9CzMDQK4VkxSjSesn6bud36lCwQqa036OgosF2x0LAAAAgAOwjDG2nLhevXpm3bp1tpwbAOzw35H/NHLlSJ2MO6lH/R/Vs8HPys3Fze5YAAAAAPIQy7LWG2PqXe61rNwOBgC4CdFJ0Zq4bqK+3/W9KnpX1Jz2c1SraC27YwEAAABwMJRAAHALrTi8QqNXjtap+FPqG9hXzwQ/o/zO+e2OBQAAAMABUQIBwC0QlRSlCWsn6MfdP6qyd2VNbjVZQUWD7I4FAAAAwIFRAgFANlt2aJnGrByj8IRwPRn0pJ6q9ZTyOeezOxYAAAAAB0cJBADZJDIxUm+teUu/7P1FVQpV0dTWUxXgG2B3LAAAAACQRAkEANliycElGrtqrCISIvRUrafUL6ifXJ1d7Y4FAAAAAJkogQDgJkQkROiNNW/ot32/qXrh6vqw9Yfy8/WzOxYAAAAAXIISCABu0OIDizV21VhFJUbpmeBn9ETgE0z/AAAAAMixKIEA4DqdSTijN1a/oT/2/yE/Hz993OZjVfepbncsAAAAALgqSiAAuA5/7v9Tr69+XVFJUXq+9vPqE9hHrk5M/wAAAADI+SiBACALwuPDNX71eC06sEgBvgH6tO2nqlq4qt2xAAAAACDLKIEA4CqMMfpj/x96ffXrik2O1Yt1XlTvgN5yceJfnwAAAAByF36LAYArOB1/WuNWjdNfB/9SUJEgjW06VpULVbY7FgAAAADcEEogALiIMUYL9i3Qm2veVHxyvAbUHaBH/B9h+gcAAABArsZvNABwnpNxJzV25VgtPbxUtYrW0pimY1TJu5LdsQAAAADgplECAYDSp39+2fuL3lzzppJSkzSw3kA97PewnJ2c7Y4GAAAAANmCEgiAwzsRe0KjV47WiiMrVKdYHY1uMloVvCvYHQsAAAAAshUlEACHZYzRj7t/1IS1E5SclqwhDYaoZ42ecrKc7I4GAAAAANmOEgiAQzoee1yj/hulf4/+q7rF62pMkzEqV7Cc3bEAAAAA4JahBALgUIwxmr9rviaum6g0k6b/NfyfelTvwfQPAAAAgDyPEgiAwzgac1Sj/hullcdWqkGJBhrVZJTKFihrdywAAAAAuC0ogQDkeWkmTfN2ztM7696RJA1vNFzdqnVj+gcAAACAQ6EEApCnHY4+rFH/jdLq46vVqGQjjW4yWqW8StkdCwAAAABuO0ogAHlSmknTNzu+0eT1k+VkOWlk45HqWrWrLMuyOxoAAAAA2IISCECecyjqkEb8N0LrTqxT01JNNbLxSJX0Kml3LAAAAACwFSUQgDwjzaTpq+1f6d0N78rZctaYJmPUqUonpn8AAAAAQJRAAPKIA1EHNOLfEdpwcoOal26uEY1HqIRnCbtjAQAAAECOQQkEIFdLTUvVF9u+0NSNU5XPOZ/GNxuv+yrdx/QPAAAAAFyEEghArrXq2Cq9s+4dbT+zXS3LtNSIxiNUzKOY3bEAAAAAIEeiBAKQ6+w+u1uT1k/SiiMrVMqzlCa0mKB2Fdox/QMAAAAAV0EJBCDXOB1/Wh+GfKj5u+bL08VTr9R9RT39eiq/c367owEAAABAjkcJBCDHi0+J1+dbP9dnWz5TUmqSetboqf41+6uwW2G7owEAAABArkEJBCDHSjNp+nXvr5q6YapOxJ1Q63Kt9XLdl1W+YHm7owEAAABArkMJBCBHWn1stSaum6jtZ7Yr0DdQb7V4S3WL17U7FgAAAADkWpRAAHKUvRF7NWn9JC07vEylPEvpreZv6e6Kd8vJcrI7GgAAAADkapRAAHKE8PhwfbTpI83bOU/uLu56ue7L6uXXi0WfAQAAACCbUAIBsFVCSkL6os+hnykxJVEPVH9AT9d6mkWfAQAAACCbUQIBsEWaSdOCvQv07oZ3dSLuhO4oe4dervuyKnpXtDsaAAAAAORJlEAAbru1x9dqwtoJ2nZmm/x9/fVG8zdUv0R9u2MBAAAAQJ5GCQTgttkbuVeT103W0sNLVdKzpN5o/oY6VOzAos8AAAAAcBtQAgG45S5e9PmlOi+pl18vubm42R0NAAAAABwGJRCAWyYhJUFzt83Vp1s+VUJKgrpX666ng5+Wj5uP3dEAAAAAwOFQAgHIdmkmTb/t+01TN0zVsdhjalW2lV6u+7IqeVeyOxoAAAAAOCxKIADZau3xtZq4bqK2hm+Vn4+fxjcbz6LPAAAAAJADUAIByBb7Ivdp0vpJWnpoqUp4ltDrzV7XPZXuYdFnAAAAAMghKIEA3JQzCWf0UchH+m7nd3JzcdOLdV7Uw34Ps+gzAAAAAOQwlEAAbkhiaqLmbk1f9Dk+JV7dqnXT07Welq+7r93RAAAAAACXQQkE4LqkmTT9vu93vbvh3fRFn8tkLPpciEWfAQAAACAnowQCkGXrjq/TO+veUWh4qPx8/DS26Vg1LNnQ7lgAAAAAgCygBAJwTfsj92vy+slacmiJinkU0/hm43VvpXtZ9BkAAAAAchFKIABXdDbhrKZtmqZvd3yrfM759Hzt5/WI/yNyd3G3OxoAAAAA4DpRAgG4RGJqor7c9qU+2fyJYlNi1a1qNz0d/LSKuBexOxoAAAAA4AZRAgHIZIzJXPT5aOxRtSjTQgPqDlDlQpXtjgYAAAAAuEmUQAAkSRtObNDEdRO15fQWVS9cXZ80/USNSjayOxYAAAAAIJtQAgEO7kDUAU1ZP0WLDy5WMY9iGtd0nO6tdK+cnZztjgYAAAAAyEaUQICDikiI0PTN0/X19q/l6uyq54Kf06MBj7LoMwAAAADkUZRAgINJSk3Sl9u+1MebP1ZsSqy6VO2iZ4OfZdFnAAAAAMjjKIEAB2GM0Z/7/9SUDVN0JOaImpVuplfqvqIqhavYHQ0AAAAAcBtQAgEOYOPJjZq4dqI2n96saoWraXqb6WpSqondsQAAAAAAtxElEJCHHYw6qCkbpmjRgUUq5l5MY5qMUcfKHVn0GQAAAAAcECUQkAdFJkZq2qZp+nrH13J1ctUzwc/oMf/H5OHqYXc0AAAAAIBNKIGAPCQpNUlfbf9K0zdPV2xyrDpX6axng59VUY+idkcDAAAAANiMEgjIA4wxWnhgoaasn6LDMYfVtHRTDag7QNUKV7M7GgAAAAAgh6AEAnK5kJMhmrhuojad2qSqhatq+l3T1aQ0iz4DAAAAAC5ECQTkUoeiDmnKhilaeGChiroXZdFnAAAAAMBVUQIBuUxkYqSmb56ur7Z/lb7oc61n9FgAiz4DAAAAAK6OEgjIJZJTkzMXfY5OilbnqumLPhfzKGZ3NAAAAABALkAJBORwxhgtOrBIUzZM0aHoQ2pcsrFeqfeKqvtUtzsaAAAAACAXoQQCcrBNpzZp4tqJCjkVoiqFqmjaXdPUtHRTu2MBAAAAAHIhSiAgBzocfVhTNkzRn/v/VBH3IhrVeJQ6VenEos8AAAAAgBtGCQTkIJGJkfpk8yf6cvuXcrac9VStp9QnoA+LPgMAAAAAbholEJADJKcm65sd32ja5mmKSozS/VXu13PBz6m4Z3G7owEAAAAA8ghKIMBGxhgtPrhYk9dP1qHoQ2pUspEG1hvIos8AAAAAgGxHCQTYZPOpzZq4bqI2ntyoyt6V9WHrD9WsdDNZlmV3NAAAAABAHkQJBNxmh6MPa+qGqfp9/+/ydfPViMYj1LlKZ7k48Y8jAAAAAODW4bdO4DaJSorSp5s/1dxtc+VsOatfzX7qG9hXnq6edkcDAAAAADgASiDgFktOTda3O7/VR5s+UlRilDpW7qjnaj+nEp4l7I4GAAAAAHAglEDALWKM0ZKDSzR5w2QdiDqghiUbamC9garhU8PuaAAAAAAAB0QJBNwCoadDNWHtBG04uUGVvCvpg9YfqHnp5iz6DAAAAACwDSUQkI2OxBzRuxve1e/7fpePm4+GNxquLlW7sOgzAAAAAMB2/GYKZIOopCh9uuVTfbH1C1mWpSeDnlTfwL7yyudldzQAAAAAACRRAgE3JTktWd/t+E4fbfpIkYmRuq/yfXq+9vMs+gwAAAAAyHEogYAbYIzR34f+1uT1k7U/ar8alGigV+q9In9ff7ujAQAAAABwWZRAwHUKOx2mCesmaP2J9aroXVHv3/m+WpRpwaLPAAAAAIAcjRIIyKKjMUc1deNULdi7QD5uPhrWcJi6VuvKos8AAAAAgFyB316Ba4hOitZnWz7T51s/Z9FnAAAAAECuRQkEXEFyWrLm75yvD0M+1NnEs7qvUvqizyW9StodDQAAAACA60YJBFzEGKOlh5Zq0vpJ2h+1X/WK19PA+gMV4BtgdzQAAAAAAG4YJRBwnrDwML2z7h2tPb5WFQpW0Ht3vqeWZVqy6DMAAAAAINejBAIkHY89rnc3vKtf9/6qwvkLa2jDoeparatcnVztjgYAAAAAQLagBIJDS0hJ0MebP9acrXNkjNHjgY/r8aDHVSBfAbujAQAAAACQrSiB4LB2nt2pQcsGaU/kHt1T6R69UPsFlfIqZXcsAAAAAABuCUogOBxjjL7a/pXeWfeOCuQroOl3TVeT0k3sjgUAAAAAwC1FCQSHcibhjEb8O0LLDi9T89LNNbbpWPm6+9odCwAAAACAW44SCA5j5dGVGvrPUEUkRmhIgyF6qMZDfOoXAAAAAMBhUAIhz0tOTdZ7G9/TzLCZquRdSR/d9ZGq+1S3OxYAAAAAALcVJRDytANRBzRo+SBtDd+q7tW669X6r8rdxd3uWAAAAAAA3HaUQMiTjDH6ac9Pen3163J1ctXkVpN1V/m77I4FAAAAAIBtKIGQ50QlRWncynH6ff/vqle8nt5o/oZKeJawOxYAAAAAALaiBEKeEnIyRIOXD9aJuBN6ofYL6hvYV85OznbHAgAAAADAdpRAyBNS01L18ZaPNX3TdJXwLKHZ7WerVtFadscCAAAAACDHoARCrncs5piGrBiiDSc3qEPFDhrWaJgK5CtgdywAAAAAAHIUSiDkagv3L9SolaOUmpaq15u9rvsq32d3JAAAAAAAciRKIORKcclxemvtW/p+1/cKKhKkt5q/pbIFy9odCwAAAACAHIsSCLnO1vCtGrx8sA5EHdATQU/omeBn5OrkancsAAAAAAByNEog5BppJk2fb/1cUzZMkU9+H33S9hM1LNnQ7lgAAAAAAOQKlEDIFU7Hn9awf4bp36P/6o6yd2hMkzEq5FbI7lgAAAAAAOQalEDI8VYcXqFh/w5TbHKshjcaru7VusuyLLtjAQAAAACQq1ACIcdKSk3S5PWTNXfbXFUtXFWftf1MVQpXsTsWAAAAAAC5EiUQcqS9EXs1aPkg7Ti7Qw/VeEgD6g1Qfuf8dscCAAAAACDXogRCjmKM0bxd8/T2mrfl7uKu9+98Xy3LtrQ7FgAAAAAAuR4lEHKMyMRIjfpvlBYfXKxGJRvp9Wavq6hHUbtjAQAAAACQJ1ACIUdYe3ytXlvxmsLjwzWg7gA9FvCYnCwnu2MBAAAAAJBnUALBVslpyZq2aZo+2fyJyhUsp7kd5iqgSIDdsQAAAAAAyHMogWCbw9GHNXjFYG0+tVmdqnTSaw1ek4erh92xAAAAAADIkyiBYIsFexdo3KpxsmTp7RZvq33F9nZHAgAAAAAgT6MEwm0Vmxyr11e/rp/3/KzgosF6s8WbKu1V2u5YAAAAAADkeZRAuG1CT4dq0PJBOhJzRE/Xelr9avaTixM/ggAAAAAA3A78Bo5bLs2kaWboTL2/8X0V8SiiGe1mqG7xunbHAgAAAADAoVAC4ZY6EXtCQ/8ZqtXHV6tt+bYa0XiEvPN72x0LAAAAAACHQwmEW2bJwSUa+d9IJaYmanST0epcpbMsy7I7FgAAAAAADokSCNkuISVBE9dN1Dc7vpGfj5/eavGWKnpXtDsWAAAAAAAOjRII2Wrn2Z0avHywdkfs1mP+j+mFOi8on3M+u2MBAAAAAODwKIGQLYwx+mr7V3pn3TsqkK+Apt01TU1LN7U7FgAAAAAAyEAJhJt2NuGsRvw7QksPL1Wz0s00ruk4+br72h0LAAAAAACchxIIN2Xl0ZUa+s9QRSRGaHD9werl14vFnwEAAAAAyIEogXBDklOT9V7Ie5oVOksVvCvoo7s+UnWf6nbHAgAAAAAAV0AJhOt2IOqABi8frLDwMHWr1k2D6g+Su4u73bEAAAAAAMBVUAIhy4wx+nnPzxq/erxcnVw1udVk3VX+LrtjAQAAAACALKAEQpZEJ0Vr7Mqx+n3/76pXvJ7eaP6GSniWsDsWAAAAAADIIkogXFPIyRANWTFEx2OP64XaL6hvYF85OznbHQsAAAAAAFwHSiBcUWpaqj7Z8ommbZqmEp4lNLv9bNUqWsvuWAAAAAAA4AZQAuGyjsUc05AVQ7Th5AZ1qNhBwxoNU4F8BeyOBQAAAAAAbhAlEC6xcP9CjVo5SqlpqXq92eu6r/J9dkcCAAAAAAA3iRIImeKS4/T22rc1f9d8BRUJ0lvN31LZgmXtjgUAAAAAALIBJRAkSdvCt2nQ8kE6EHVAjwc+rmdrPytXJ1e7YwEAAAAAgGxCCeTg0kya5m6dqykbpqhw/sL6pO0naliyod2xAAAAAABANqMEcmCn409r2L/D9O+Rf9WqbCuNaTJGhd0K2x0LAAAAAADcApRADuqfI/9o6D9DFZscq2ENh+mB6g/Isiy7YwEAAAAAgFuEEsjBJKUmafL6yZq7ba6qFKqiT9t+qqqFq9odCwAAAAAA3GKUQA5kb8ReDVo+SDvO7lDPGj01oO4Aubm42R0LAAAAAADcBpRADsAYo/m75uutNW/JzcVN7935nlqVbWV3LAAAAAAAcBtRAuVxkYmRGr1ytBYdWKRGJRtpfLPxKuZRzO5YAAAAAADgNqMEysPWHV+nISuGKDw+XAPqDtBjAY/JyXKyOxYAAAAAALABJVAelJKWoo82faRPt3yqsgXKam6HuQooEmB3LAAAAAAAYCNKoDzmcPRhDVkxRJtObVKnKp30WoPX5OHqYXcsAAAAAABgM0qgPOS3vb9p7KqxkqS3W7yt9hXb25wIAAAAAADkFJRAeUBscqxeX/26ft7zs4KLBuvNFm+qtFdpu2MBAAAAAIAchBIolws9HarBywfrcMxhPVXrKfWv2V8uTnxbAQAAAADAhWgLcqk0k6ZZYbP03ob3VMSjiGa0m6G6xevaHQsAAAAAAORQlEC50Mm4k/rfiv9p9fHValO+jUY2Hinv/N52xwIAAAAAADkYJVAu8/fBvzXivxFKTE3U6Caj1blKZ1mWZXcsAAAAAACQw1EC5RIJKQmauG6ivtnxjWr41NBbLd5SJe9KdscCAAAAAAC5BCVQLrDr7C4NWj5IuyN261H/R/VinReVzzmf3bEAAAAAAEAuQgmUgxlj9PWOrzVx7UR55fPSR3d9pGalm9kdCwAAAAAA5EKUQDnU2YSzGvHvCC09vFTNSjfT2KZjVcS9iN2xAAAAAABALkUJlAOtOrZK/1vxP0UkRmhQ/UHq5ddLTpaT3bEAAAAAAEAuRgmUgySnJuv9kPc1M3SmKnhX0Id3fagaPjXsjgUAAAAAAPIASqAc4mDUQQ1aPkhh4WHqVq2bBtUfJHcXd7tjAQAAAACAPIISyGbGGP2852e9vvp1uTi5aHKrybqr/F12xwIAAAAAAHkMJZCNopOiNXbVWP2+73fVK15PbzR/QyU8S9gdCwAAAAAA5EFZWm3Ysqy7LcvaYVnWbsuyhlxlu66WZRnLsuplX8S8KeRkiLr/0l0L9y/U87Wf16dtP6UAAgAAAAAAt8w1J4Esy3KW9IGkNpIOS1prWdbPxpitF21XQNKLklbfiqB5RWpaqj7d8qk+2vSRSniW0Ky7Zym4WLDdsQAAAAAAQB6XlUmgBpJ2G2P2GmOSJH0t6f7LbDdW0luSErIxX55yPPa4Hl/4uN4PeV/tKrTTd/d9RwEEAAAAAABui6ysCVRa0qHzHh+W1PD8DSzLqiOprDFmgWVZr2Zjvjxj8YHFGvnfSKWkpWh8s/G6r9J9sizL7lgAAAAAAMBB3PTC0JZlOUmaJKl3FrbtJ6mfJJUrV+5mT50rxCXH6e21b2v+rvkK9A3UWy3eUrmCjvHeAQAAAABAzpGVEuiIpLLnPS6T8dw5BSQFSlqaMdlSQtLPlmV1NMasO/9AxpiPJX0sSfXq1TM3kTtX2H5muwYtH6T9kfv1eODjejb4Wbk6u9odCwAAAAAAOKCslEBrJVW1LKui0sufByU9dO5FY0ykpCLnHluWtVTSwIsLIEeSZtI0d+tcTdkwRYXyF9LHbT9Wo5KN7I4FAAAAAAAc2DVLIGNMimVZz0n6U5KzpBnGmDDLssZIWmeM+flWh8xNTsef1rB/h+nfI/+qVdlWGtNkjAq7FbY7FgAAAAAAcHBZWhPIGPObpN8uem7EFbZtdfOxcqd/jvyjof8MVWxyrIY2HKoe1Xuw+DMAAAAAAMgRbnphaEhJqUmasmGKPt/6uaoUqqJP236qqoWr2h0LAAAAAAAgEyXQTdobuVeDlw/W9jPb1bNGTw2oO0BuLm52xwIAAAAAALgAJdBNiEyMVK8FveTi5KL37nxPrcq2sjsSAAAAAADAZVEC3QTv/N4a2Xik6hSvo2IexeyOAwAAAAAAcEWUQDfp7op32x0BAAAAAADgmpzsDgAAAAAAAIBbjxIIAAAAAADAAVACAQAAAAAAOABKIAAAAAAAAAdACQQAAAAAAOAAKIEAAAAAAAAcACUQAAAAAACAA6AEAgAAAAAAcACUQAAAAAAAAA6AEggAAAAAAMABUAIBAAAAAAA4AEogAAAAAAAAB0AJBAAAAAAA4AAogQAAAAAAABwAJRAAAAAAAIADoAQCAAAAAABwAJRAAAAAAAAADoASCAAAAAAAwAFQAgEAAAAAADgASiAAAAAAAAAHQAkEAAAAAADgACiBAAAAAAAAHAAlEAAAAAAAgAOgBAIAAAAAAHAAlEAAAAAAAAAOgBIIAAAAAADAAVACAQAAAAAAOABKIAAAAAAAAAdACQQAAAAAAOAAKIEAAAAAAAAcACUQAAAAAACAA6AEAgAAAAAAcACUQAAAAAAAAA6AEggAAAAAAMABUAIBAAAAAAA4AEogAAAAAAAAB0AJBAAAAAAA4AAogQAAAAAAABwAJRAAAAAAAIADoAQCAAAAAABwAJRAAAAAAAAADoASCAAAAAAAwAFQAgEAAAAAADgASiAAAAAAAAAHQAkEAAAAAADgACiBAAAAAAAAHAAlEAAAAAAAgAOgBAIAAAAAAHAAlEAAAAAAAAAOgBIIAAAAAADAAVACAQAAAAAAOABKIAAAAAAAAAdACQQAAAAAAOAAKIEAAAAAAAAcACUQAAAAAACAA6AEAgAAAAAAcACUQAAAAAAAAA6AEggAAAAAAMABUAIBAAAAAAA4AEogAAAAAAAAB0AJBAAAAAAA4AAogQAAAAAAABwAJRAAAAAAAIADoAQCAAAAAABwAJRAAAAAAAAADoASCAAAAAAAwAFQAgEAAAAAADgASiAAAAAAAAAHQAkEAAAAAADgACiBAAAAAAAAHAAlEAAAAAAAgAOgBAIAAAAAAHAAlEAAAAAAAAAOgBIIAAAAAADAAVACAQAAAAAAOABKIAAAAAAAAAdACQQAAAAAAOAAKIEAAAAAAAAcACUQAAAAAACAA6AEAgAAAAAAcACUQAAAAAAAAA6AEggAAAAAAMABUAIBAAAAAAA4AEogAAAAAAAAB0AJBAAAAAAA4AAogQAAAAAAABwAJRAAAAAAAIADoAQCAAAAAABwAJRAAAAAAAAADoASCAAAAAAAwAFQAgEAAAAAADgASiAAAAAAAAAHQAkEAAAAAADgACiBAAAAAAAAHAAlEAAAAAAAgAOgBAIAAAAAAHAAlEAAAAAAAAAOgBIIAAAAAADAAVACAQAAAAAAOABKIAAAAAAAAAdACQQAAAAAAOAAKIEAAAAAAAAcACUQAAAAAACAA6AEAgAAAAAAcACUQAAAAAAAAA6AEggAAPxfe3cbJNl12Pf5f7pnZneBxRvJFQUuQBCmaSdIHOsFphTFkp1Ilkg5RTop20VWElOJUowSMbFLlYrpOKW4mC+2HDsVV7ES0yWWpZQp6iVWBUkg03LkipNKaAGiGNMkRRN8MwBSJEiCBJbA7kx3n3y4t2du93TPzuzOzuzueZ6qqe6+fbv7zuKiZ/o3554LAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAacKgIVEp5UynlU6WUp0op715x/0+UUj5WSvloKeX/LqU8cvybCgAAAMC1umoEKqWMk7w3yZuTPJLk7SsizwdqrX+g1vodSX4myV8/7g0FAAAA4NodZiTQG5M8VWv9bK11O8kHk7x1uEKt9YXBzTuT1OPbRAAAAACu18Yh1rmY5OnB7WeSfM/ySqWUn0zyU0m2kvwbx7J1AAAAAByLY5sYutb63lrr65P8+ST/1ap1SinvLKU8WUp58rnnnjuulwYAAADgKg4TgZ5N8uDg9gP9snU+mORPrLqj1vq+WuujtdZHL1y4cOiNBAAAAOD6HCYCPZHkDaWUh0spW0neluSx4QqllDcMbv7xJJ8+vk0EAAAA4HpddU6gWuuklPKuJB9KMk7y/lrrx0sp70nyZK31sSTvKqX8UJKdJM8neceN3GgAAAAAjuYwE0On1vp4kseXlv304PqfPebtAgAAAOAYHdvE0AAAAADcvEQgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAYcKgKVUt5USvlUKeWpUsq7V9z/U6WUT5RS/kkp5f8opTx0/JsKAAAAwLW6agQqpYyTvDfJm5M8kuTtpZRHllb77SSP1lr/lSS/kuRnjntDAQAAALh2hxkJ9MYkT9VaP1tr3U7ywSRvHa5Qa/2HtdaX+psfTvLA8W4mAAAAANfjMBHoYpKnB7ef6Zet8+NJfu16NgoAAACA47VxnE9WSvl3kzya5I+suf+dSd6ZJK997WuP86UBAAAAOMBhRgI9m+TBwe0H+mULSik/lOQvJnlLrfXKqieqtb6v1vporfXRCxcuXMv2AgAAAHANDhOBnkjyhlLKw6WUrSRvS/LYcIVSyncm+ZvpAtBXjn8zAQAAALgeV41AtdZJkncl+VCSTyb5pVrrx0sp7ymlvKVf7a8mOZ/kl0spHy2lPLbm6QAAAAA4BYeaE6jW+niSx5eW/fTg+g8d83YBAAAAcIwOczgYAAAAALc4EQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgAYeKQKWUN5VSPlVKeaqU8u4V9/9AKeUjpZRJKeVPHv9mAgAAAHA9rhqBSinjJO9N8uYkjyR5eynlkaXV/nmSH0vygePeQAAAAACu38Yh1nljkqdqrZ9NklLKB5O8Nckn5ivUWj/f3ze7AdsIAAAAwHU6zOFgF5M8Pbj9TL/syEop7yylPFlKefK55567lqcAAAAA4Bqc6MTQtdb31VofrbU+euHChZN8aQAAAICmHSYCPZvkwcHtB/plAAAAANwiDhOBnkjyhlLKw6WUrSRvS/LYjd0sAAAAAI7TVSNQrXWS5F1JPpTkk0l+qdb68VLKe0opb0mSUsofKqU8k+RPJfmbpZSP38iNBgAAAOBoDnN2sNRaH0/y+NKynx5cfyLdYWIAAAAA3IROdGJoAAAAAE6HCAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAasHHaG3DL+7m3JFvnk/te13891F3e+9pk89wpbxwAAABARwS6HrNZsnVn8vXPJp/5jWTy8uL9d90/iEOvS+59aO/6+VcnIwOxAAAA4FRNriQvfLH7rF7KaW/NDSUCXY/RKHn7L3TXa02+9Vzy/Of3f33u/0r+vw8mqXuP3Ti7GIXue2gxFp05f5LfCQAAANx+ppPkxS8lLzybfPOZ/vLZwe0vJt/6Srfuf/5Ucv7C6W7vDSYCHZdSkvPf1n09+Mb990+uJN94ug9Dn9sLRN/4QvKF/yfZfnFx/TsvrB5BdN/rkrtfk4zGN/b7AQAAgJvZbNYFnG8+m7zwzFLc6WPPpd9N6mzxcWfuTu6+mNxzMbn/Dyb3PNB9zt48ezrfxwkSgU7KxpnkVb+3+1pWa/Ly84tx6PnPJ89/IXn6N5N/+neTOt1bf7TZzTl031Icmn+dvefGfz8AAABwo9SavPS1pdE7w9DzbPLiF5PZZPFxG+e6uHP3xeT1//pe7Ln7gb3lZ+8+ne/pJiAC3QxKSe54Rfd18bv33z/d6Xb8YSD6xhe6yy/+dheQhs7dt3/00PzrngeS8eYN/XYAAABgrVqTy99cE3f66PPCF5PJ5cXHjbe6ETt3P5A89K/21y/2I3n6y3P33fbz+lwPEehWMN5MXvFw97XKy9/Yi0LPf2EvFP3ux5Lf+d+T2c7eumXc1c9Vgei+h/0PAwAAwPW5cmnFHDyD0PPCF5PtS4uPKePu5Er3XEzu/47kX/jji6N37nkgueNVTrB0nUSg28G5e7uv+//g/vtm0+5/sOHoofnXp36tm8x6aOuu/RNV3/dwd/ve13aHtQEAANCmnct9yFlziNYLz3SjfBb0c+jefTG58PuT1//gYty5+2Jy17eb+/YEiEC3u9E4uffB7ivfv//+K5f6OLQUiL766eSpf7A0/K50w+2WRxDNDz07/21GEQEAANyqpjvdIIKDDtN66Wv7H3fHK7uQc99DyUPft38OnrvuTza2Tv77YR8RqHVnziev/pe6r2XzmdZXnfb+M7/RnWZvaPOOFXMRPbQXirbuuKHfCgAAAGvMpsmLv9tHnnVn0vpykrr4uDP37MWci9+1/xCtu1+TbJ47lW+JoxOBWG806obk3fXtyWu/d//9Oy8PTnu/9PW5f5TsfGtx/fOvXn/a+7vud2wnAADAtZjNkpe+epUzaX1p8azTSbJ5517QecO/uDrwnLnrdL4nbggRiGu3eS658Pu6r2Xz0/nthqHP7U1c/YX/N/nYLyd1trf+eKsPQyvOanbvQ02fwg8AAGhYrd0ZoXcDzzP7D9l64YvJdHvxceMzXcS554HkdX94/xw891xMzt5rSo/GiEDcGKUkd76q+3rg0f33T7aTbz69+rT3Tz+RXFmaSOyOV64/7f3dF5OxXRkAALgFXX7h6qdK33lp8TGjjeSu13Qh5+KjySN94JnHnbsf6D6LCTws8cmZ07Gxlbzy9d3XKi8/v3SIWR+IvvjbyScfS2aTvXVHG13NXnna+9d1p70HAAA4adsvrThV+rOL16+8sPSg0k3JcffFbu7WN/zI/lE857/NmbS4JiIQN6dz93Vfr/nO/fdNJ92b5fIIouc/n3zyf90/W/2Ze1YfZnbf65J7HjRLPQAAsGg2TSZXurMlT7e7y8n20u3Bssnlbs6d5VOlv/z8/ue+80J3mNYrfk/y8PfvP0TrrvuT8ebJf880QQTi1jPe6KPOQ0n+yP77L78wCEODQPSVTyb/7O8tHitbRt2b7Ln7ugnP9n3dnWyd379seHvrvEmtATg5tXYfNnZeXrq8nEyG11ets+Zyup2UcTe6djTuvzYGX4e8XcZHeMxw2fLlIV979/X8HIbbxmyWTK8sBZYr/bIr68PM7jqrYs01PM/wyIOjOHvvXtB58A+tCDyvSTbPHus/GRyFCMTt5+zdybf/ge5r2WzWFfrh6KFv/PMuHF15Ibn0leRrn0muvNh9TV4+3GtuDSPR+fXBaF1Emi8zKgng1lJrMt3pfl7MI8zC5WFjzNJjJ1fWrzu5fO3bO9pINs51H0B2L892J2ios+5Dz2zanT1mNtm7vXt9xe3hiR5OTbmGaHW9oeuIwWpt6LrK7XKYbRXCOAa78eXKilgyDCzr1hkGletYZ7ZzPN/PxtluYuSNwdfu7bPJ1h3JHa/o3v82zna/h696zPw9cuPsiudZun3Xtydbdx7P9sMNIgLRltGoK/D3XEwe+r6rrz+dJNsv7kWh3a8X1iy7tHf7xS8v3pd69dcbnzk4GO1GpqvEpc07TAIHtGk2XRNPrhwQaq52OQ85a9a55ghSujNtbpxdujzTBZo7XrHivqtdnlkReQaXN+JECrPZimi0HI4OE5NWPe5qtyfd6x/5MdPBa/a3d7aP8BxLr7l8yuXTUkb913hwvf8ajfYv2123rFh//hzL9y0/dxmse8ivozz3wvpH2e7l51/1HOu2fc327Vu3HPDc6/7N12zfaNztS5PlYLIqxAzuXxtrjrJOf3v5zFLXanxmKaosRZaNs91omX0RZdVjVoWYQ6wz3vS7MKwhAsFBxht78xNdj1qT7W8tRqN9cWlVWHqxO5Z4GJemV67+emV0wOFsVxuhNFh/6y5nXgOu3brDlvYFlcMetnRQyOnXuZ6/II/P7B8hM48rW+e7ORxWxpdVweXsmnUHl+Ot2+NDymiUZNT2/BW1Hi4+1asFq4MC1CFGZ9XZiq/aRapV981WrT8brF+X1l9+ntq97nT7mJ+7Lq279MVq4+WosiKynL1nEEzWjZJZDjPr1lkTZm6H9zW4jfl0ByehlD6unE9y//U91+RKH4XWjUZ6Mdm+tH/Z5W8k33x6EKEuHe71Nu9YH4yuNl/ScNnGGb8UtGL+y/vCISXTvWXDv/jX6d4oglqT1MUPAAu3l+4/cN357RWPO5Z159uQI6w7eI1jX3eW1Bxh3UN8r0dZt866D4E37LCleVAZRJaz96wf7XLUGDNfx+E0XKtSuj+a+MPJybjueHVAHJtN9z9+ZZCqBzz3mq+Voat/7tm0C6mHGgGzItaMt7yHAYfiJxXcauY/8O985fU9z2zax6IVweigEUrbl7q5lHbj0gs51DD40eZglNGqWHSV+ZJOeiLu2eCXsoVoMRtEjYOWzR87XXqe2SGXTddsw3zZYbZhxbKrbeORlk0Wt3G+zF9pj6AsHhKQsnR9fl+5CdZdcQjEcN3x1sGB5VDB5gYftgTcHuajzwA4Mr9hQatG4+4v6Wfvub7nmR/usTIarRux9OL+ibi3LyU7Lx3uNRcm4r6r+6B5tUBxqLAyWHbTm89jMJgwdHe+gnXLNvbmM1heNtroR2tdZb0y7n75Hk5WeqRlS9d3L5fDwtVu5wjrHhQ71sWPHGHdwWscat1hgAEAgJMjAgHXp/QTm26eS85/2/U916En4l6KSzsv9yFhcylWzEPGIZatChMrlx0ltvQh5FDLjrBd8+cAAAA4AhEIuHkc10TcAAAA7ONPyQAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAAzZOewNudT/5gY9kZzLL5niUjXHJxmiUrY3ucmNcuuWjko3xKJvzy3HZWzbev+7meLT7fOvun7/W5rh7nvny8aic9j8JAAAAcBMSga7Tl795OZeuTLIznWUyq9mZzLIzq5lMZ5lMa3Zm3eVkVk9ke0pJNgfRaFVEWhei1q27NQ9N47Lw3KtD1urn2tz3+IO2q7ssRdACAACA4yICXadf+Y+/71Dr1dqFoIUwNN0LRjvTmkm/fHt68P3z4DRcvjOtfWzqru9MZwuP71539XNd3pllMp0sLp/NsjMZPvfec51Qz8p4VBZGPm0ORlMNg9LeKKsD4tRyGFt6rjMb45zdHB3p8szGKCMjrwAAALhFiEAnpJRu9MvmODmX8WlvznWZzYYha+/66ji1F6hWxa+rPX4hiq0IUsO4NZnWXJpMVj7X7kitpee6XlvjUc4sxKFDBKTNcc5udJdnNhZv77tc8zwO++NmV2vd/X9vZzrb/f949/Zk7z1ie9L9vzg/lHZzvHdY7eZGF243++sbo5KtsQALAADXQgTiyEajkjOjcc7c4ntPrTXTWfdBdXsyy+XJNFd2VlzuTHNlsv7yymSayzvd5ZWdxdtfvTRZuD28vB6b/eilMxujnB3EpO72EUc0HTJYnd0YZWNsLvnTsLCvzkf59UFlGFe2p7PsTLrgOb8+D6rbK67PRwxuD+LMzsL1pduTfpTg/Pp0tjtqcHlbbvQhsPORglvjxcNON+cjAvtDWYcjCdetuzBCcHAI7PL1zaXDW7fm87FtLD73wuuMRtnc2Bul6DBXAABO0y3+MR6uXSmlP5wsObc1zj3ZPLHXrrX7kL4uHq283Jnm8mS2OlQNnuPKzizPv7S9dr16HZ/Nx6OyEJ72B6jly+sLUWc2Rzm7MT72OaJmfSTZncdrVUzpR53Nr3dxpQ8mS9fn0WN7siaeXOX69mRvpNp8XrHd6/1ouev573Y1Wxvd4ZHdqJv9sWQvhJSc39zYFzwWQsvG3qGY8+vLUWZVUEkyGCm09280Hw04vD5Z8W/Yxa3V13cm3SjB5ZA1WfXvfwwjBA8ynPdsa2PUj3ZaDEYbo/7fdTAyajlY7Y9eq0LX6ji2OQ9YK66veg0jDwEAbh8iEJyCUuYjecbJCcennWk9MDgdKkjtXi6OjPrmyzu5smLE1OWd6XXNJTUqWYhCy5fjUVmYD2tlbJn0o1am3aiaG2U4j9U8kGxu9IczjRc/8J/dHOWusxsrPrAv3l4ejbIbD/rru2cO3FiMMlsrnmtz3Mee/vFjo1MWzOdvWxejhqFw1fWFMDUYZTW/Plmxf64KXTvTLvhe6udr2x+9un16HjNv5D5dSvYFpuH1jVG3H87/nzy3Oc65rXHObvSX/aGtw+Vnt7rRhee2xjm3OV9nfv9odz2H/QEAHC8RCBpSSsnWRveB7a6zJ/vaO9P90eig0UyHD1HT7Exn2RyPcnZzGF760S3D8HLAaId9o19WzU/TX18eUTE8+50Prbe2vfnbbq1DH6ezxTg0D567o9aW5mBadX03Ng0OKbx66OrW2+4PjX3x8iTPvXgll3emeXlnmpe3uxGM25NrOwR2a6OPR31I2o1F82DULzu3tPzMUmDaC02jlYFqazwSQ7ml1X64qP0YgKsRgYATMY8r52/1yaTgJjQelYxH/UkHzpzutqwyndXdUYEv95eXd2Z7oahffmW+bLju9mDd3cdO89yLk93HX5l0ly9f46jDUcn+EUn96KWzCyGpXzYIScNAdW7w+FXh6uymif1vBfsOGT5kVF05am9lSF09cnDVvG/7Rg7ujgLsX3dwCHGt6c+QOjjcdrR3eOjG4PbCGVNHS4eMrniO4SGjK8+6OhrMlTZYZ2++teXX2RtJOB+dujEu5k4DOAE+jQEAN9R4VHLnmY3ceYMj8PyQ12Es2gtNs8VlO3vLhiFqIUZtT3PpSje66cpkthua5iMar8XWeLQ3Iml5lNK+Q+bGObe1KkZ1yxdGRg3v37o5RjcNzxK4cn6vfs6uhfAxDxuDieznh2juXl+aO21v5NrBIeUwh2WexuGVwznZ5odXzmPNnWc2BiFn/zxrw0nsU0p3ttTZ4ve1/4yre+tc3pll0h92uu6srLvPc4Pnp5sbRqV1IWv+b7QQp5ai0+byc2zMA9fi5P4b41URbP06B0UvIQsOb3jik+F7/7qpHYZzdS7M27nmEPx1gf3g2F7zgf/we3LfnVun/c9zQ4lAAMBtYXjI6z3nbux8a7NZzeXJ/hFNC6OchjFqMKJpX6CazHJ5e5qvfWs7Lz+/FKh2ptcUJcpgdNPyaKXukLn5iKVu+dZ4lMms7oaZfaNfBvFkeP2gydtv9FkC102EvvfhfG/Z2c1RNs9u9JPW70WD4eG+w/nblp/j6q/VxkTr0+XANFsc4bQvJE27YDcMb/viUr+vDCPdUUPWpcuTlc99M4Ss+b6zb8RVH4yG+9LGqGRUuvn6Rv1ZMMelu757OUo2RqN+vezeN+4fuzGarzd8bDIej/r1svsa433rLb723np7jxn1J1a56mNKyWiUhdcwD+GNM5/TcPk9+aB5DNcd6r18iPjiCUv62yuuD0+Ssnx93wjGE/j/cXMQgXfn0Fxzxthzm+PdeTpbIAIBABzRaFRyx9ZG7jiBPxbuTGdrD43rRi7Ng9Js6ZC7wfJJ//jJNN+6MslXL23vPW5nmu3JLOPR+vAxPMPfua1+FMqon39tfujP/Ox2S2cJ3P2gO5irbTh5/XJIWTeH28Zgm4y2OB3zQ0/Pbo5Pe1Ou2Y0MWfMPzAeFrOGohvk6L+9MM7m8NxJt1o+QmM5qprVmNsvgevdhf9bfHq5/g7vrsSglCwFpGK3mYWtcSsarQlMfoFaFpnkAG48WQ9rCawxCWveco5UhbXUgm+//o30hbf7apZRMZ3ujGIcjGuf/zZdD+rrRiYcZsbI8kvFGWo4mw5Fxy+/Td2xtrHwvH/4cWb6+6sQnu+F0cEKT3etLZ1Zdvu5nxMFEIACAm9j8F+m7z57c2SThdnU7hKx15ofX7IajYUxaikuzuiIm7T5mlmkfnmaD55xO90LUMEBNpvP1snf/IGJNB68zj1h762X3NSZL663d/pr+eWaZzbpQvi+eLT3PbJZM+u9rtrRNw9c9iZFiW+O9oLEx6mPIIJivPSS0Pwvs8Iywu4c6Lh1aui6orwrwq64P/xAgqNx+RCAAAIBbXOlHyviAd+2GIW03Pg2C2kI8WxGshof9bY73j2RxSBw3A+8RAAAANE9IowVtzHwEAAAA0DgRCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANOFQEKqW8qZTyqVLKU6WUd6+4/0wp5Rf7+/9xKeV1x76lAAAAAFyzq0agUso4yXuTvDnJI0neXkp5ZGm1H0/yfK319yb575L8lePeUAAAAACu3WFGAr0xyVO11s/WWreTfDDJW5fWeWuSn+uv/0qSHyyllOPbTAAAAACux2Ei0MUkTw9uP9MvW7lOrXWS5JtJXrn8RKWUd5ZSniylPPncc89d2xYDAAAAcGQnOjF0rfV9tdZHa62PXrhw4SRfGgAAAKBph4lAzyZ5cHD7gX7ZynVKKRtJ7knytePYQAAAAACu32Ei0BNJ3lBKebiUspXkbUkeW1rnsSTv6K//ySS/UWutx7eZAAAAAFyPjautUGudlFLeleRDScZJ3l9r/Xgp5T1Jnqy1PpbkZ5P8T6WUp5J8PV0oAgAAAOAmcdUIlCS11seTPL607KcH1y8n+VPHu2kAAAAAHJcTnRgaAAAAgNMhAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANKrfV0XriU55J84VRe/Nb3qiRfPe2N4JZin+Go7DMclX2Go7LPcFT2GY7C/sJR3U77zEO11gur7ji1CMS1K6U8WWt99LS3g1uHfYajss9wVPYZjso+w1HZZzgK+wtH1co+43AwAAAAgAaIQAAAAAANEIFuTe877Q3glmOf4ajsMxyVfYajss9wVPYZjsL+wlE1sc+YEwgAAACgAUYCAQAAADRABLrJlFIeLKX8w1LKJ0opHy+l/Nl++V8qpTxbSvlo//Wjg8f8hVLKU6WUT5VSfuT0tp7TUkr5fCnlY/2+8WS/7BWllF8vpXy6v7yvX15KKX+j32f+SSnlu0536zlppZTfP3gv+Wgp5YVSyp/zPsNQKeX9pZSvlFL+6WDZkd9XSinv6Nf/dCnlHafxvXAy1uwzf7WU8jv9fvGrpZR7++WvK6W8PHi/+R8Hj/nu/mfaU/1+VU7h2+EErNlnjvyzqJTypn7ZU6WUd5/098HJWbPP/OJgf/l8KeWj/XLvMxz0+brZ32kcDnaTKaXcn+T+WutHSil3JfmtJH8iyZ9OcqnW+t8urf9Ikl9I8sYkr0nyD5L8vlrr9EQ3nFNVSvl8kkdrrV8dLPuZJF+vtf7l/hei+2qtf77/Zeo/TfKjSb4nyX9fa/2e09huTl8pZZzk2XT7wr8f7zP0Sik/kORSkp+vtf7L/bIjva+UUl6R5Mkkjyap6X6mfXet9flT+Ja4wdbsMz+c5DdqrZNSyl9Jkn6feV2S/22+3tLz/GaS/yzJP07yeJK/UWv9tRP6NjhBa/aZv5Qj/Czq7/5nSf5YkmeSPJHk7bXWT5zE98DJWrXPLN3/15J8s9b6Hu8zJAd+vv6xNPo7jZFAN5la65dqrR/pr7+Y5JNJLh7wkLcm+WCt9Uqt9XNJnkr3wxHemuTn+us/l+7Nbr7852vnw0nu7d8cadMPJvlMrfULB6zjfaZBtdZ/lOTrS4uP+r7yI0l+vdb69f6XpF9P8qYbvvGcilX7TK3179daJ/3NDyd54KDn6Pebu2utH67dXyp/Pnv7GbeZNe8z66z7WfTGJE/VWj9ba91O8sF+XW5DB+0z/WieP50uFq7lfaYtB3y+bvZ3GhHoJtbX6+9MV6iT5F39kLT3z4erpduBnx487JkcHI24PdUkf7+U8lullHf2y15da/1Sf/13k7y6v26fYehtWfxlyfsMBznq+4p9h6H/IMnwL+0Pl1J+u5Tyf5ZSvr9fdjHdfjJnn2nTUX4WeZ9h7vuTfLnW+unBMu8z7Fr6fN3s7zQi0E2qlHI+yf+c5M/VWl9I8j8keX2S70jypSR/7fS2jpvQH661fleSNyf5yX6o7K7+rxyO/WRBKWUryVuS/HK/yPsMh+Z9haMopfzFJJMkf6df9KUkr621fmeSn0rygVLK3ae1fdxU/CziWr09i3/Y8j7DrhWfr3e19juNCHQTKqVspttB/06t9e8mSa31y7XWaa11luRvZe9QjGeTPDh4+AP9MhpSa322v/xKkl9Nt398eX6YV3/5lX51+wxzb07ykVrrlxPvMxzKUd9X7DuklPJjSf7NJP9O/4t2+kN6vtZf/60kn0k3v8uzWTxkzD7TmGv4WeR9hpRSNpL820l+cb7M+wxzqz5fp+HfaUSgm0x/LOvPJvlkrfWvD5YP52z5t5LMZ8R/LMnbSilnSikPJ3lDkt88qe3l9JVS7uwnOUsp5c4kP5xu/3gsyXzW+nck+V/6648l+TP9zPffm27yvC+FFi38xcz7DIdw1PeVDyX54VLKff0hHT/cL6MRpZQ3Jfkvkryl1vrSYPmFfmL6lFJ+T7r3lc/2+80LpZTv7X8n+jPZ289owDX8LHoiyRtKKQ/3I1zf1q9LW34oye/UWncP8/I+Q7L+83Ua/p1m47Q3gH3+tST/XpKPlf70hkn+yyRvL6V8R7phap9P8h8lSa3146WUX0ryiXTDrH/SGXua8+okv9q9v2UjyQdqrX+vlPJEkl8qpfx4ki+kmygv6c6A8KPpJlR8Kd0ZoWhMHwz/WPr3kt7PeJ9hrpTyC0n+aJJXlVKeSfJfJ/nLOcL7Sq3166WU/ybdh7QkeU+t9bCTwHKLWbPP/IUkZ5L8ev9z6sO11p9I8gNJ3lNK2UkyS/ITg33jP0nyt5OcSzeHkDP23KbW7DN/9Kg/i0op70r3YWyc5P211o+f7HfCSVm1z9Rafzb75zhMvM/QWff5utnfaZwiHgAAAKABDgcDAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA04P8HEvr0nJzZIvsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, test_indoor_loss, label='IndoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_outdoor_loss, label='OutdoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_belt_loss, label='OnConveyorBeltDS Tesing Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Testing(EvaluationModel) Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9960552453994751,\n",
       " 0.9960552453994751,\n",
       " 0.9960552453994751,\n",
       " 0.9960552453994751,\n",
       " 0.9960552453994751,\n",
       " 0.9960552453994751,\n",
       " 0.9980276226997375,\n",
       " 0.9960552453994751,\n",
       " 0.9960552453994751,\n",
       " 0.9960552453994751]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.977450966835022,\n",
       " 0.9813725352287292,\n",
       " 0.9823529124259949,\n",
       " 0.9823529124259949,\n",
       " 0.9823529124259949,\n",
       " 0.9803921580314636,\n",
       " 0.9833333492279053,\n",
       " 0.9823529124259949,\n",
       " 0.9833333492279053,\n",
       " 0.9823529124259949]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8963093161582947,\n",
       " 0.8875219821929932,\n",
       " 0.885764479637146,\n",
       " 0.885764479637146,\n",
       " 0.8875219821929932,\n",
       " 0.8787346482276917,\n",
       " 0.8840070366859436,\n",
       " 0.880492091178894,\n",
       " 0.8769771456718445,\n",
       " 0.880492091178894]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012962587177753448,\n",
       " 0.011658747680485249,\n",
       " 0.009471280500292778,\n",
       " 0.010952955111861229,\n",
       " 0.009503494948148727,\n",
       " 0.007018743082880974,\n",
       " 0.008461156859993935,\n",
       " 0.007112788036465645,\n",
       " 0.006298051215708256,\n",
       " 0.007760495413094759]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07801217585802078,\n",
       " 0.06928345561027527,\n",
       " 0.06569641083478928,\n",
       " 0.06652291864156723,\n",
       " 0.06689843535423279,\n",
       " 0.06920250505208969,\n",
       " 0.06818868219852448,\n",
       " 0.06762784719467163,\n",
       " 0.06957519054412842,\n",
       " 0.07703875005245209]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.395635187625885,\n",
       " 0.4432317614555359,\n",
       " 0.4799497425556183,\n",
       " 0.5236878395080566,\n",
       " 0.5500499606132507,\n",
       " 0.5916233658790588,\n",
       " 0.5610044598579407,\n",
       " 0.6221010684967041,\n",
       " 0.635604739189148,\n",
       " 0.6429727077484131]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Last Epoch and test in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del dataset memory and reload\n",
    "# RAM\n",
    "del train_ds\n",
    "del val_ds\n",
    "del test_indoor_ds\n",
    "del test_outdoor_ds\n",
    "del test_belt_ds\n",
    "# VRAM\n",
    "#from numba import cuda\n",
    "#cuda.select_device(0)\n",
    "#cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_105008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_191681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_110893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_210309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_210076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_109956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_222751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_223358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_214449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_215725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_227560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_204809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_219887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_105680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_109340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_217484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_107731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_169809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_114021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_226019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_112809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_206459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_112229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_226953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_104387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_110669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_200647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_105896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_219949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_222922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_104560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_115258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_115482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_203595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_208488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_104784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_227124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_110353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_220323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_196322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_108851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_105232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_107772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_113349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_107548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_197183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_198011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_114810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_109523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_200040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_221708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_108220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_106395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_201254) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_108128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_114469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_223965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_107298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_196089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_105100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_222144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_107507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_108668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_109248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_103814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_220930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_226626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_112005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_111796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_107108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_114153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_224805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_114428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_208255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_210683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_201861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_114902) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_227186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_205852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_112677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_216706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_113033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_203050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_111697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_203657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_111076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_109299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_107996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_207648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_104336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_105456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_226393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_104835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_225350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_228167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_214278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_103599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_111025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_104219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_216099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_112636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_109681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_108352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_113797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_216270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_207274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_209640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_109905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_115126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_106120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_225786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_108627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_110577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_207041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_198826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_221101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_197637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_216332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_103947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_113573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_112901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_197121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_217920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_216877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_110404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_107240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_212504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_114601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_106171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_224743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_218720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_175963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_113705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_223529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_104120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_113756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_209033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_79438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_111913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_202988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_199433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_105779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_111755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_213064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_111341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_204638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_104428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_199200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_221537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_107067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_218153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_205478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_106344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_220556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_110129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_209702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_115085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_214511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_211290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_202428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_218527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_106792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_107456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_196729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_199807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_113125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_115350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_111249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_201192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_201628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_109472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_212068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_112453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_105988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_225179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_107016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_209095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_105507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_113257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_105283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_212737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_206652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_198593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_108800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_113481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_107955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_113532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_115034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_109024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_104652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_215118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_109564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_198764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_106436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_209469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_204264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_219109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_104178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_106843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_228400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_111524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_221163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_222377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_211461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_103440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_114861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_110180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_106660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_108179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_106884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_207819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_115309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_113980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_114204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_109116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_208426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_110852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_201021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_210247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_213904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_213297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_111473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_212130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_110628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_109773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_109732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_215492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_219716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_108892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_217313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_207212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_105947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_107680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_104611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_112412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_114652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_219280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_110221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_223591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_215663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_203424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_103389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_113308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_108576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_213842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_211897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_110801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_224136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_222984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_111300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_103773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_112188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_113929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_114245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_204871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_212675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_110445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_103988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_224572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_206023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_103640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_213671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_205416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_105548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_109997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_107339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_112137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_111964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_216939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_222315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_228774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_205245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_106212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_200414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_210916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_210854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_226564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_112361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_105324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_207881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_208862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_204031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_217546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_198266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_196260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_201799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_108403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_103481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_185549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_204202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_108444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_202235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_228338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_105738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_219342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_218091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_202817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_227731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_211523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_112860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_227793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_196667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_104876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_114377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_206714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_224198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_111117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_225957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_214885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_198204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_206085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_197575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_213235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_220494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_215056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_113084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_114693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_199371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_200585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_112585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_105059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_106619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_111565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_106568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_225412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_218782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_199978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_221770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_107904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_109075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_202490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 507 files belonging to 10 classes.\n",
      "Found 1020 files belonging to 10 classes.\n",
      "Found 569 files belonging to 10 classes.\n",
      "train_indoor num x,y : 507,507 are predicting\n",
      "train_outdoor num x,y : 1020,1020 are predicting\n",
      "train_belt num x,y : 569,569 are predicting\n",
      "all num x,y :2096,2096\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "last_epoch_model = tf.keras.models.load_model(path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb')\n",
    "\n",
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_10FreqClasses/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_10FreqClasses/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_10FreqClasses/DatasetMedicalWasteTestLabeledCropped/belt'\n",
    "\n",
    "img_height=600\n",
    "img_width=600\n",
    "batch_size=1\n",
    "\n",
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "  layers.RandomZoom(height_factor=0.1),\n",
    "  layers.RandomContrast(0.05),\n",
    "])\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  #ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)\n",
    "\n",
    "class_names = ['2WayFoleyCatheter', 'CottonBall', 'ExtensionTube', 'Glove', 'Mask', 'NGTube', 'Needle', 'OxygenMask', 'Syringe', 'UrineBag']\n",
    "\n",
    "N = 500\n",
    "\n",
    "x_test_indoor = np.concatenate([ x for x,y in test_indoor_ds],axis=0)\n",
    "y_test_indoor = np.concatenate([ y for x,y in test_indoor_ds],axis=0)\n",
    "print(f\"train_indoor num x,y : {len(x_test_indoor)},{len(y_test_indoor)} are predicting\")\n",
    "x_indoor_sets = np.array_split(x_test_indoor, N)\n",
    "del x_test_indoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_indoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_indoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_indoor_sets,test_indoor_ds\n",
    "\n",
    "x_test_outdoor = np.concatenate([ x for x,y in test_outdoor_ds],axis=0)\n",
    "y_test_outdoor = np.concatenate([ y for x,y in test_outdoor_ds],axis=0)\n",
    "print(f\"train_outdoor num x,y : {len(x_test_outdoor)},{len(y_test_outdoor)} are predicting\")\n",
    "x_outdoor_sets = np.array_split(x_test_outdoor, N)\n",
    "del x_test_outdoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_outdoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_outdoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_outdoor_sets,test_outdoor_ds\n",
    "\n",
    "x_test_belt = np.concatenate([ x for x,y in test_belt_ds],axis=0)\n",
    "y_test_belt = np.concatenate([ y for x,y in test_belt_ds],axis=0)\n",
    "print(f\"train_belt num x,y : {len(x_test_belt)},{len(y_test_belt)} are predicting\")\n",
    "x_belt_sets = np.array_split(x_test_belt, N)\n",
    "del x_test_belt\n",
    "y_all_sets_predicted = []\n",
    "for x in x_belt_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_belt_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_belt_sets,test_belt_ds\n",
    "\n",
    "y_all = np.concatenate([y_test_indoor,y_test_outdoor,y_test_belt],axis=0)\n",
    "y_all_predicted = np.concatenate([y_indoor_predicted,y_outdoor_predicted,y_belt_predicted],axis=0)\n",
    "print(f\"all num x,y :{len(y_all_predicted)},{len(y_all)}\")\n",
    "\n",
    "#del x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all=2096\n",
      "TP=2012\n",
      "FP=84\n",
      "acc=0.9599236641221374\n",
      "all check = 2096\n"
     ]
    }
   ],
   "source": [
    "y_all_predicted_max = np.array([],dtype=np.int)\n",
    "# acc all\n",
    "TP = 0\n",
    "FP = 0\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP = TP + 1\n",
    "    else :\n",
    "        FP = FP + 1\n",
    "    y_all_predicted_max=np.append(y_all_predicted_max,np.argmax(y_all_predicted[i]))\n",
    "print(f'all={TP+FP}')\n",
    "print(f'TP={TP}')\n",
    "print(f'FP={FP}')\n",
    "print(f'acc={TP/(TP+FP)}')\n",
    "\n",
    "# acc eachclass\n",
    "TP_eachclass = [0] * 41\n",
    "FP_eachclass = [0] * 41\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP_eachclass[y_all[i]] = TP_eachclass[y_all[i]] + 1\n",
    "    else :\n",
    "        FP_eachclass[y_all[i]] = FP_eachclass[y_all[i]] + 1\n",
    "#recheck\n",
    "print(f'all check = {sum(TP_eachclass)+sum(FP_eachclass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2WayFoleyCatheter acc = 88.80597014925374%\n",
      "CottonBall acc = 99.40119760479041%\n",
      "ExtensionTube acc = 82.92682926829268%\n",
      "Glove acc = 98.80952380952381%\n",
      "Mask acc = 99.22077922077922%\n",
      "NGTube acc = 90.32258064516128%\n",
      "Needle acc = 92.5%\n",
      "OxygenMask acc = 100.0%\n",
      "Syringe acc = 99.61977186311786%\n",
      "UrineBag acc = 97.5%\n",
      "\n",
      "\n",
      "\n",
      "all_avg_eachclass = 94.9106652560919%\n"
     ]
    }
   ],
   "source": [
    "avg_acc_eachclass = []\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]} acc = {TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100}%')\n",
    "    avg_acc_eachclass.append(TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100)\n",
    "all_avg_eachclass = sum(avg_acc_eachclass) / len(avg_acc_eachclass)\n",
    "print(f'\\n\\n\\nall_avg_eachclass = {all_avg_eachclass}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   1,   0,   3,   0,   0,   0,   6,   0,   5],\n",
       "       [  0, 166,   0,   0,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 102,   1,   8,   8,   0,   0,   2,   2],\n",
       "       [  4,   0,   0, 332,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 382,   0,   0,   1,   0,   2],\n",
       "       [  0,   0,   3,   0,   7, 140,   0,   1,   2,   2],\n",
       "       [  0,   0,   7,   0,   2,   6, 259,   0,   3,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 133,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0, 262,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   3,   0, 117]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# for using scikit-learn's built-in metrics\n",
    "from sklearn.metrics import *\n",
    "# for using tesnorflow/keras' built-in metrics\n",
    "import tensorflow.keras.backend as K\n",
    "''' ndarray of shape (n_classes, n_classes)\n",
    "Confusion matrix whose i-th row and j-th column entry indicates the number of samples with  {true label being i-th row class} and {predicted label being column j-th class}.\n",
    "> Example\n",
    ">>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    ">>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    ">>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    " \n",
    "       \n",
    "'''\n",
    "# \n",
    "confusionMat = confusion_matrix(y_all, y_all_predicted_max, labels=range(len(class_names)))\n",
    "confusionMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88.80597015,   0.74626866,   0.        ,   2.23880597,\n",
       "          0.        ,   0.        ,   0.        ,   4.47761194,\n",
       "          0.        ,   3.73134328],\n",
       "       [  0.        ,  99.4011976 ,   0.        ,   0.        ,\n",
       "          0.5988024 ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,  82.92682927,   0.81300813,\n",
       "          6.50406504,   6.50406504,   0.        ,   0.        ,\n",
       "          1.62601626,   1.62601626],\n",
       "       [  1.19047619,   0.        ,   0.        ,  98.80952381,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         99.22077922,   0.        ,   0.        ,   0.25974026,\n",
       "          0.        ,   0.51948052],\n",
       "       [  0.        ,   0.        ,   1.93548387,   0.        ,\n",
       "          4.51612903,  90.32258065,   0.        ,   0.64516129,\n",
       "          1.29032258,   1.29032258],\n",
       "       [  0.        ,   0.        ,   2.5       ,   0.        ,\n",
       "          0.71428571,   2.14285714,  92.5       ,   0.        ,\n",
       "          1.07142857,   1.07142857],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        , 100.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.38022814,   0.        ,\n",
       "         99.61977186,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   2.5       ,\n",
       "          0.        ,  97.5       ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatFloat = confusionMat.astype('float64')\n",
    "confusionMatFloatPercent=confusionMatFloat/confusionMatFloat.sum(axis=1)[:,None]  # divided by number of sample in each class (sum of each row)\n",
    "confusionMatFloatPercent*=100\n",
    "confusionMatFloatPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMat, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (15,15))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMatFloatPercent, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (15,15))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\".2f\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
