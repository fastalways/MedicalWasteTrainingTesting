{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteCropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset_path='D:/DatasetMedicalWasteCroppedBalanced/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/belt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=456\n",
    "img_width=456\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 files belonging to 4 classes.\n",
      "Using 3095 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-InfectionWaste', '2-BloodSecretionWaste', '3-LabWardWaste', '4-VaccineOtherWaste']\n",
      "number of class = 4\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_number = len(class_names)\n",
    "print(class_names)\n",
    "print(f'number of class = {class_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 files belonging to 4 classes.\n",
      "Using 773 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1794 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3140 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2206 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"vertical\"),\n",
    "  layers.RandomRotation(0.100),\n",
    "  layers.RandomZoom(height_factor=0.025,width_factor=0.025),\n",
    "  #layers.RandomContrast(0.300),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  # ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 456, 456, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "# Test -> Fetching Mini Batch\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:-1]: # this is where I changed your code\n",
    "    model.add(layer)    \n",
    "\n",
    "# Freeze the layers \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add 'softmax' instead of earlier 'prediction' layer.\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input,EfficientNetB5\n",
    "\n",
    "efficientnetB0_model = keras.applications.EfficientNetB5(input_shape=(img_height,img_width,3),include_top=True,weights=\"imagenet\",classifier_activation=\"softmax\")\n",
    "\n",
    "efficientnetB0_model_nooutput = efficientnetB0_model.layers[-3].output\n",
    "custom_efficientnetB0_model = Model(inputs = efficientnetB0_model.input, outputs = efficientnetB0_model_nooutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freez Extractor+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 456, 456, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 456, 456, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 456, 456, 3)  7           rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 457, 457, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 228, 228, 48) 1296        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 228, 228, 48) 192         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 228, 228, 48) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 228, 228, 48) 432         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 228, 228, 48) 192         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 228, 228, 48) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 48)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 12)     588         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 48)     624         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 228, 228, 48) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 228, 228, 24) 1152        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 228, 228, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 228, 228, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 228, 228, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 228, 228, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 228, 228, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 228, 228, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 228, 228, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 228, 228, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 228, 228, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 228, 228, 24) 216         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 228, 228, 24) 96          block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 228, 228, 24) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 24)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 228, 228, 24) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 228, 228, 24) 576         block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 228, 228, 24) 96          block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (Dropout)          (None, 228, 228, 24) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 228, 228, 24) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 228, 228, 144 3456        block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 228, 228, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 228, 228, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 229, 229, 144 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 114, 114, 144 1296        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 114, 114, 144 576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 114, 114, 144 0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 114, 114, 144 0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 114, 114, 40) 5760        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 114, 114, 40) 160         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 114, 114, 240 960         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 114, 114, 240 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 114, 114, 240 960         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 114, 114, 240 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 240)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 114, 114, 240 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 114, 114, 40) 160         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 114, 114, 40) 0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 114, 114, 40) 0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 114, 114, 240 960         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 114, 114, 240 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 114, 114, 240 960         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 114, 114, 240 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 240)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 114, 114, 240 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 114, 114, 40) 160         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 114, 114, 40) 0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 114, 114, 40) 0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 114, 114, 240 960         block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 114, 114, 240 0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 114, 114, 240 960         block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 114, 114, 240 0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 240)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 114, 114, 240 0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 114, 114, 40) 160         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (Dropout)          (None, 114, 114, 40) 0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 114, 114, 40) 0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 114, 114, 240 960         block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 114, 114, 240 0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 114, 114, 240 2160        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 114, 114, 240 960         block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 114, 114, 240 0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 240)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 114, 114, 240 0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 114, 114, 40) 9600        block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 114, 114, 40) 160         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (Dropout)          (None, 114, 114, 40) 0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 114, 114, 40) 0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 114, 114, 240 9600        block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 114, 114, 240 960         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 114, 114, 240 0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 117, 117, 240 0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 57, 57, 240)  6000        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 57, 57, 240)  960         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 57, 57, 240)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 240)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 57, 57, 240)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 57, 57, 64)   15360       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 57, 57, 64)   256         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 57, 57, 384)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 57, 57, 384)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 384)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 57, 57, 384)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 57, 57, 64)   256         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 57, 57, 64)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 57, 57, 64)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 57, 57, 384)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 57, 57, 384)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 384)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 57, 57, 384)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 57, 57, 64)   256         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 57, 57, 64)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 57, 57, 64)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 57, 57, 384)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 57, 57, 384)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 384)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 57, 57, 384)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 57, 57, 64)   256         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (Dropout)          (None, 57, 57, 64)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 57, 57, 64)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 57, 57, 384)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 57, 57, 384)  9600        block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 57, 57, 384)  1536        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 57, 57, 384)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 384)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 57, 57, 384)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 57, 57, 64)   24576       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 57, 57, 64)   256         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (Dropout)          (None, 57, 57, 64)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 57, 57, 64)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 57, 57, 384)  24576       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 57, 57, 384)  1536        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 57, 57, 384)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 59, 59, 384)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 29, 29, 384)  3456        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 29, 29, 384)  1536        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 29, 29, 384)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 384)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 384)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 29, 29, 384)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 29, 29, 128)  49152       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 29, 29, 128)  512         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 29, 29, 768)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 29, 29, 768)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 768)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 29, 29, 768)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 29, 29, 128)  512         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 29, 29, 128)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 29, 29, 128)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 29, 29, 768)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 29, 29, 768)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 768)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 29, 29, 768)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 29, 29, 128)  512         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 29, 29, 128)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 29, 29, 128)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 29, 29, 768)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 29, 29, 768)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 768)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 29, 29, 768)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 29, 29, 128)  512         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 29, 29, 128)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 29, 29, 128)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 29, 29, 768)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 29, 29, 768)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 768)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 29, 29, 768)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 29, 29, 128)  512         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 29, 29, 128)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 29, 29, 128)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 29, 29, 768)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 29, 29, 768)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 768)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 29, 29, 768)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 29, 29, 128)  512         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (Dropout)          (None, 29, 29, 128)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 29, 29, 128)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 29, 29, 768)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 29, 29, 768)  6912        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 29, 29, 768)  3072        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 29, 29, 768)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 768)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 29, 29, 768)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 29, 29, 128)  98304       block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 29, 29, 128)  512         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (Dropout)          (None, 29, 29, 128)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 29, 29, 128)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 29, 29, 768)  98304       block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 29, 29, 768)  3072        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 29, 29, 768)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 29, 29, 768)  19200       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 29, 29, 768)  3072        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 29, 29, 768)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 768)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 768)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 29, 29, 768)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 29, 29, 176)  135168      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 29, 29, 176)  704         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 29, 29, 1056) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 29, 29, 1056) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1056)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 29, 29, 176)  704         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 29, 29, 176)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 29, 29, 176)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 29, 29, 1056) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 29, 29, 1056) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1056)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 29, 29, 176)  704         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 29, 29, 176)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 29, 29, 176)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 29, 29, 1056) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 29, 29, 1056) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1056)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 29, 29, 176)  704         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 29, 29, 176)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 29, 29, 176)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 29, 29, 1056) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 29, 29, 1056) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1056)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 29, 29, 176)  704         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 29, 29, 176)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 29, 29, 176)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 29, 29, 1056) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 29, 29, 1056) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1056)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 29, 29, 176)  704         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (Dropout)          (None, 29, 29, 176)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 29, 29, 176)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 29, 29, 1056) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 29, 29, 1056) 26400       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 29, 29, 1056) 4224        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 29, 29, 1056) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1056)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 29, 29, 1056) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 29, 29, 176)  185856      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 29, 29, 176)  704         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (Dropout)          (None, 29, 29, 176)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 29, 29, 176)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 29, 29, 1056) 185856      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 29, 29, 1056) 4224        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 29, 29, 1056) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 33, 33, 1056) 0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 15, 15, 1056) 26400       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 15, 15, 1056) 4224        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 15, 15, 1056) 0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1056)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 15, 15, 1056) 0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 15, 15, 304)  321024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 15, 15, 1824) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 15, 15, 1824) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1824)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 15, 15, 304)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 15, 15, 304)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 15, 15, 1824) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 15, 15, 1824) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1824)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 15, 15, 304)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 15, 15, 304)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 15, 15, 1824) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 15, 15, 1824) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1824)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 15, 15, 304)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 15, 15, 304)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 15, 15, 1824) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 15, 15, 1824) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1824)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 15, 15, 304)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 15, 15, 304)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 15, 15, 1824) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 15, 15, 1824) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1824)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 15, 15, 304)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 15, 15, 304)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 15, 15, 1824) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 15, 15, 1824) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 1824)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (Dropout)          (None, 15, 15, 304)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 15, 15, 304)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 15, 15, 1824) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 15, 15, 1824) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 1824)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (Dropout)          (None, 15, 15, 304)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 15, 15, 304)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 15, 15, 1824) 0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 45600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 15, 15, 1824) 0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 1824)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 15, 15, 1824) 0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 15, 15, 304)  554496      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 15, 15, 304)  1216        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (Dropout)          (None, 15, 15, 304)  0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 15, 15, 304)  0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 15, 15, 1824) 554496      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 15, 15, 1824) 7296        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 15, 15, 1824) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 15, 15, 1824) 16416       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 15, 15, 1824) 7296        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 15, 15, 1824) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1824)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 15, 15, 1824) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 15, 15, 512)  933888      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 15, 15, 512)  2048        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 15, 15, 3072) 1572864     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 15, 15, 3072) 12288       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 15, 15, 3072) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 15, 15, 3072) 27648       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 15, 15, 3072) 12288       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 15, 15, 3072) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3072)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3072)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 128)    393344      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3072)   396288      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 15, 15, 3072) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 15, 15, 512)  1572864     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 15, 15, 512)  2048        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 15, 15, 512)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 15, 15, 512)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 15, 15, 3072) 1572864     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 15, 15, 3072) 12288       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 15, 15, 3072) 0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 15, 15, 3072) 27648       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 15, 15, 3072) 12288       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 15, 15, 3072) 0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3072)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3072)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 128)    393344      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3072)   396288      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 15, 15, 3072) 0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 15, 15, 512)  1572864     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 15, 15, 512)  2048        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (Dropout)          (None, 15, 15, 512)  0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 15, 15, 512)  0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 15, 15, 2048) 1048576     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 15, 15, 2048) 8192        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 15, 15, 2048) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           top_activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 28,513,527\n",
      "Trainable params: 0\n",
      "Non-trainable params: 28,513,527\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "custom_efficientnetB0_model.trainable = False\n",
    "for layer in custom_efficientnetB0_model.layers:\n",
    "    layer.trainable = False\n",
    "## Freez\n",
    "#custom_inceptionv3_model.layers[-1].trainable = True\n",
    "#custom_inceptionv3_model.layers[-2].trainable = True\n",
    "#custom_inceptionv3_model.layers[-3].trainable = True\n",
    "print(custom_efficientnetB0_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(custom_efficientnetB0_model, to_file=\"InceptionRemoveOutput.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Feature Extractor\n",
    "model.add(custom_efficientnetB0_model)\n",
    "# Classifier\n",
    "#DeepDense\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(len(class_names), activation='softmax', trainable=True))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 2048)              28513527  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 30,615,803\n",
      "Trainable params: 2,102,276\n",
      "Non-trainable params: 28,513,527\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = ['1WayConnectorforFoley', '2WayConnectorforFoley', '2WayFoleyCatheter', '3WayConnectorforFoley', '3Waystopcock', 'AlcoholBottle', 'AlcoholPad', 'BootCover', 'CottonBall', 'CottonSwap', 'Dilator', 'DisposableInfusionSet', 'ExtensionTube', 'FaceShield', 'FrontLoadSyringe', 'GauzePad', 'Glove', 'GuideWire', 'LiquidBottle', 'Mask', 'NGTube', 'NasalCannula', 'Needle', 'OxygenMask', 'PPESuit', 'PharmaceuticalProduct', 'Pill', 'PillBottle', 'PrefilledHumidifier', 'PressureConnectingTube', 'ReusableHumidifier', 'SodiumChlorideBag', 'SterileHumidifierAdapter', 'SurgicalBlade', 'SurgicalCap', 'SurgicalSuit', 'Syringe', 'TrachealTube', 'UrineBag', 'Vaccinebottle', 'WingedInfusionSet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[-1]._name = 'Classifier'\n",
    "#model.layers[-2]._name = 'InceptionV3'\n",
    "#print(len(model.layers))\n",
    "#tf.keras.utils.plot_model(model, to_file=\"Incepv3_FreezExtractorOurOutputLayer.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/2000\n",
      "49/49 [==============================] - 116s 2s/step - loss: 0.2702 - accuracy: 0.8989 - val_loss: 0.0765 - val_accuracy: 0.9728\n",
      "Epoch 2/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0636 - accuracy: 0.9809 - val_loss: 0.0512 - val_accuracy: 0.9832\n",
      "Epoch 3/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.0395 - val_accuracy: 0.9884\n",
      "Epoch 4/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.0397 - val_accuracy: 0.9871\n",
      "Epoch 5/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.0267 - val_accuracy: 0.9858\n",
      "Epoch 6/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0229 - val_accuracy: 0.9922\n",
      "Epoch 7/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0253 - val_accuracy: 0.9897\n",
      "Epoch 8/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.0171 - val_accuracy: 0.9922\n",
      "Epoch 9/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0235 - val_accuracy: 0.9884\n",
      "Epoch 10/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0216 - val_accuracy: 0.9935\n",
      "Epoch 11/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0226 - val_accuracy: 0.9884\n",
      "Epoch 12/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0321 - val_accuracy: 0.9871\n",
      "Epoch 13/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0261 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 14/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9909\n",
      "Epoch 15/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.2126e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
      "Epoch 16/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0244 - val_accuracy: 0.9935\n",
      "Epoch 17/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1413e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9922\n",
      "Epoch 18/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.7602e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 19/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0241 - val_accuracy: 0.9922\n",
      "Epoch 20/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0770e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 21/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1136e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9922\n",
      "Epoch 22/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.5043e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9922\n",
      "Epoch 23/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2601e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 24/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3415e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9922\n",
      "Epoch 25/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4775e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9922\n",
      "Epoch 26/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0222 - val_accuracy: 0.9922\n",
      "Epoch 27/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3483e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
      "Epoch 28/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8207e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
      "Epoch 29/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0218 - val_accuracy: 0.9922\n",
      "Epoch 30/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6117e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9922\n",
      "Epoch 31/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.0319e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9922\n",
      "Epoch 32/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0009e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9922\n",
      "Epoch 33/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3586e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9922\n",
      "Epoch 34/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5949e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9922\n",
      "Epoch 35/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1041e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9922\n",
      "Epoch 36/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.7065e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9922\n",
      "Epoch 37/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.2962e-04 - accuracy: 0.9997 - val_loss: 0.0215 - val_accuracy: 0.9922\n",
      "Epoch 38/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.7715e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9922\n",
      "Epoch 39/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5578e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 40/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.1344e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 41/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3425e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9922\n",
      "Epoch 42/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9368e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 43/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7645e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 44/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.1282e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 45/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1073e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 46/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.7754e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 47/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0475e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 48/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3897e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9922\n",
      "Epoch 49/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9206e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9922\n",
      "Epoch 50/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.8149e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9935\n",
      "Epoch 51/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0209 - val_accuracy: 0.9922\n",
      "Epoch 52/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.2330e-04 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9922\n",
      "Epoch 53/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.7234e-04 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9922\n",
      "Epoch 54/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4256e-04 - accuracy: 0.9997 - val_loss: 0.0207 - val_accuracy: 0.9922\n",
      "Epoch 55/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5700e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9922\n",
      "Epoch 56/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6850e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9922\n",
      "Epoch 57/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1246e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9922\n",
      "Epoch 58/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0208 - val_accuracy: 0.9922\n",
      "Epoch 59/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2244e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9922\n",
      "Epoch 60/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3456e-04 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9922\n",
      "Epoch 61/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0203 - val_accuracy: 0.9922\n",
      "Epoch 62/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8508e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9922\n",
      "Epoch 63/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9091e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9922\n",
      "Epoch 64/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.7034e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9922\n",
      "Epoch 65/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0199 - val_accuracy: 0.9922\n",
      "Epoch 66/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3280e-04 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9922\n",
      "Epoch 67/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.6275e-04 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9922\n",
      "Epoch 68/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7704e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9922\n",
      "Epoch 69/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0203 - val_accuracy: 0.9922\n",
      "Epoch 70/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.0473e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9922\n",
      "Epoch 71/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0173e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9922\n",
      "Epoch 72/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2566e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9922\n",
      "Epoch 73/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2907e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9922\n",
      "Epoch 74/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5842e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9935\n",
      "Epoch 75/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.2438e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9935\n",
      "Epoch 76/2000\n",
      "49/49 [==============================] - 71s 1s/step - loss: 3.9877e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9935\n",
      "Epoch 77/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 5.8070e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9935\n",
      "Epoch 78/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 4.9541e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9935\n",
      "Epoch 79/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 3.2915e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9935\n",
      "Epoch 80/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 5.9980e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9935\n",
      "Epoch 81/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 4.7394e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9935\n",
      "Epoch 82/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0196 - val_accuracy: 0.9935\n",
      "Epoch 83/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 6.0263e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9935\n",
      "Epoch 84/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 6.1885e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9935\n",
      "Epoch 85/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 4.8103e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9935\n",
      "Epoch 86/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 4.4234e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 87/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 4.2640e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 88/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 4.6056e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 89/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.3065e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9922\n",
      "Epoch 90/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 9.7497e-04 - accuracy: 0.9994 - val_loss: 0.0196 - val_accuracy: 0.9935\n",
      "Epoch 91/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2744e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9922\n",
      "Epoch 92/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 5.2519e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9922\n",
      "Epoch 93/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.6231e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9922\n",
      "Epoch 94/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 5.0331e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9922\n",
      "Epoch 95/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.9874e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9935\n",
      "Epoch 96/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1517e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9935\n",
      "Epoch 97/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.7262e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9922\n",
      "Epoch 98/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.7989e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 99/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.3832e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 100/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4445e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 101/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2236e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 102/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0260e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9935\n",
      "Epoch 103/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.2081e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9922\n",
      "Epoch 104/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.7114e-04 - accuracy: 0.9997 - val_loss: 0.0202 - val_accuracy: 0.9922\n",
      "Epoch 105/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.2004e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9935\n",
      "Epoch 106/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2634e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9935\n",
      "Epoch 107/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.2956e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9935\n",
      "Epoch 108/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8191e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9935\n",
      "Epoch 109/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.6928e-04 - accuracy: 0.9997 - val_loss: 0.0188 - val_accuracy: 0.9922\n",
      "Epoch 110/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0372e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9922\n",
      "Epoch 111/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0827e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9922\n",
      "Epoch 112/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1773e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9922\n",
      "Epoch 113/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0712e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9922\n",
      "Epoch 114/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.7107e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9922\n",
      "Epoch 115/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3928e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9922\n",
      "Epoch 116/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8284e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9922\n",
      "Epoch 117/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0188 - val_accuracy: 0.9922\n",
      "Epoch 118/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.9452e-04 - accuracy: 0.9997 - val_loss: 0.0183 - val_accuracy: 0.9922\n",
      "Epoch 119/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2248e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9922\n",
      "Epoch 120/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8158e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9922\n",
      "Epoch 121/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9772e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9922\n",
      "Epoch 122/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8563e-04 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9922\n",
      "Epoch 123/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.0790e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9922\n",
      "Epoch 124/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8363e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9922\n",
      "Epoch 125/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6813e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9922\n",
      "Epoch 126/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5935e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9922\n",
      "Epoch 127/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.7199e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9922\n",
      "Epoch 128/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.6083e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9922\n",
      "Epoch 129/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9187e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9935\n",
      "Epoch 130/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9935\n",
      "Epoch 131/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4375e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9935\n",
      "Epoch 132/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9548e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9922\n",
      "Epoch 133/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3835e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9922\n",
      "Epoch 134/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.6841e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 135/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5501e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9922\n",
      "Epoch 136/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.6776e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 137/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3512e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 138/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5524e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 139/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5481e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 140/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1608e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9922\n",
      "Epoch 141/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3182e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9922\n",
      "Epoch 142/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9681e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 143/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1047e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 144/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.7679e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 145/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.6168e-04 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9922\n",
      "Epoch 146/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3213e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9922\n",
      "Epoch 147/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7171e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 148/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8459e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 149/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6202e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 150/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4479e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9922\n",
      "Epoch 151/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4480e-04 - accuracy: 0.9994 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 152/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4742e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9922\n",
      "Epoch 153/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4838e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9922\n",
      "Epoch 154/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3246e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9922\n",
      "Epoch 155/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2189e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9922\n",
      "Epoch 156/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8741e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9935\n",
      "Epoch 157/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1386e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9935\n",
      "Epoch 158/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9824e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9935\n",
      "Epoch 159/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2776e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9935\n",
      "Epoch 160/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3056e-04 - accuracy: 0.9997 - val_loss: 0.0180 - val_accuracy: 0.9935\n",
      "Epoch 161/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3381e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9935\n",
      "Epoch 162/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3453e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9935\n",
      "Epoch 163/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5845e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9935\n",
      "Epoch 164/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9257e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9935\n",
      "Epoch 165/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4023e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9922\n",
      "Epoch 166/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4864e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9922\n",
      "Epoch 167/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0952e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9935\n",
      "Epoch 168/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8347e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9922\n",
      "Epoch 169/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.6246e-04 - accuracy: 0.9997 - val_loss: 0.0181 - val_accuracy: 0.9935\n",
      "Epoch 170/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9292e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9935\n",
      "Epoch 171/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9935\n",
      "Epoch 172/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9222e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9935\n",
      "Epoch 173/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5594e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9935\n",
      "Epoch 174/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5061e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9935\n",
      "Epoch 175/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7378e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9922\n",
      "Epoch 176/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9957e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9922\n",
      "Epoch 177/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6677e-04 - accuracy: 0.9997 - val_loss: 0.0179 - val_accuracy: 0.9922\n",
      "Epoch 178/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2141e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9922\n",
      "Epoch 179/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9372e-04 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9922\n",
      "Epoch 180/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2416e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9922\n",
      "Epoch 181/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4716e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9922\n",
      "Epoch 182/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9628e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9922\n",
      "Epoch 183/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2016e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 184/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4006e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 185/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7314e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9922\n",
      "Epoch 186/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4785e-04 - accuracy: 0.9997 - val_loss: 0.0176 - val_accuracy: 0.9935\n",
      "Epoch 187/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 2.0126e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9935\n",
      "Epoch 188/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.6344e-04 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9935\n",
      "Epoch 189/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 3.7534e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9935\n",
      "Epoch 190/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 4.0909e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9935\n",
      "Epoch 191/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 3.9772e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9935\n",
      "Epoch 192/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.9253e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9935\n",
      "Epoch 193/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 3.1875e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9935\n",
      "Epoch 194/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 2.6782e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9935\n",
      "Epoch 195/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 3.8280e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9935\n",
      "Epoch 196/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 2.9183e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9935\n",
      "Epoch 197/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.6652e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9935\n",
      "Epoch 198/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.1039e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9935\n",
      "Epoch 199/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.8940e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9935\n",
      "Epoch 200/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.1225e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7532e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9948\n",
      "Epoch 202/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.2573e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9948\n",
      "Epoch 203/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.8856e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9948\n",
      "Epoch 204/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.7667e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9935\n",
      "Epoch 205/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.8245e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9948\n",
      "Epoch 206/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.2019e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9935\n",
      "Epoch 207/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.5735e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9935\n",
      "Epoch 208/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.0548e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9935\n",
      "Epoch 209/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.0680e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9935\n",
      "Epoch 210/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.5257e-04 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
      "Epoch 211/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.4965e-04 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
      "Epoch 212/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.9420e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9935\n",
      "Epoch 213/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.1462e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9935\n",
      "Epoch 214/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7717e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9935\n",
      "Epoch 215/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 4.2212e-04 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
      "Epoch 216/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.5402e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9935\n",
      "Epoch 217/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.8724e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9935\n",
      "Epoch 218/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.9854e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9935\n",
      "Epoch 219/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.9098e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9935\n",
      "Epoch 220/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.1598e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9935\n",
      "Epoch 221/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7099e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9935\n",
      "Epoch 222/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.4639e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 223/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.1256e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9935\n",
      "Epoch 224/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.7375e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9935\n",
      "Epoch 225/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.3409e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9935\n",
      "Epoch 226/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.0734e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9935\n",
      "Epoch 227/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 1.5264e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9935\n",
      "Epoch 228/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.6616e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 229/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.1612e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 230/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.2527e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 231/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.2476e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 232/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.3891e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 233/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.3563e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 234/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.5706e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 235/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7078e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 236/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.4578e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 237/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.0162e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 238/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.2010e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 239/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.7183e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 240/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.4581e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
      "Epoch 241/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7367e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 242/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7072e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 243/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.0435e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 244/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.3161e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 245/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.5534e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 246/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7611e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 247/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.7093e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 248/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.5947e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 249/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.4966e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 250/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.8817e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9935\n",
      "Epoch 251/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.4978e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9935\n",
      "Epoch 252/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 3.6661e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 253/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.5706e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 254/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.7963e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 255/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.9298e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 256/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 1.2417e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 257/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 6.2807e-04 - accuracy: 0.9997 - val_loss: 0.0168 - val_accuracy: 0.9935\n",
      "Epoch 258/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.0902e-04 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
      "Epoch 259/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 2.8155e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
      "Epoch 260/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.8241e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 261/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 1.9834e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 262/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 1.2080e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 263/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.5060e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 264/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.4197e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 265/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.5159e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 266/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.8768e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 267/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0152 - val_accuracy: 0.9948\n",
      "Epoch 268/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 1.6787e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 269/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2341e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9935\n",
      "Epoch 270/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8666e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9935\n",
      "Epoch 271/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8426e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9935\n",
      "Epoch 272/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5868e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9935\n",
      "Epoch 273/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8421e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9935\n",
      "Epoch 274/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9090e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9935\n",
      "Epoch 275/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8100e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9935\n",
      "Epoch 276/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9850e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9935\n",
      "Epoch 277/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.6565e-05 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 278/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7281e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 279/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5584e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 280/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1254e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
      "Epoch 281/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1771e-04 - accuracy: 0.9997 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 282/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0808e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 283/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3787e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 284/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6063e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 285/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0706e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 286/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8218e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 287/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0562e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9935\n",
      "Epoch 288/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7931e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 289/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3763e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 290/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7283e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 291/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7179e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9948\n",
      "Epoch 292/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5315e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
      "Epoch 293/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6824e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 294/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5562e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 295/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3969e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 296/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1987e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 297/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 298/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9220e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 299/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1191e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 300/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1972e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 301/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6576e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
      "Epoch 302/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3744e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9948\n",
      "Epoch 303/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6723e-04 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9948\n",
      "Epoch 304/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3168e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 305/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1036e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 306/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0920e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 307/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2633e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 308/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1269e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 309/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5473e-04 - accuracy: 0.9997 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 310/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7518e-04 - accuracy: 0.9997 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
      "Epoch 311/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5033e-05 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9948\n",
      "Epoch 312/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6443e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 313/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3282e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 314/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 315/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8957e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9935\n",
      "Epoch 316/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0060e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9935\n",
      "Epoch 317/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1779e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9935\n",
      "Epoch 318/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4780e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9935\n",
      "Epoch 319/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5090e-05 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9935\n",
      "Epoch 320/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3210e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9935\n",
      "Epoch 321/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6697e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 322/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5320e-04 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 323/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1935e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
      "Epoch 324/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3051e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 325/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8029e-04 - accuracy: 0.9997 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
      "Epoch 326/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7053e-05 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
      "Epoch 327/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6149e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9948\n",
      "Epoch 328/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8944e-05 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9948\n",
      "Epoch 329/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0400e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 330/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3615e-05 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
      "Epoch 331/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6904e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9948\n",
      "Epoch 332/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4353e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 333/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9268e-05 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9948\n",
      "Epoch 334/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4039e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 335/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1776e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
      "Epoch 336/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0005e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 337/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2013e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 338/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4809e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 339/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0140e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 340/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0229e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 341/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3161e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
      "Epoch 342/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0609e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9948\n",
      "Epoch 343/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.5436e-05 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9948\n",
      "Epoch 344/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7458e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 345/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0536e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 346/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2247e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 347/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1309e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 348/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.1862e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 349/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0666e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 350/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2316e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 351/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0140e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 352/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1547e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
      "Epoch 353/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2993e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 354/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0801e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 355/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.6212e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 356/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2637e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 357/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 358/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2412e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 359/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.4845e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 360/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1924e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 361/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6658e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
      "Epoch 362/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3482e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 363/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5539e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 364/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1129e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 365/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5781e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 366/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2414e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 367/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0374e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 368/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6947e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 369/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9120e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 370/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5141e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 371/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6343e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
      "Epoch 372/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2139e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 373/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5977e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 374/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0700e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 375/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0437e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 376/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9596e-05 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
      "Epoch 377/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1106e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 378/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.4732e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
      "Epoch 379/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2203e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
      "Epoch 380/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5577e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 381/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1267e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 382/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1521e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 383/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0035e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 384/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.1080e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 385/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.5113e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
      "Epoch 386/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0926e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 387/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0576e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 388/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4460e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 389/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9336e-04 - accuracy: 0.9997 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 390/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0800e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 391/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8986e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
      "Epoch 392/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4615e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
      "Epoch 393/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4641e-04 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 394/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6640e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 395/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0341e-04 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 396/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5526e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 397/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3425e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 398/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5627e-04 - accuracy: 0.9997 - val_loss: 0.0156 - val_accuracy: 0.9935\n",
      "Epoch 399/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1118e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
      "Epoch 400/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3486e-05 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5836e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 402/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.8003e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 403/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1858e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 404/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0956e-04 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 405/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3050e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 406/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5762e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 407/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3834e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 408/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6059e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 409/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3085e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 410/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8610e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 411/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9811e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 412/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1231e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9935\n",
      "Epoch 413/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7628e-05 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9948\n",
      "Epoch 414/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6401e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 415/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3300e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 416/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.0354e-04 - accuracy: 0.9997 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 417/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3375e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9948\n",
      "Epoch 418/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3028e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
      "Epoch 419/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4023e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
      "Epoch 420/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7950e-04 - accuracy: 0.9997 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
      "Epoch 421/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2950e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 422/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5777e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 423/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9759e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 424/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7053e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 425/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0587e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 426/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.1114e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
      "Epoch 427/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2368e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 428/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9054e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 429/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5549e-05 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
      "Epoch 430/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1286e-04 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
      "Epoch 431/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4019e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9948\n",
      "Epoch 432/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3145e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
      "Epoch 433/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1735e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9948\n",
      "Epoch 434/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3261e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9948\n",
      "Epoch 435/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4311e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 436/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.8155e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 437/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1845e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 438/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.2228e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 439/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2270e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 440/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3712e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 441/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1678e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 442/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6991e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 443/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3758e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 444/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9849e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 445/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7192e-04 - accuracy: 0.9997 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 446/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.6449e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 447/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.7785e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 448/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1839e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 449/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6259e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 450/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.6534e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 451/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5816e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 452/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1780e-04 - accuracy: 0.9997 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 453/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0438e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 454/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.6539e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 455/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3476e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 456/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.8194e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 457/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.1121e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 458/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6892e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 459/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.8183e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 460/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.0532e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 461/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0015e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 462/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3998e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 463/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.0582e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 464/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4411e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 465/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2677e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 466/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.4489e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 467/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8531e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 468/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0448e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 469/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3030e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 470/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1080e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 471/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4029e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 472/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0440e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 473/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9052e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 474/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0032e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 475/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.0826e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 476/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4993e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 477/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3606e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9948\n",
      "Epoch 478/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0219e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 479/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.4779e-04 - accuracy: 0.9997 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 480/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1808e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 481/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 1.6584e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 482/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 5.7071e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 483/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 6.6036e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 484/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 3.0049e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 485/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 8.8261e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9935\n",
      "Epoch 486/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 8.7586e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9935\n",
      "Epoch 487/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 1.0181e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9935\n",
      "Epoch 488/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 7.8530e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9935\n",
      "Epoch 489/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 6.1706e-04 - accuracy: 0.9997 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 490/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 1.2124e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 491/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 1.1161e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 492/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4844e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 493/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.5892e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 494/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.4010e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9935\n",
      "Epoch 495/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 4.6161e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9935\n",
      "Epoch 496/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 6.4128e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9935\n",
      "Epoch 497/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 5.2355e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9935\n",
      "Epoch 498/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 1.1759e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9935\n",
      "Epoch 499/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.7336e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 500/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 6.5183e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 501/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1841e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 502/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8762e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9935\n",
      "Epoch 503/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.4163e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9935\n",
      "Epoch 504/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9612e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9935\n",
      "Epoch 505/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2809e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9935\n",
      "Epoch 506/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.0561e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 507/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.8434e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 508/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9539e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 509/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3816e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 510/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.0278e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 511/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.8217e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 512/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0970e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 513/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7138e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 514/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.9519e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 515/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.4237e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 516/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.2841e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 517/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9253e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 518/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5312e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 519/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9972e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 520/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1828e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 521/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.4220e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 522/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3153e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 523/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.7657e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 524/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3869e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 525/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9787e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 526/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2033e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 527/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.4614e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 528/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9432e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 529/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0117e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9935\n",
      "Epoch 530/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3649e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9935\n",
      "Epoch 531/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8167e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9935\n",
      "Epoch 532/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0992e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 533/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1099e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 534/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4866e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9935\n",
      "Epoch 535/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9976e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 536/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8171e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 537/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3245e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 538/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5079e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9935\n",
      "Epoch 539/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.7560e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9935\n",
      "Epoch 540/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4978e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 541/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4215e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 542/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5663e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 543/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.6405e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 544/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5978e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 545/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9197e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 546/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3227e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 547/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6095e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 548/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9784e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 549/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3678e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 550/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7029e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 551/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0402e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 552/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9658e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 553/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7363e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9935\n",
      "Epoch 554/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4709e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9935\n",
      "Epoch 555/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5280e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 556/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9357e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 557/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.8853e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 558/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.6868e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 559/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.2318e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 560/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.7333e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 561/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2839e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9935\n",
      "Epoch 562/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9314e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9935\n",
      "Epoch 563/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0212e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 564/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.2970e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 565/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9192e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 566/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3149e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 567/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6613e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 568/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0667e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 569/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2696e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 570/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1925e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 571/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8522e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 572/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3163e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 573/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7350e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 574/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5534e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 575/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7292e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 576/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9417e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9935\n",
      "Epoch 577/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9454e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9935\n",
      "Epoch 578/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6524e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9935\n",
      "Epoch 579/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4146e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9935\n",
      "Epoch 580/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3576e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9935\n",
      "Epoch 581/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0863e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9935\n",
      "Epoch 582/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8160e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9935\n",
      "Epoch 583/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.8035e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9935\n",
      "Epoch 584/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5280e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9935\n",
      "Epoch 585/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8735e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9935\n",
      "Epoch 586/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5279e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 587/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.2112e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 588/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.8468e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 589/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7705e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 590/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.6304e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 591/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.7610e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 592/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0514e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 593/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0733e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 594/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6084e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9935\n",
      "Epoch 595/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0267e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9935\n",
      "Epoch 596/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5399e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9935\n",
      "Epoch 597/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.1802e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9935\n",
      "Epoch 598/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0865e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9935\n",
      "Epoch 599/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.1147e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9935\n",
      "Epoch 600/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2467e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4949e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 602/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.2082e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 603/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2653e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 604/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0358e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 605/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.0191e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9935\n",
      "Epoch 606/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0566e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9935\n",
      "Epoch 607/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6454e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9935\n",
      "Epoch 608/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1026e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9935\n",
      "Epoch 609/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4472e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9935\n",
      "Epoch 610/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.6579e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 611/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3107e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9935\n",
      "Epoch 612/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6015e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9935\n",
      "Epoch 613/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0928e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 614/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0537e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 615/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2946e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 616/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0159e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 617/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8996e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 618/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7970e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9935\n",
      "Epoch 619/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0062e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9935\n",
      "Epoch 620/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3890e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9935\n",
      "Epoch 621/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7977e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 622/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2330e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 623/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9564e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9935\n",
      "Epoch 624/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5326e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9935\n",
      "Epoch 625/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1584e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 626/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1837e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 627/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1008e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 628/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1639e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 629/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9372e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 630/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.8630e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 631/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3652e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9961\n",
      "Epoch 632/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6823e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9961\n",
      "Epoch 633/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9045e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 634/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.8431e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 635/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4761e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 636/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.2042e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 637/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4332e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 638/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1172e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9935\n",
      "Epoch 639/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0378e-04 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 640/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2292e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 641/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3752e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 642/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9751e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 643/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5043e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 644/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0633e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 645/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0816e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 646/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7126e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 647/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8660e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 648/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7853e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 649/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3736e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 650/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2095e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 651/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3607e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 652/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5970e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 653/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0119e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 654/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4956e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 655/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9370e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 656/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7258e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 657/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8494e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 658/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0019e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 659/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3113e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 660/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0941e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9935\n",
      "Epoch 661/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6562e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9935\n",
      "Epoch 662/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9500e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 663/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6143e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 664/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4655e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 665/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0674e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 666/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9990e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 667/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1813e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 668/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7644e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 669/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1361e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 670/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2406e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9935\n",
      "Epoch 671/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3261e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 672/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6090e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 673/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1214e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 674/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3207e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 675/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8649e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 676/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6611e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 677/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0768e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 678/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.4876e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 679/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8319e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 680/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2247e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 681/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6413e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 682/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7668e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 683/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5239e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 684/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2928e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 685/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6947e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 686/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8633e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 687/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.2897e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 688/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9136e-04 - accuracy: 0.9997 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 689/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4992e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 690/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7481e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 691/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6845e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 692/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1812e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 693/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2862e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 694/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6326e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 695/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.0465e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 696/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0102e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 697/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5895e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 698/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5569e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9935\n",
      "Epoch 699/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2928e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9935\n",
      "Epoch 700/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5106e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 701/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2526e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 702/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3216e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9935\n",
      "Epoch 703/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0987e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 704/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5510e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 705/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4007e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 706/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2416e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 707/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0205e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 708/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0180e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 709/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6886e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 710/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.1623e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 711/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6235e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 712/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.1791e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 713/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5021e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 714/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6619e-04 - accuracy: 0.9997 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 715/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7547e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 716/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4036e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 717/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.2218e-04 - accuracy: 0.9997 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 718/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3387e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 719/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.9320e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 720/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8932e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 721/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8467e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 722/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8745e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 723/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8441e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 724/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9770e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 725/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.7679e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 726/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0183e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 727/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1153e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 728/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3830e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 729/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4831e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 730/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2262e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 731/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8746e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 732/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6247e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 733/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0868e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 734/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3985e-04 - accuracy: 0.9997 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 735/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8776e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 736/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2562e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 737/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4036e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 738/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5330e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 739/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0119e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 740/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.2154e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9961\n",
      "Epoch 741/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3828e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9961\n",
      "Epoch 742/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.6617e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 743/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8243e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 744/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8130e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 745/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0227e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 746/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2983e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 747/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0355e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 748/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6254e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 749/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6072e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 750/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4464e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 751/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3901e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 752/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3817e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 753/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8684e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 754/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4587e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 755/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6346e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 756/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0214e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 757/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2105e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 758/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2512e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 759/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5152e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 760/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5413e-04 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 761/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0924e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 762/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5445e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 763/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7294e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 764/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4650e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 765/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5234e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 766/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5074e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 767/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7536e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 768/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2150e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 769/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6883e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 770/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4028e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 771/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5040e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 772/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8341e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 773/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2758e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 774/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3839e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 775/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5476e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 776/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8212e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 777/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4096e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 778/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1220e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 779/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4154e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 780/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1492e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 781/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3112e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 782/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9520e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 783/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3535e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 784/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4525e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 785/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1068e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 786/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7566e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 787/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3301e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 788/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3338e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 789/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3695e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 790/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5198e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 791/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0611e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 792/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2974e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 793/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7500e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 794/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7501e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 795/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3730e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 796/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3975e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 797/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0618e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 798/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3894e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 799/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6003e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 800/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2965e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5608e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 802/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7301e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 803/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0902e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 804/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3292e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 805/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0876e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 806/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3604e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 807/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8402e-04 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 808/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7676e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9961\n",
      "Epoch 809/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8702e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 810/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7580e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 811/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6547e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 812/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.1275e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 813/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0548e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 814/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8654e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 815/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9680e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 816/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3525e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 817/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3006e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9961\n",
      "Epoch 818/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5671e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 819/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7284e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 820/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9691e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 821/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8426e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 822/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4915e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 823/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2760e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 824/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3415e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 825/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0532e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 826/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6638e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 827/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6830e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 828/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1244e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 829/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2588e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 830/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1861e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 831/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3718e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 832/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1359e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 833/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8969e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 834/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6354e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 835/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2301e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 836/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7405e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 837/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7371e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 838/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2067e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 839/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.8243e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 840/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4216e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 841/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6947e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 842/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4610e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 843/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1739e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 844/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7855e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 845/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0054e-04 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 846/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6203e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 847/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6544e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 848/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0962e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 849/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5014e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 850/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8749e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 851/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1774e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 852/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2344e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 853/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1755e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 854/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3479e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 855/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9843e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 856/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3299e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 857/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3388e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 858/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0844e-04 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 859/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4642e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 860/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6358e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 861/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9942e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 862/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7093e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 863/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4240e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 864/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4354e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 865/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4027e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 866/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9933e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 867/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.2253e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 868/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8861e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 869/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6707e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 870/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6574e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 871/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6171e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 872/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.6039e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 873/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9060e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 874/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2380e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9961\n",
      "Epoch 875/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2284e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 876/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4590e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 877/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7818e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 878/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7526e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 879/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7267e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 880/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0498e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 881/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9693e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 882/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2256e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 883/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7742e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 884/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2305e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 885/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0812e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 886/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4054e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 887/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6072e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 888/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4173e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 889/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9551e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 890/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3597e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 891/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3476e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 892/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2692e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 893/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7728e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 894/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5881e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 895/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7838e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 896/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5897e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 897/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2741e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 898/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0400e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 899/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6269e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 900/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1041e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 901/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9197e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 902/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0253e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 903/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2514e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 904/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6639e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 905/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9672e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 906/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5434e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 907/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6271e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 908/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.9969e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 909/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2904e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 910/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6356e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 911/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4063e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 912/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8902e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 913/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2711e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 914/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2596e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 915/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9824e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 916/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9945e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 917/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6548e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 918/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0183e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 919/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3026e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 920/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8609e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 921/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.8966e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 922/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7816e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 923/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9309e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 924/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4135e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 925/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0271e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 926/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9735e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 927/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7184e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 928/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.5903e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 929/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2728e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 930/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5670e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 931/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.1889e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 932/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5210e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 933/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0896e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 934/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3204e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 935/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8846e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 936/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5226e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 937/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4385e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 938/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0081e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 939/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4689e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 940/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6848e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 941/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6296e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 942/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9359e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 943/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4659e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 944/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6662e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 945/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2668e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 946/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3611e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 947/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4869e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 948/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8661e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 949/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3711e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 950/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.6916e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 951/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6395e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9961\n",
      "Epoch 952/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6859e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9961\n",
      "Epoch 953/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4807e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9961\n",
      "Epoch 954/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1468e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 955/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5714e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 956/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9111e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 957/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9808e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 958/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8901e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 959/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3591e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 960/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2256e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 961/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6528e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 962/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2251e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 963/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6146e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 964/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9851e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 965/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1397e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 966/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4485e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 967/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6586e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 968/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5029e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 969/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2363e-04 - accuracy: 0.9997 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 970/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8826e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 971/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6514e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 972/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8621e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 973/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8921e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 974/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2829e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 975/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7137e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 976/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3376e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 977/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5771e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 978/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5934e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 979/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2417e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 980/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9350e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 981/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7791e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 982/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4593e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 983/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0342e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 984/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0968e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 985/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4163e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 986/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1263e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 987/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6517e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 988/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5314e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 989/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8594e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 990/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0764e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 991/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0603e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 992/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0212e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 993/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9304e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 994/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3558e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 995/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7947e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 996/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4425e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 997/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1586e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 998/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3959e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 999/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8188e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1000/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3392e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.7315e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1002/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.4375e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9935\n",
      "Epoch 1003/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3998e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9935\n",
      "Epoch 1004/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3383e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9935\n",
      "Epoch 1005/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6641e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9935\n",
      "Epoch 1006/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7152e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9935\n",
      "Epoch 1007/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3116e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9935\n",
      "Epoch 1008/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4842e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9935\n",
      "Epoch 1009/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1176e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 1010/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.6036e-06 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 1011/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5419e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 1012/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3226e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1013/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4217e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1014/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3726e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1015/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4660e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1016/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9877e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1017/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2187e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 1018/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7583e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1019/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1430e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1020/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1968e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1021/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5756e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1022/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1212e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1023/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3163e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1024/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3134e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1025/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4335e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 1026/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9668e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1027/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3214e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1028/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4260e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1029/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2697e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 1030/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1456e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 1031/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5095e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 1032/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6047e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9948\n",
      "Epoch 1033/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4523e-04 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9948\n",
      "Epoch 1034/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5140e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9948\n",
      "Epoch 1035/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6338e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1036/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5403e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1037/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1742e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1038/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1849e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1039/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1155e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1040/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1945e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1041/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2186e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1042/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6199e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1043/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2607e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1044/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1700e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 1045/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2253e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 1046/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3458e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 1047/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2266e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 1048/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5022e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9922\n",
      "Epoch 1049/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2755e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1050/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3301e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 1051/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8014e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1052/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7413e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1053/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1896e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 1054/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5516e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 1055/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0274e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1056/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.0963e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9935\n",
      "Epoch 1057/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3533e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9935\n",
      "Epoch 1058/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4906e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9935\n",
      "Epoch 1059/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9638e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 1060/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6656e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1061/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7427e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 1062/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2561e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 1063/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5138e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1064/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5209e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 1065/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3233e-04 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 1066/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2369e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 1067/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.6215e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9948\n",
      "Epoch 1068/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3427e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9948\n",
      "Epoch 1069/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6847e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9948\n",
      "Epoch 1070/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1594e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 1071/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5261e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 1072/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6029e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1073/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0425e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1074/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3769e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1075/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8833e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1076/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2757e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9948\n",
      "Epoch 1077/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6410e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 1078/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7366e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 1079/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7762e-06 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 1080/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7570e-06 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9948\n",
      "Epoch 1081/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5748e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 1082/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3222e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1083/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1108e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1084/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0868e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1085/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6148e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1086/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9160e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 1087/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1860e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
      "Epoch 1088/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0430e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 1089/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4091e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 1090/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4535e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1091/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3198e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1092/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.1326e-06 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 1093/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1102e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1094/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5465e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1095/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5634e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1096/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.0886e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1097/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1356e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1098/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2214e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1099/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5361e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1100/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2290e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1101/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2595e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1102/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3769e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1103/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.5455e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1104/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8706e-06 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1105/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1741e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 1106/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2355e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1107/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9766e-06 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1108/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2738e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1109/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4941e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1110/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4849e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1111/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7001e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1112/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8816e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1113/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0172e-04 - accuracy: 0.9997 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1114/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5565e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1115/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8710e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1116/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3298e-04 - accuracy: 0.9997 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1117/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8268e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1118/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3612e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1119/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0754e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1120/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3132e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1121/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1690e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1122/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8341e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1123/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3517e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1124/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.6272e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1125/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4201e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1126/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.7410e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1127/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0964e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1128/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2050e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1129/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9723e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1130/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3436e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1131/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.1598e-04 - accuracy: 0.9997 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 1132/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9209e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9948\n",
      "Epoch 1133/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3690e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1134/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2330e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 1135/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2222e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1136/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.4987e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1137/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2496e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1138/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2301e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1139/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8109e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1140/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7679e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1141/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5911e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1142/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0473e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1143/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8152e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1144/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.2306e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1145/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8290e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1146/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8815e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1147/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.5229e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1148/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5094e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1149/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.7394e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1150/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0402e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1151/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1048e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1152/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5175e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1153/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1657e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1154/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0691e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1155/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3606e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1156/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3986e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1157/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1137e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1158/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5022e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1159/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3932e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 1160/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4151e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1161/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6414e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1162/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.6376e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1163/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2673e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1164/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.7481e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1165/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7260e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1166/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0714e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1167/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8133e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1168/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2801e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1169/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.4523e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1170/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2717e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1171/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0403e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 1172/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1105e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 1173/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.9546e-06 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1174/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4027e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1175/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3706e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1176/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1071e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 1177/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3577e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1178/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1339e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1179/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9078e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1180/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.2068e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1181/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0178e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1182/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.0932e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1183/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0801e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1184/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8009e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1185/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3668e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1186/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8755e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1187/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8073e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9974\n",
      "Epoch 1188/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1615e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1189/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7591e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1190/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.9606e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1191/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2570e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1192/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2369e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1193/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0061e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1194/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2069e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1195/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.2561e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 1196/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3633e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1197/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9445e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1198/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3481e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1199/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0046e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 1200/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4197e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.8110e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 1202/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.5067e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1203/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1418e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9974\n",
      "Epoch 1204/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8751e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9974\n",
      "Epoch 1205/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6769e-05 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 1206/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7390e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9974\n",
      "Epoch 1207/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.1470e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9974\n",
      "Epoch 1208/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8882e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9974\n",
      "Epoch 1209/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.2254e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1210/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4889e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1211/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3920e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1212/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1927e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1213/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7315e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1214/2000\n",
      "49/49 [==============================] - 71s 1s/step - loss: 9.0454e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1215/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.1664e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1216/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 5.4660e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1217/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8092e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1218/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2748e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1219/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.0513e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1220/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.0361e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1221/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1010e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1222/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6052e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1223/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6844e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1224/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1389e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1225/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4078e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1226/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3392e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1227/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.1174e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1228/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.3047e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1229/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0935e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1230/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1079e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1231/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8148e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1232/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7841e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1233/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.3278e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1234/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.6403e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1235/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9977e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1236/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3710e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1237/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2673e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1238/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.7616e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1239/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9731e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1240/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2093e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1241/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4853e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1242/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6528e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1243/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0408e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1244/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5039e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1245/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.9960e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1246/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.5409e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1247/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.1952e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1248/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6667e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1249/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3173e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1250/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2280e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1251/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0650e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1252/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4566e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1253/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1079e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1254/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.5438e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1255/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7700e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1256/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3602e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1257/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0999e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1258/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0843e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1259/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7450e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1260/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2961e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1261/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3075e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1262/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1166e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1263/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6952e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1264/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9031e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1265/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.8474e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1266/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1605e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1267/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.2183e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1268/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9297e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1269/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9610e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1270/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.5955e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1271/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9813e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1272/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.5665e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1273/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0936e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1274/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0995e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1275/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5356e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1276/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.4850e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1277/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1254e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1278/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2980e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1279/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0952e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1280/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.6468e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1281/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2782e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1282/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0446e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1283/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.0142e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1284/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.7750e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9948\n",
      "Epoch 1285/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.6517e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1286/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.3070e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9948\n",
      "Epoch 1287/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7835e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1288/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8186e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1289/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4172e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1290/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9664e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1291/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.7983e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1292/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.9216e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9948\n",
      "Epoch 1293/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.3502e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9948\n",
      "Epoch 1294/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6403e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1295/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6770e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9948\n",
      "Epoch 1296/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3186e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1297/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 6.1691e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1298/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0703e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1299/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.2134e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1300/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 9.6123e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1301/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 1.1040e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1302/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 9.6180e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1303/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5051e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1304/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.3716e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1305/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2243e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1306/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2721e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1307/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1173e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1308/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5553e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1309/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 9.4084e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1310/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.1212e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1311/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9277e-04 - accuracy: 0.9997 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1312/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1076e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1313/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2822e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1314/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.6174e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1315/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.2091e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1316/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.3606e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1317/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.0100e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1318/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.6863e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1319/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2217e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1320/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8259e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1321/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.3295e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1322/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1519e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1323/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2105e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1324/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7245e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1325/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4446e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1326/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2231e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1327/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.0928e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1328/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0599e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1329/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.4768e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1330/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5736e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1331/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9430e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1332/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.1090e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1333/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.9374e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1334/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6868e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1335/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0225e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1336/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1016e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1337/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.9371e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1338/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0935e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1339/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3317e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1340/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.4019e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1341/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2493e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1342/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.0697e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1343/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9567e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1344/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.1881e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1345/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3780e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1346/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6459e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1347/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1585e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1348/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.8104e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1349/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4502e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1350/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3307e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1351/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.2286e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1352/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6166e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1353/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0665e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1354/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.7494e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1355/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.9732e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1356/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4336e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1357/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1212e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1358/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1317e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1359/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.9183e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1360/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 9.7330e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1361/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 9.3839e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1362/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 1.9056e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1363/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0211e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1364/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1533e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1365/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4745e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1366/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0704e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1367/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0675e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1368/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.8186e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1369/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 3.6591e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1370/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6372e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1371/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.3822e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1372/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5710e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1373/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4225e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1374/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7023e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1375/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2451e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1376/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.3605e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1377/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.8493e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1378/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.6125e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1379/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5816e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1380/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3470e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1381/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2294e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1382/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5711e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1383/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.4361e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1384/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.6481e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1385/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0169e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1386/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4470e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1387/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5601e-05 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1388/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.8698e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1389/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1125e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9961\n",
      "Epoch 1390/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.7013e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1391/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.1198e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9948\n",
      "Epoch 1392/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2519e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9948\n",
      "Epoch 1393/2000\n",
      "49/49 [==============================] - 71s 1s/step - loss: 4.5174e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1394/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 6.9829e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1395/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.4292e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1396/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 6.4611e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1397/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.0381e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1398/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 1.0619e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1399/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 1.7884e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1400/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 6.8681e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1401/2000\n",
      "49/49 [==============================] - 70s 1s/step - loss: 1.1485e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1402/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 5.7240e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1403/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 8.2280e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1404/2000\n",
      "49/49 [==============================] - 68s 1s/step - loss: 3.6064e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1405/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 1.2291e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1406/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.3410e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1407/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 9.0591e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1408/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1160e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1409/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4420e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1410/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1206e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1411/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1150e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1412/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6036e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1413/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0427e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1414/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.5983e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1415/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5411e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1416/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.1807e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1417/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8597e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1418/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.1224e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1419/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.0031e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1420/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.9169e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1421/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.1651e-05 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1422/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.8955e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1423/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2781e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1424/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.8449e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1425/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.3843e-04 - accuracy: 0.9997 - val_loss: 0.0101 - val_accuracy: 0.9961\n",
      "Epoch 1426/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.4308e-06 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9961\n",
      "Epoch 1427/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.8893e-06 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9961\n",
      "Epoch 1428/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.9459e-05 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9961\n",
      "Epoch 1429/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0675e-05 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9961\n",
      "Epoch 1430/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2653e-05 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9948\n",
      "Epoch 1431/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.3023e-05 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9948\n",
      "Epoch 1432/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.7783e-06 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 1433/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0709e-06 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 1434/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1415e-06 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 1435/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4871e-06 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 1436/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.5563e-06 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 1437/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1354e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9961\n",
      "Epoch 1438/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9120e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9961\n",
      "Epoch 1439/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5891e-05 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9961\n",
      "Epoch 1440/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4905e-06 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9961\n",
      "Epoch 1441/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.9317e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9961\n",
      "Epoch 1442/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1971e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9961\n",
      "Epoch 1443/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.3578e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9961\n",
      "Epoch 1444/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0043e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9961\n",
      "Epoch 1445/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5016e-06 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9961\n",
      "Epoch 1446/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.6897e-06 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9961\n",
      "Epoch 1447/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.9894e-06 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9961\n",
      "Epoch 1448/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5903e-06 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9961\n",
      "Epoch 1449/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.9217e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1450/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0835e-05 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9961\n",
      "Epoch 1451/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2172e-05 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9961\n",
      "Epoch 1452/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.3648e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1453/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2090e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1454/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2965e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1455/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.7063e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1456/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.0478e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1457/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.1610e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1458/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9870e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 1459/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0632e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1460/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.5784e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1461/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1476e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1462/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.7801e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1463/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8867e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1464/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4360e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1465/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.2226e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1466/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0772e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1467/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2484e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 1468/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5890e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1469/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8214e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1470/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0748e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1471/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.5584e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1472/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.3422e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1473/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.3368e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1474/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.9151e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1475/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1139e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1476/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.7569e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1477/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.6509e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1478/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0276e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1479/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.0291e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1480/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.2985e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1481/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.9145e-05 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9948\n",
      "Epoch 1482/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.7800e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1483/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1590e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1484/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8616e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1485/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5480e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1486/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8938e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1487/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5594e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1488/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6978e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1489/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2629e-05 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1490/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5491e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1491/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.7012e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1492/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2160e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1493/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.7488e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1494/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.4551e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1495/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8042e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1496/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1175e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1497/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.9432e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1498/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.6841e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1499/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8674e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1500/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1644e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1501/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.8448e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1502/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1571e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1503/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5189e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1504/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3505e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1505/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9331e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1506/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5138e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1507/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.3350e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1508/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.7249e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1509/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4694e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1510/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.2543e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1511/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.7723e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1512/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.4091e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1513/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1036e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1514/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.7294e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1515/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.4811e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1516/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.2527e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1517/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0180e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1518/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.3897e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1519/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4738e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1520/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1277e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1521/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2354e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1522/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.4497e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1523/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9825e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1524/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.9389e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1525/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.6519e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1526/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2798e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1527/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1172e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1528/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1131e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1529/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.4424e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1530/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8101e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1531/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2410e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1532/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1817e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1533/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.0564e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1534/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.0324e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1535/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3655e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1536/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7253e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1537/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.6917e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1538/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.7957e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1539/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9628e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1540/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7261e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1541/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.0604e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1542/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1778e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1543/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.7769e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1544/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4284e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1545/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8644e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1546/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.4050e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1547/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0517e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1548/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.7617e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1549/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.0494e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1550/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2601e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1551/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2995e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9948\n",
      "Epoch 1552/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.8522e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9948\n",
      "Epoch 1553/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.9094e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9948\n",
      "Epoch 1554/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.0360e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9948\n",
      "Epoch 1555/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1987e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9961\n",
      "Epoch 1556/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0342e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9961\n",
      "Epoch 1557/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.3241e-06 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1558/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.4519e-06 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1559/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.9548e-06 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1560/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.2651e-06 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1561/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1413e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1562/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1285e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1563/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1451e-06 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1564/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.9179e-06 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1565/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.3231e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1566/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5846e-06 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 1567/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9068e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1568/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.3269e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1569/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.4545e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1570/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2182e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1571/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1596e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1572/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5507e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1573/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.5803e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1574/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.4084e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1575/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.9347e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1576/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1484e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1577/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.1173e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1578/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.0444e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1579/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0839e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1580/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.8563e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1581/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4396e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1582/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.8102e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1583/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8644e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1584/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5428e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1585/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.8295e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1586/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.9873e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1587/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9386e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1588/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8656e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1589/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.9675e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1590/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.6243e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9974\n",
      "Epoch 1591/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1279e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1592/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.8787e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 1593/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0843e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1594/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2781e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1595/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5106e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1596/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8768e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1597/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1546e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1598/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.8152e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1599/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2037e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1600/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1740e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.4667e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1602/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2786e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1603/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5088e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1604/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.8972e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1605/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.3381e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1606/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4306e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1607/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5374e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1608/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.6869e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1609/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2299e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1610/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8757e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1611/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.4275e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1612/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6874e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1613/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0384e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1614/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5355e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1615/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.8101e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1616/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0414e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1617/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7739e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1618/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1959e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1619/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.2157e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1620/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.3648e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1621/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0532e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1622/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2136e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1623/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.6005e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1624/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9069e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1625/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9606e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1626/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8703e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1627/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.6204e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1628/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.1634e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1629/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4035e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1630/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6945e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1631/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5884e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1632/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8524e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1633/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1276e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1634/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4080e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1635/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.0997e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1636/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2015e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1637/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.6042e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1638/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5616e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1639/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.0291e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1640/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1592e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1641/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8056e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1642/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3521e-06 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1643/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.5134e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1644/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8341e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1645/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.9762e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1646/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.0590e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1647/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.0581e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1648/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.3024e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1649/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7282e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1650/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6227e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1651/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4628e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1652/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 4.1275e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1653/2000\n",
      "49/49 [==============================] - 74s 2s/step - loss: 4.6222e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1654/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3941e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1655/2000\n",
      "49/49 [==============================] - 71s 1s/step - loss: 5.4976e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1656/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 7.5524e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1657/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 2.4312e-04 - accuracy: 0.9997 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1658/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0339e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1659/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5571e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1660/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6268e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9948\n",
      "Epoch 1661/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.0239e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1662/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.9964e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9948\n",
      "Epoch 1663/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5146e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9948\n",
      "Epoch 1664/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0978e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1665/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5566e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1666/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8920e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9948\n",
      "Epoch 1667/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.1819e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9948\n",
      "Epoch 1668/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5141e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 1669/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6980e-06 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 1670/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.5056e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1671/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.0041e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9974\n",
      "Epoch 1672/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.0897e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9974\n",
      "Epoch 1673/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.3270e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9974\n",
      "Epoch 1674/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3880e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9974\n",
      "Epoch 1675/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5040e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 1676/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1892e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 1677/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.8280e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 1678/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5153e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 1679/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0009e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 1680/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.2804e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 1681/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3375e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 1682/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1350e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 1683/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1837e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 1684/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.8662e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1685/2000\n",
      "49/49 [==============================] - 73s 2s/step - loss: 9.8544e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1686/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.1159e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 1687/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.9187e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9974\n",
      "Epoch 1688/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.1364e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9974\n",
      "Epoch 1689/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.0185e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1690/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5375e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1691/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8450e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1692/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 6.0131e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1693/2000\n",
      "49/49 [==============================] - 69s 1s/step - loss: 7.6415e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1694/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1632e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1695/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0282e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 1696/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6981e-06 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9961\n",
      "Epoch 1697/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.7846e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9961\n",
      "Epoch 1698/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9633e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9961\n",
      "Epoch 1699/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.6148e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1700/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8911e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1701/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.3524e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1702/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9282e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1703/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3904e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1704/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0492e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1705/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9748e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1706/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.7468e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1707/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6962e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1708/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.0895e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1709/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6862e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1710/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6340e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1711/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.3831e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1712/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1936e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1713/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4869e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1714/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1690e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1715/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.2749e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1716/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4970e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1717/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.8454e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1718/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3675e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1719/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.1396e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1720/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5056e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1721/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.5875e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1722/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.8851e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1723/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4718e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1724/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.9751e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1725/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5339e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1726/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.7865e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1727/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4256e-06 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
      "Epoch 1728/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4511e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9961\n",
      "Epoch 1729/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3195e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1730/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8396e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1731/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5951e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1732/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.0266e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1733/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.6908e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1734/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3611e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1735/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.7110e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1736/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.0620e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1737/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.0516e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1738/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7998e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1739/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.1553e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1740/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3491e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1741/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.2137e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1742/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.5219e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1743/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9298e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1744/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7741e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1745/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.0497e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1746/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.4557e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1747/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3127e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1748/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6703e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1749/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1750/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.6300e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1751/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6923e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1752/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.1289e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1753/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.2494e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1754/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5900e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1755/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7177e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 1756/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8274e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 1757/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.9008e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 1758/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5564e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 1759/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3866e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 1760/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.9953e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1761/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0838e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1762/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.4942e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9974\n",
      "Epoch 1763/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.6901e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9974\n",
      "Epoch 1764/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5975e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 1765/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.8496e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9974\n",
      "Epoch 1766/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7685e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 1767/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.0971e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9974\n",
      "Epoch 1768/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3040e-06 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9974\n",
      "Epoch 1769/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.5724e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 1770/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.7285e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 1771/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.2194e-05 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 1772/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.7499e-06 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9961\n",
      "Epoch 1773/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.7293e-05 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
      "Epoch 1774/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.8714e-06 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9974\n",
      "Epoch 1775/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.4447e-06 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
      "Epoch 1776/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.7320e-06 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9974\n",
      "Epoch 1777/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.4294e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9974\n",
      "Epoch 1778/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2480e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 1779/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.7033e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9974\n",
      "Epoch 1780/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 6.9090e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9974\n",
      "Epoch 1781/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9391e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9974\n",
      "Epoch 1782/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.0959e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 1783/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.2836e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 1784/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.9669e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
      "Epoch 1785/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9114e-06 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9974\n",
      "Epoch 1786/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5423e-06 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 1787/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.1153e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 1788/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5461e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9974\n",
      "Epoch 1789/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.6948e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 1790/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6492e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 1791/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8173e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9974\n",
      "Epoch 1792/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.6240e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 1793/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2276e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1794/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.0783e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1795/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.8811e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1796/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0293e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1797/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.3075e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1798/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1426e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1799/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.7482e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1800/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6684e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6939e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1802/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.8734e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1803/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.2885e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1804/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.5556e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1805/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.3345e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1806/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0626e-06 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 1807/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.8388e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1808/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5584e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1809/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.2049e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1810/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.7659e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1811/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9479e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1812/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.4114e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1813/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6451e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1814/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1209e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1815/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7102e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1816/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0734e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1817/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4600e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1818/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.7462e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1819/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1127e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1820/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.3378e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1821/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5036e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1822/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.5334e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1823/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5149e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1824/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9287e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1825/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9036e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1826/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.2138e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1827/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.5343e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1828/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.7436e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1829/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8463e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1830/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.4047e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1831/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6479e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9948\n",
      "Epoch 1832/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0482e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9948\n",
      "Epoch 1833/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.2396e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9948\n",
      "Epoch 1834/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.4219e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1835/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2458e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1836/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.4556e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1837/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5657e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1838/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.1618e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1839/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 8.0677e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1840/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4496e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1841/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9313e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 1842/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.3913e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1843/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6421e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1844/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.7179e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1845/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.8797e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1846/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.4586e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1847/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3731e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1848/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.7350e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1849/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5252e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1850/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1881e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1851/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.1932e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1852/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.8053e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1853/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 9.7870e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1854/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.6134e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1855/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5249e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1856/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.8873e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9961\n",
      "Epoch 1857/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5656e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9961\n",
      "Epoch 1858/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4450e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1859/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5499e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1860/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0559e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "Epoch 1861/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9539e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1862/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.3778e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1863/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4550e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1864/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.7542e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1865/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8414e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1866/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8977e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1867/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3733e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1868/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1992e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1869/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8013e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1870/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9978e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1871/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.7191e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1872/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.1542e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1873/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8316e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1874/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.1842e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1875/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.2520e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1876/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.6952e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1877/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.2246e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1878/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.6351e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9948\n",
      "Epoch 1879/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.0084e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9948\n",
      "Epoch 1880/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 5.3663e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1881/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.8734e-06 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1882/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1533e-04 - accuracy: 0.9997 - val_loss: 0.0118 - val_accuracy: 0.9948\n",
      "Epoch 1883/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8731e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9948\n",
      "Epoch 1884/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.9443e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9948\n",
      "Epoch 1885/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9435e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9948\n",
      "Epoch 1886/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5033e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9948\n",
      "Epoch 1887/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.1193e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9948\n",
      "Epoch 1888/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.2526e-06 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 1889/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3526e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
      "Epoch 1890/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.1402e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9948\n",
      "Epoch 1891/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.7826e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1892/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.0063e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9948\n",
      "Epoch 1893/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.4562e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1894/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.2649e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1895/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.3687e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1896/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.4223e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1897/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1660e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1898/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.6083e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1899/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3204e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1900/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.3999e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1901/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5339e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1902/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.7215e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1903/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3380e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1904/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.0215e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1905/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6157e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1906/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6651e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1907/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8009e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1908/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9371e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1909/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.0617e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1910/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2293e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1911/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9023e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1912/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2609e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1913/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9946e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1914/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.0286e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1915/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.2710e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1916/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4999e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1917/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3210e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1918/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.6942e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1919/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0703e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1920/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.3292e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1921/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5619e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1922/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9860e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1923/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.4786e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1924/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.3005e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1925/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9002e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 1926/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.1498e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1927/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.9980e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1928/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.3596e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9961\n",
      "Epoch 1929/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.8944e-06 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9961\n",
      "Epoch 1930/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9046e-06 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9961\n",
      "Epoch 1931/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0993e-06 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9961\n",
      "Epoch 1932/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8910e-06 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1933/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.6145e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1934/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4803e-06 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 1935/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3097e-06 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1936/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 8.8359e-06 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9961\n",
      "Epoch 1937/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3077e-06 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1938/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9012e-06 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1939/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6858e-06 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1940/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.7126e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1941/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5672e-06 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 1942/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.2804e-06 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 1943/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0363e-06 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9961\n",
      "Epoch 1944/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.5903e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
      "Epoch 1945/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.5323e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1946/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.8495e-06 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 1947/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.4026e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1948/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.1209e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1949/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.3553e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1950/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9418e-06 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9961\n",
      "Epoch 1951/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 5.9258e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1952/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4097e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 1953/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.7615e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1954/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1804e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9961\n",
      "Epoch 1955/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.4477e-06 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 1956/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.8538e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 1957/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5496e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1958/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.2540e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1959/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.3083e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1960/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.9732e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1961/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.9452e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1962/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.6699e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1963/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.7735e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1964/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 1.4208e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1965/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 4.4683e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1966/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1796e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1967/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.5608e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1968/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.1609e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1969/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.7577e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1970/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 9.0569e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1971/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.2588e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
      "Epoch 1972/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 4.6920e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1973/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.2586e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1974/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.6749e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1975/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5024e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1976/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.1814e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1977/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.4552e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9974\n",
      "Epoch 1978/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.3179e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 1979/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.9658e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 1980/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.9184e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1981/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.9131e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1982/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.0824e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1983/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.4930e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1984/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.2550e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1985/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.4855e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1986/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.5200e-06 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 1987/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 3.4545e-06 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 1988/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.9747e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 1989/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4470e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9974\n",
      "Epoch 1990/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.8295e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 1991/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.4401e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 1992/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 6.8311e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 1993/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.4326e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9961\n",
      "Epoch 1994/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.6084e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 1995/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 3.0165e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 1996/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 7.2552e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 1997/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.1605e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 1998/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 7.3016e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 1999/2000\n",
      "49/49 [==============================] - 73s 1s/step - loss: 2.2778e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "Epoch 2000/2000\n",
      "49/49 [==============================] - 72s 1s/step - loss: 1.7144e-06 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9974\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB5\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "save_model_interval = 200\n",
    "checkpoint_filepath = path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch{epoch:04d}.pb' # -val_acc{val_accuracy:.2f}\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    period=save_model_interval,\n",
    "    save_best_only=False)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                  patience=5, min_lr=0.00001,cooldown=1, verbose=1)\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "history = model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS, callbacks=[model_checkpoint_callback,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.subplot(1, 2, 2)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 39s 1s/step - loss: 0.1815 - accuracy: 0.9599\n",
      "test_indoor_ds_results:test loss, test acc: [0.18154418468475342, 0.9598662257194519]\n"
     ]
    }
   ],
   "source": [
    "#indoor testset\n",
    "test_indoor_ds_results = model.evaluate(test_indoor_ds)\n",
    "print(\"test_indoor_ds_results:test loss, test acc:\", test_indoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 65s 1s/step - loss: 0.3510 - accuracy: 0.9455\n",
      "test_outdoor_ds_results:test loss, test acc: [0.3510190546512604, 0.9455413818359375]\n"
     ]
    }
   ],
   "source": [
    "#outdoor testset\n",
    "test_outdoor_ds_results = model.evaluate(test_outdoor_ds)\n",
    "print(\"test_outdoor_ds_results:test loss, test acc:\", test_outdoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 45s 1s/step - loss: 1.0380 - accuracy: 0.8364\n",
      "test_belt_ds_results:test loss, test acc: [1.038012146949768, 0.8363553881645203]\n"
     ]
    }
   ],
   "source": [
    "#belt testset\n",
    "test_belt_ds_results = model.evaluate(test_belt_ds)\n",
    "print(\"test_belt_ds_results:test loss, test acc:\", test_belt_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB5/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read path of trained model\n",
    "import os, os.path\n",
    "trained_path = path_to_model\n",
    "models_paths = []\n",
    "for name_folder in os.listdir(trained_path):\n",
    "    if os.path.isdir(os.path.join(trained_path, name_folder)):\n",
    "        models_paths.append(os.path.join(trained_path, name_folder))\n",
    "models_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_92781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_168645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_95049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_172869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_96551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_89885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_158252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_140009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_176526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_89977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_92384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_167431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_171655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_89055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_155475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_95762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_163836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_89712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_91488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_171717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_166653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_96434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_95945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_91977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_94334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_168707) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_159052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_169921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_169688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_155021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_176900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_89305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_173912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_154959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_91712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_159114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_89529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_90549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_89096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_95273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_90641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_94998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_164879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_161262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_92608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_166093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_89264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_94392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_175966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_91885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_173305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_154381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_93265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_162451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_160888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_91279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_154552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_95721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_96867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_163898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_174145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_93754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_94161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_172091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_92109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_168100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_93662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_162062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_92333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_94550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_94642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_166326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_169081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_93713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_160655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_163665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_92873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_96826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_162684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_71339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_155849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_94601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_156602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_157271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_166824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_164443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_170550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_172931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_93041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_96169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_95314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_92201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_93530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_89753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_157816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_175904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_165486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_158423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_88824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_96602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_177133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_175126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_165657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_96999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_95986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_175733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_161869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_151169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_177071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_159441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_170877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_92649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_175359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_93438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_91089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_166886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_95222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_91529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_91936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_94866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_172262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_90208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_96118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_156431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_169859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_91221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_93306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_91753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_176464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_174752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_154614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_165719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_93082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_91320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_89213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_88691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_93978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_90325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_94433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_169314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_172324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_94202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_157878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_171110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_174083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_159612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_88650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_90376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_164272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_91048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_88491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_92990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_160048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_135656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_91437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_165112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_163229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_176293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_165050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_94774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_177507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_157209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_96643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_95497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_92557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_167260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_169252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_163291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_172698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_159674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_166264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_93214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_164505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_160219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_160281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_89661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_96342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_163058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_157038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_95090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_155413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_90167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_92160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_173538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_96775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_157645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_156042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_160826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_95446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_93489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_95670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_175297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_171048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_156104) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_158859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_158485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_167867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_90417) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_89437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_90997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_170488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_90600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_88532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_168474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_161495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_174519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_95894) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_92832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_90865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_171484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_91661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_174690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_96210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_90109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_90773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_90824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_161433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_89936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_93937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_96393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_95538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_168038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_173476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_167493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_88440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_88865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_89488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_146838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_94110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_170295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_92425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_88997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_162124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_93886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_156664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_162622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_94825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 36s 1s/step - loss: 0.1851 - accuracy: 0.9537\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.2852 - accuracy: 0.9424\n",
      "35/35 [==============================] - 41s 1s/step - loss: 0.8410 - accuracy: 0.8264\n",
      "Epoch200 \n",
      " test_indoor_acc=0.9537346959114075 \n",
      " test_outdoor_acc=0.9423567056655884 \n",
      " test_belt_acc=0.826382577419281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_302687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_239562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_303527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_319125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_235917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_241529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_241305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_304134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_240458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_240806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_320401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_317973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_305370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_239338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_243255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_321615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_319561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_307751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_243123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_238640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_308125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_236805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_322720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_236673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_238681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_311742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_304072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_242690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_238233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_238192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_238457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_238813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_314901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_239521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_308940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_311306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_321989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_312582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_238009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_301669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_303465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_241478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_315944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_302858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_239969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_313080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_321008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_317740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_235744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_241702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_281912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_239694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_234788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_308318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_236464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_307144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_240898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_237253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_308878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_234906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_217595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_309547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_319732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_237693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_235968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_300637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_240142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_242242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_322160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_241254) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_305930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_236581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_239786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_317304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_239745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_320946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_311368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_239470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_309314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_242649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_310761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_301731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_310154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_313516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_301277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_242150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_304508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_321382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_234747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_314356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_241570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_239088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_316806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_242201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_297425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_314123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_237917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_286265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_317911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_241753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_238416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_243082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_234696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_242425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_315508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_241081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_308707) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_305697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_242858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_313687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_300808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_306537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_303901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_241794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_315337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_304741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_236897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_237785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_300870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_302920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_239246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_235253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_242466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_241122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_314294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_318518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_323327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_241926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_313749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_237968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_235785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_318954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_240417) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_240648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_235693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_240689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_234947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_309485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_241977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_320339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_323763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_305308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_307082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_237477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_235121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_316115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_323389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_240590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_315570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_302105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_312349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_235520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_303294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_316551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_323156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_293094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_242598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_301215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_306911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_310699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_241030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_318580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_305115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_236009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_235561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_235352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_320775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_238365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_306304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_322222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_308380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_237304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_238141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_236632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_239129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_311975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_240010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_309921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_242807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_238589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_242374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_322549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_312520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_235469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_240366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_238905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_236365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_313142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_237535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_314963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_239037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_304679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_237121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_314730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_237029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_242018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_310528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_319794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_310092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_306475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_316177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_240193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_319187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_307689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_240234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_302298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_305868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_320168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_238864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_240857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_235311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_312909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_236233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_236856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_236423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_236192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_242899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_237576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_237080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_316744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_243031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_237345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_307518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_235080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_318347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_302360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_317133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_239918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_239297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_237744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_311135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_236141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_317366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_241346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_322782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_311913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_321553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 35s 1s/step - loss: 0.1805 - accuracy: 0.9543\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.2867 - accuracy: 0.9439\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.8461 - accuracy: 0.8305\n",
      "Epoch400 \n",
      " test_indoor_acc=0.9542920589447021 \n",
      " test_outdoor_acc=0.9439490437507629 \n",
      " test_belt_acc=0.8304623961448669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_383813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_382951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_449743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_469434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_468827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_381399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_388652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_384694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_386196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_461241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_456432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_386247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_381066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_383358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_389533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_465403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_464796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_460572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_384246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_456977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_385366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_385315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_385748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_447555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_388876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_381971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_466010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_461615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_448965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_388428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_462222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_466617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_383307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_385407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_465232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_386736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_383083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_381358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_458020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_389136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_389309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_382470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_460401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_464251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_388031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_382859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_464625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_462393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_454985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_448383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_384735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_453189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_462829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_388479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_386064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_467286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_457584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_382419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_443703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_469667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_453360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_458253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_452815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_389401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_451975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_454403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_457646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_446915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_383755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_450179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_470041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_388296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_447086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_387583) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_454596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_464018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_385142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_463644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_456806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_383175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_385091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_383582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_457039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_386471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_387756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_468998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_450412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_388968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_465839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_460634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_363873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_466446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_468500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_467831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_385616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_469605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_387176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_381798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_467224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_464189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_388703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_388744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_463582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_459187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_386644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_468438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_384419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_389177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_381184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_450350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_461008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_454658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_381225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_450957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_389085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_386695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_387807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_450786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_383134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_386288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_449198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_455763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_384287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_453796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_455592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_439372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_455156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_387135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_449805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_385524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_457413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_386868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_458627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_382246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_468267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_388072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_386926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_449136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_453422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_459794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_383854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_447947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_383623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_387359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_381025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_387532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_465465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_451648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_382701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_386967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_381531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_387848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_383971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_460027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_383531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_384867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_463022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_459420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_384918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_381589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_382910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_467893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_452753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_384511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_448576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_466679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_382022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_447148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_463084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_382511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_387084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_451019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_453967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_384063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_385840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_382287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_385575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_384022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_383399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_388520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_458860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_387308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_464858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_386023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_451393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_467660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_466072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_459358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_458191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_455825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_384195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_382643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_381839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_381747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_389360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_382063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_428190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_449572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_452146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_455218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_461848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_384470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_456370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_387400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_448638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_388255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_386512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_388204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_458798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_451586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_382195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_386420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_459965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_388927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_387624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_385972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_385183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_452582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_381630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_387980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_469060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_461786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_454029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_380974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_382742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_384959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_462455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_447493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_456199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_448009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_461179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_452208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_384643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_385799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_467053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_463411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_432543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 35s 1s/step - loss: 0.1856 - accuracy: 0.9560\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3070 - accuracy: 0.9430\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.9020 - accuracy: 0.8341\n",
      "Epoch600 \n",
      " test_indoor_acc=0.9559643268585205 \n",
      " test_outdoor_acc=0.9429936408996582 \n",
      " test_belt_acc=0.8340888619422913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_600088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_529650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_613952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_528935) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_530711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_593847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_594930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_609121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_599714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_531816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_532356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_607533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_614123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_535469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_608514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_606693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_532315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_578835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_530487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_528131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_603269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_528711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_601448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_603705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_533376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_594239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_532091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_615290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_593378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_574482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_614792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_596642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_609376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_613516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_533259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_527266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_604483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_614730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_531658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_530986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_532539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_612738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_614185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_529691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_530047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_535168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_616333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_528090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_606319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_532936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_604919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_532580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_527358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_527650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_531027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_611150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_533651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_614559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_534364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_535601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_527517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_600695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_528538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_602055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_615897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_607471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_609314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_528993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_613578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_604312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_612971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_534496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_602117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_528314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_613345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_529874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_599481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_531159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_605479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_605152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_601277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_608078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_608140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_603876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_599107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_531434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_596704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_529375) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_611757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_529823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_534099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_534720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_510165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_527476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_528762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_603938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_612909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_531251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_529243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_615352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_609936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_534588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_605712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_530355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_597940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_535652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_534140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_596035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_527691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_532040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_530762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_595864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_606926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_598438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_528355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_534995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_602724) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_604545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_602491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_528579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_610543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_531908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_612364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_598267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_534048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_533692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_603098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_533427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_597249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_600950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_531607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_603331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_528803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_595257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_593785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_527823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_599652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_589995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_598874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_535825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_533600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_531867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_611695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_532488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_597078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_601510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_532712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_529034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_531210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_609874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_533916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_533028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_600888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_535428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_597878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_534812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_596097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_533824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_527317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_529426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_530263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_605090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_611524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_533218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_528039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_535377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_594868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_530314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_608685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_595428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_532987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_533160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_529915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_535260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_607300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_607907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_601884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_593440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_529599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_534323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_585664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_529467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_528263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_598500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_528487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_606257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_594675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_612302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_611088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_606864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_530579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_610481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_530146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_535693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_535219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_527922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_532763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_595490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_531475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_600259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_532804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_530935) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_597685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_529202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_530803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_531383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_615119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_530538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_534771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_533875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_609703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_600321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_534944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_529151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_531699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_533468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_599045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_615959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_615726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_606086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_534547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_608747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_612131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_610917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_594301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_596471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_535036) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_530105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_527881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_532264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_597311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_532132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_605650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_593207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_534272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_610310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_602662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 35s 1s/step - loss: 0.1867 - accuracy: 0.9560\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3165 - accuracy: 0.9443\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.9296 - accuracy: 0.8318\n",
      "Epoch800 \n",
      " test_indoor_acc=0.9559643268585205 \n",
      " test_outdoor_acc=0.9442675113677979 \n",
      " test_belt_acc=0.8318222761154175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_762631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_677997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_754983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_752010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_678878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_675449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_679010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_751777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_746619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_678654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_678114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_756001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_745343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_758055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_756234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_677060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_679557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_754438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_758429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_676403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_762257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_680214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_673656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_746012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_673615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_754205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_675673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_675291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_745779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_676172) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_753831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_743376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_753162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_673774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_739676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_745950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_681517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_749396) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_681466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_675060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_676345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_759269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_674785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_753769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_760250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_680794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_674179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_759036) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_740973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_674337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_747746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_679766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_747808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_744176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_754812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_680621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_680173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_681334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_742769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_750843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_741555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_743609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_681018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_679102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_680886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_757822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_675332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_679458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_749629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_680346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_740083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_678165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_756172) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_744565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_751450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_675009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_678430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_678389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_749567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_761417) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_675724) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_676877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_673948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_755674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_752991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_675897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_676561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_757215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_750781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_750174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_750236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_739505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_679285) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_673989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_753598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_679990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_678338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_680397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_740145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_681950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_676612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_674561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_741166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_759643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_677732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_681242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_676213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_676785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_751388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_725133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_742395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_748789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_761090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_677681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_747575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_741788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_656463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_675541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_677009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_679949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_760857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_677325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_743547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_740537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_757993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_751948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_673564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_678206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_756779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_720780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_677457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_680570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_743002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_761028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_675500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_679516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_748415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_681293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_675233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_758600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_678786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_744736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_743983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_761650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_674388) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_752384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_731962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_762195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_681110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_750610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_677956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_759876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_751217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_675948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_681767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_757448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_681991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_674653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_741228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_675765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_757386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_679234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_760483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_676653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_742333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_755612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_746993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_758662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_752555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_677284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_749022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_745405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_750003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_681726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_740599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_747186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_742162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_756608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_755419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_676836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_744238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_681675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_677508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_679898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_748960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_680662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_747248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_746557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_677101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_681558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_675101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_678613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_741726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_754376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_760421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_674429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_681069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_759207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_677773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_676121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_674836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_675989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_674612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_679725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_761588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_762024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_679061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_759814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_748353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_678837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_746386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_681899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_679326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_755045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_753224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_748182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_736293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_682123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_677549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_676444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_674877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_752617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_673815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_742940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_680845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_744798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_680438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_674121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_674220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_756841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_739738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_679674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_680122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_677233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_677905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_678562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_745172) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 35s 1s/step - loss: 0.1888 - accuracy: 0.9565\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3043 - accuracy: 0.9452\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.9565 - accuracy: 0.8323\n",
      "Epoch1000 \n",
      " test_indoor_acc=0.95652174949646 \n",
      " test_outdoor_acc=0.9452229142189026 \n",
      " test_belt_acc=0.8322756290435791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_904311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_885823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_894733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_902319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_900149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_822083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_906194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_823826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_892875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_887291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_886401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_898702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_893566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_823551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_886917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_889087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_900694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_828309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_825379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_822439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_895885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_892704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_885994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_901992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_823378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_898873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_892268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_890301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_824931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_823867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_821327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_889927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_887484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_827784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_890883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_893893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_903766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_826440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_824707) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_826756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_904980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_901130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_826664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_889865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_823643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_820439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_820266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_907906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_892330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_821991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_895340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_887546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_908513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_824315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_892937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_907346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_907735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_827204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_827336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_878280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_902926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_821195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_906739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_824432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_894126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_820879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_894500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_907968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_895714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_897768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_897706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_897535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_819933) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_898095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_902490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_905354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_821609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_901363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_822215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_904373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_821378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_828441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_825776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_824880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_825196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_895947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_827560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_824972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_899309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_897161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_822879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_896554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_828268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_820747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_895278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_824223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_906132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_819974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_887873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_827387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_821650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_898935) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_908342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_827835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_820497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_825155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_825104) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_826491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_827611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_906568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_823195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_900756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_802781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_886855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_822490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_821551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_901930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_894064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_821818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_819882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_891723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_825552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_823419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_824091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_822721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_891661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_823775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_826888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_820930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_824050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_825420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_825644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_826939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_893504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_903533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_822930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_825328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_821859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_904747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_823103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_828085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_826715) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_895107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_826980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_825834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_904140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_903159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_820706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_903704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_820655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_822663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_888651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_828217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_827876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_827428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_901301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_822042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_907408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_894671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_823327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_822971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_898328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_823999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_824656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_908949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_905961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_899480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_907175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_824274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_896492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_900523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_827112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_890494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_821103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_904918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_821419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_820133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_905587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_822762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_826084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_886056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_899542) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_903097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_867098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_827163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_891490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_821154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_820538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_888713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_871451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_892097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_899916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_826043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_820092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_888106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_900087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_905525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_826216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_820307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_827652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_822531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_891054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_888480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_896928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_823154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_882611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_828044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_826308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_898266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_897099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_824748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_902552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_906801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_823602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_893311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_889320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_890556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_826267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_825992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_889258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_891116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_908575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_822266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_825603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_820971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_827993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_901737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_825875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_896321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_886463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_822307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_824483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_821767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_889694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_826532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_824524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_888044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 35s 1s/step - loss: 0.1852 - accuracy: 0.9593\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3146 - accuracy: 0.9446\n",
      "35/35 [==============================] - 40s 1s/step - loss: 0.9772 - accuracy: 0.8314\n",
      "Epoch1200 \n",
      " test_indoor_acc=0.9593088030815125 \n",
      " test_outdoor_acc=0.9445859789848328 \n",
      " test_belt_acc=0.8313689827919006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1039169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_968825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_972826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1048286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_970818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1052488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1040420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_971897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1054200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_971225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_969713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_973457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1035988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1054869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1036159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1053469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_967944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1054807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1043455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1037955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1050605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1050434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_966733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1038562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1046817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1042615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_971266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1034774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1033778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_966386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_974338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_970950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_967041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_967621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1038624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1032695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1047424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_972128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_966832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1043829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_971001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1051212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_967173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_970069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_970293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1034167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_971846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_970161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_969489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1041572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1038391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1046443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_968601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_967489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1034945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1045167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_968336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_970609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1047050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_972510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_970120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1053640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_967672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1034400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_966601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_969173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1047595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_969896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1052426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_974603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_971398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1036850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1036221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_969937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_966268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1013392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1040965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_967903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_966227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_971490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_971449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1042179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_970344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1047657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1053095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1046988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1048846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1049391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1033149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_967713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_971673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_967448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1039860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1033211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1039231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_971938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1035381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1054636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_973182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1041634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1040358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_966176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_949075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1042008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_966791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1032757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_973050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_974562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_968061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1041027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1048784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1051041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1051648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1050060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1042241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_970777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_969224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_970517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_969621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_966949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1049220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_971714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_970726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_973905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_972286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1044622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_966427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1052862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1055243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_968112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1044389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_971042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1045836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1043222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1038017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1042848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_972734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1039605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1033585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_969265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1043393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_968560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1052255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1033840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1054262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1049827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_966560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1024574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1037784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_968784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1051819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_973406) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_970568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_972785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_974170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1048224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1044000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_972602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_967265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1028905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_973722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1038998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_973681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_973274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1041401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_973946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1017745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1049998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1035614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_967000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1053033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1037177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1035007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1045603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_972561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_967845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_970385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1045774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_973233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1042786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_973854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_973630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_972169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1032117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_969845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_972958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1036788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_968377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1046381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_972378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_974287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1037410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1039798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_969397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_967224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1053702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_969015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_971622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1051881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_969056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1048613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1044560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_972070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1040794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_968957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1044062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1044996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_968733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_973498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1045229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1046210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1050667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_974129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_968153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1034338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_974078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1035552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_969672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_968285) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1040187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_972337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1032350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1054029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1048031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_974735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1036595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_969448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1051274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1032288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_973009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1049453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_967397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_971174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_974511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1037348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_974379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_968509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 36s 1s/step - loss: 0.1896 - accuracy: 0.9593\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3226 - accuracy: 0.9452\n",
      "35/35 [==============================] - 40s 1s/step - loss: 1.0141 - accuracy: 0.8336\n",
      "Epoch1400 \n",
      " test_indoor_acc=0.9593088030815125 \n",
      " test_outdoor_acc=0.9452229142189026 \n",
      " test_belt_acc=0.8336355686187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1117348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1190306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1196304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1120476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1117704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1113703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1113138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1114815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1187940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1191909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1198187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1192749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1114866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1179001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1189154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1119580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1193294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1190695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1196366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1188485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1195152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1194919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1198732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1181251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1117083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1189528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1196973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1112533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1184868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1188314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1180146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1185475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1170880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1183156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1198125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1117572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1118376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1113347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1114907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1182527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1181080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1114591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1197954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1190368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1116375) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1192516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1120685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1120211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1118867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1184261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1179063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1113571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1199401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1193356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1115321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1112866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1192687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1119936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1115362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1192142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1184090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1118684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1195090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1116426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1117307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1200335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1201549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1116202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1114019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1189092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1120644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1183094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1117480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1115703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1115978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1120028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1179891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1114683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1187333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1195759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1119091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1186104) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1181920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1195697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1199168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1095381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1116650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1193901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1185911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1197518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1119712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1189761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1180084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1185537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1179517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1180473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1184930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1119264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1115530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1191473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1117124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1117032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1115795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1120909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1194530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1118434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1118816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1113255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1120593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1118020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1120868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1116467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1119804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1117928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1112907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1182294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1113039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1199339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1116243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1181313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1118475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1192080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1113097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1186726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1190135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1114250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1113927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1119763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1117979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1200506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1182901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1112574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1191535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1114459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1201113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1119488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1118592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1191302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1120160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1113754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1115754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1175211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1201175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1120384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1185304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1112482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1114209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1196133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1117755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1187271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1115263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1116019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1164051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1181687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1183716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1184697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1118203) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1184323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1186664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1118152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1115927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1190866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1195526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1112733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1199946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1118643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1188921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1115571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1117256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1178656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1187878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1188547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1120252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1117531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1119040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1115090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1178423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1116915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1196911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1113306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1200008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1194592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1182465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1200568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1116874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1118908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1118244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1190928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1116691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1180644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1196740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1183654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1189699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1115479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1119539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1113795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1113530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1186166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1186493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1121041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1112692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1187100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1194337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1114418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1116151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1197580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1114367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1199775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1113978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1114642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1193123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1193730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1119132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1116599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1197347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1200942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1193963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1198561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1113479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1119315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1159698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1180706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1178594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1115131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1115039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1114151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1119987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1179455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1198794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1181858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1183483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1117796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1120817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1119356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1187707) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1116823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1120435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 36s 1s/step - loss: 0.2004 - accuracy: 0.9582\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3266 - accuracy: 0.9452\n",
      "35/35 [==============================] - 40s 1s/step - loss: 1.0503 - accuracy: 0.8327\n",
      "Epoch1600 \n",
      " test_indoor_acc=0.9581939578056335 \n",
      " test_outdoor_acc=0.9452229142189026 \n",
      " test_belt_acc=0.832728922367096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1265633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1267227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1264521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1260909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1344443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1264694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1336686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1262296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1267359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1266570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1331186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1261889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1332484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1345719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1266794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1266753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1342451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1345112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1339674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1329972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1339067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1328783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1265409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1334196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1265450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1326402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1329219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1343058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1259797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1266305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1262021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1340281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1259456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1330034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1332229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1258800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1329412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1342015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1337013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1343665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1330641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1336079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1260113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1331855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1344272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1345657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1264793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1343898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1327569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1260021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1328238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1333418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1259665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1266702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1259357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1334632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1328612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1260469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1332982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1338227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1327024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1263233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1334258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1338460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1346264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1346326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1329474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1338398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1342622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1335472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1262072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1266911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1264114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1262245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1339612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1339005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1329801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1265674) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1326464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1265806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1346824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1262337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1333589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1324974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1266962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1260777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1324912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1261225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1341237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1261001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1325381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1265185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1260245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1328845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1345050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1265582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1331622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1335239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1321529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1343836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1266478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1266081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1339441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1263192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1259010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1262968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1264073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1261408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1336624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1336017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1261797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1341470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1264752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1262113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1263890) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1346093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1260296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1264297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1331793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1263350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1261680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1260685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1261449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1261581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1310369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1340655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1337620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1267135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1347260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1266122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1325835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1337791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1335846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1259889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1261184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1260527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1259573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1263141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1263574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1263849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1241699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1261639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1328176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1266254) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1331015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1262917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1260072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1258851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1265226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1317198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1261848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1262744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1267186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1341844) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1260960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1264338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1262785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1344505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1266346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1260736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1263401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1260568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1258892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1334865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1265857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1261133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1265002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1337853) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1264910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1332422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1343291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1325773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1334025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1340848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1338834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1259848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1262561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1262520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1306016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1326962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1262693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1262469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1347493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1259184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1326209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1343229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1330408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1263009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1266030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1265134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1324741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1264961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1327631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1263666) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1266529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1259225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1345486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1263625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1344879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1264470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1340219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1340910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1267003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1334803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1332811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1265358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1260337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1337184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1259624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1325319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1347867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1264562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1333044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1331248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1347431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1259051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1346653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1337246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1341408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1330579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1263798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1264022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1264246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1340048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1342077) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1261357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1259415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1336453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1335410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1263442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1326791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1327398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1328005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1342684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1346886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1265898) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1333651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 35s 1s/step - loss: 0.2042 - accuracy: 0.9593\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3364 - accuracy: 0.9459\n",
      "35/35 [==============================] - 40s 1s/step - loss: 1.0553 - accuracy: 0.8336\n",
      "Epoch1800 \n",
      " test_indoor_acc=0.9593088030815125 \n",
      " test_outdoor_acc=0.9458598494529724 \n",
      " test_belt_acc=0.8336355686187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1472527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1492644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1480576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1409943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1413321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1410839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1483502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1406563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1485759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1477504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1471292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1488769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1408879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1491368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1488333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1487726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1482397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1411279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1472720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1408339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1472782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1407767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1405169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1467847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1493811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1412796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1480514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1479300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1405369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1408614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1493142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1409459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1486366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1411544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1481183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1482942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1409668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1411727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1409892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1410167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1476290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1474323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1408166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1482164) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1475101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1486537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1407502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1481557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1406166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1490216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1492971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1480950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1411503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1476119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1473887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1413020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1472153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1409510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1476726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1413112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1479969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1478547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1410116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1489547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1407543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1478802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1409011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1471637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1490823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1483004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1410656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1471230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1475792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1477333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1405733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1405502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1493749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1412572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1481728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1409103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1493578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1407726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1463516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1408390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1475163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1413229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1405210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1475537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1479362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1472091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1489376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1411992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1493204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1473109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1410615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1473949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1474556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1409719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1489609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1476897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1406886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1408563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1476959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1408115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1405942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1475730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1487555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1410208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1483331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1405891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1412623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1412175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1456687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1490154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1487788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1410564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1409551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1408838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1412847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1485930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1413504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1452334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1485152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1413453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1410788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1471699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1491804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1492411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1405675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1478111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1473280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1485323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1406787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1491430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1482771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1407957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1412399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1405328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1410391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1407451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1411111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1490590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1412888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1491197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1476352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1411900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1481790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1481121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1411951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1473716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1408655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1410432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1413071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1409286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1483564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1407278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1409235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1407319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1407675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1406339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1411012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1409760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1413677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1405543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1491975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1487228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1484171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1477940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1479736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1409327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1479907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1412216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1407003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1473342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1407095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1484716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1405118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1413280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1411768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1410340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1489002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1407998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1407054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1407899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1490761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1413545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1487166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1484778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1406390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1488162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1411320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1405774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1494185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1406207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1492037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1406614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1479129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1412124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1406845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1488395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1405983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1478740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1412348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1478173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1492582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1411676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1488940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1412440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1483938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1471059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1406655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1408431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1485385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1411228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1474930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1408787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1485992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1482335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1409062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1474494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1406115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1486599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1408207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1480343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1411070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1406431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1486973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1484109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1388017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1409984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1410880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1477566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1412664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1411452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1407227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1484545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1489983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 36s 1s/step - loss: 0.1815 - accuracy: 0.9599\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.3510 - accuracy: 0.9455\n",
      "35/35 [==============================] - 40s 1s/step - loss: 1.0380 - accuracy: 0.8364\n",
      "Epoch2000 \n",
      " test_indoor_acc=0.9598662257194519 \n",
      " test_outdoor_acc=0.9455413818359375 \n",
      " test_belt_acc=0.8363553881645203\n"
     ]
    }
   ],
   "source": [
    "test_indoor_acc = []\n",
    "test_outdoor_acc = []\n",
    "test_belt_acc = []\n",
    "test_indoor_loss = []\n",
    "test_outdoor_loss = []\n",
    "test_belt_loss = []\n",
    "\n",
    "for lm_idx,plmodel in enumerate(models_paths):\n",
    "    loaded_model=tf.keras.models.load_model(plmodel)\n",
    "    ## -> keep loss / acc in each epoch\n",
    "    #indoor\n",
    "    test_indoor_results = loaded_model.evaluate(test_indoor_ds)\n",
    "    test_indoor_loss.append(test_indoor_results[0]) # append loss\n",
    "    test_indoor_acc.append(test_indoor_results[1]) # append acc\n",
    "    #outdoor\n",
    "    test_outdoor_results = loaded_model.evaluate(test_outdoor_ds)\n",
    "    test_outdoor_loss.append(test_outdoor_results[0]) # append loss\n",
    "    test_outdoor_acc.append(test_outdoor_results[1]) # append acc\n",
    "    #belt\n",
    "    test_belt_results = loaded_model.evaluate(test_belt_ds)\n",
    "    test_belt_loss.append(test_belt_results[0]) # append loss\n",
    "    test_belt_acc.append(test_belt_results[1]) # append acc\n",
    "    # printout\n",
    "    lm_idx_show = (lm_idx+1) * save_model_interval\n",
    "    print(f\"Epoch{lm_idx_show:03d} \\n test_indoor_acc={test_indoor_acc[lm_idx]} \\n test_outdoor_acc={test_outdoor_acc[lm_idx]} \\n test_belt_acc={test_belt_acc[lm_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "test_avg_acc = []\n",
    "for i in range(len(test_indoor_acc)):\n",
    "    tmp_avg = (test_indoor_acc[i] + test_outdoor_acc[i] + test_belt_acc[i]) / 3.0\n",
    "    test_avg_acc.append(tmp_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(200, 2200, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Testing(EvaluationModel) Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss / acc in each epoch graph ploting\n",
    "#EPOCHS = 400\n",
    "import matplotlib.pyplot as plt\n",
    "epochs_range = range(save_model_interval,EPOCHS+save_model_interval,save_model_interval)\n",
    "print(epochs_range)\n",
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, test_indoor_acc, label='IndoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_outdoor_acc, label='OutdoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_belt_acc, label='OnConveyorBeltDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_avg_acc, label='Average Tesing Accuracy',linewidth=3)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Testing(EvaluationModel) Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max acc -> 0.9139209985733032\n",
      "max index -> 9\n",
      "The [Epoch] of max acc -> 2000\n"
     ]
    }
   ],
   "source": [
    "#Find Max Index and Value\n",
    "print(f\"max acc -> {max(test_avg_acc)}\")\n",
    "max_index = test_avg_acc.index(max(test_avg_acc))\n",
    "print(f\"max index -> {max_index}\")\n",
    "print(f\"The [Epoch] of max acc -> {(max_index+1)*save_model_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, test_indoor_loss, label='IndoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_outdoor_loss, label='OutdoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_belt_loss, label='OnConveyorBeltDS Tesing Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Testing(EvaluationModel) Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9537346959114075,\n",
       " 0.9542920589447021,\n",
       " 0.9559643268585205,\n",
       " 0.9559643268585205,\n",
       " 0.95652174949646,\n",
       " 0.9593088030815125,\n",
       " 0.9593088030815125,\n",
       " 0.9581939578056335,\n",
       " 0.9593088030815125,\n",
       " 0.9598662257194519]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9423567056655884,\n",
       " 0.9439490437507629,\n",
       " 0.9429936408996582,\n",
       " 0.9442675113677979,\n",
       " 0.9452229142189026,\n",
       " 0.9445859789848328,\n",
       " 0.9452229142189026,\n",
       " 0.9452229142189026,\n",
       " 0.9458598494529724,\n",
       " 0.9455413818359375]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.826382577419281,\n",
       " 0.8304623961448669,\n",
       " 0.8340888619422913,\n",
       " 0.8318222761154175,\n",
       " 0.8322756290435791,\n",
       " 0.8313689827919006,\n",
       " 0.8336355686187744,\n",
       " 0.832728922367096,\n",
       " 0.8336355686187744,\n",
       " 0.8363553881645203]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18506163358688354,\n",
       " 0.1804824024438858,\n",
       " 0.18556468188762665,\n",
       " 0.18672999739646912,\n",
       " 0.18883679807186127,\n",
       " 0.185163214802742,\n",
       " 0.18960638344287872,\n",
       " 0.20042164623737335,\n",
       " 0.2041599452495575,\n",
       " 0.18154418468475342]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2851848602294922,\n",
       " 0.28673475980758667,\n",
       " 0.3070204555988312,\n",
       " 0.31646254658699036,\n",
       " 0.30433741211891174,\n",
       " 0.31460148096084595,\n",
       " 0.32264992594718933,\n",
       " 0.3265926241874695,\n",
       " 0.3364255726337433,\n",
       " 0.3510190546512604]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8409690260887146,\n",
       " 0.8461312651634216,\n",
       " 0.9020317196846008,\n",
       " 0.9296244382858276,\n",
       " 0.9565193057060242,\n",
       " 0.977152943611145,\n",
       " 1.0140670537948608,\n",
       " 1.0502655506134033,\n",
       " 1.055303692817688,\n",
       " 1.038012146949768]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Last Epoch and test in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del dataset memory and reload\n",
    "# RAM\n",
    "del train_ds\n",
    "del val_ds\n",
    "del test_indoor_ds\n",
    "del test_outdoor_ds\n",
    "del test_belt_ds\n",
    "# VRAM\n",
    "#from numba import cuda\n",
    "#cuda.select_device(0)\n",
    "#cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1472527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1492644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1480576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1409943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1413321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1410839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1483502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1406563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1485759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1477504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1471292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1488769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1408879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1491368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1488333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1487726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1482397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1411279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1472720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1408339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1472782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1407767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1405169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1467847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1493811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1412796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1480514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1479300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1405369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1408614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1493142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1409459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1486366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1411544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1481183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1482942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1409668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1411727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1409892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1410167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1476290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1474323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1408166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1482164) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1475101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1486537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1407502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1481557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1406166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1490216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1492971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1480950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1411503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1476119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1473887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1413020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1472153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1409510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1476726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1413112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1479969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1478547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1410116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1489547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1407543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1478802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1409011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1471637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1490823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1483004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1410656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1471230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1475792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1477333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1405733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1405502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1493749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1412572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1481728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1409103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1493578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1407726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1463516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1408390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1475163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1413229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1405210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1475537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1479362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1472091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1489376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1411992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1493204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1473109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1410615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1473949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1474556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1409719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1489609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1476897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1406886) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1408563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1476959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1408115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1405942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1475730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1487555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1410208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1483331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1405891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1412623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1412175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1456687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1490154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1487788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1410564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1409551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1408838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1412847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1485930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1413504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1452334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1485152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1413453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1410788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1471699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1491804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1492411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1405675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1478111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1473280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1485323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1406787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1491430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1482771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1407957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1412399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1405328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1410391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1407451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1411111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1490590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1412888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1491197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1476352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1411900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1481790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1481121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1411951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1473716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1408655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1410432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1413071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1409286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1483564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1407278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1409235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1407319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1407675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1406339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1411012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1409760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1413677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1405543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1491975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1487228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1484171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1477940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1479736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1409327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1479907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1412216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1407003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1473342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1407095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1484716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1405118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1413280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1411768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1410340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1489002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1407998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1407054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1407899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1490761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1413545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1487166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1484778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1406390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1488162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1411320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1405774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1494185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1406207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1492037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1406614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1479129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1412124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1406845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1488395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1405983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1478740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1412348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1478173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1492582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1411676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1488940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1412440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1483938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1471059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1406655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1408431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1485385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1411228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1474930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1408787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1485992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1482335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1409062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1474494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1406115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1486599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1408207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1480343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1411070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1406431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1486973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1484109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1388017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1409984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1410880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1477566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1412664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1411452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1407227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1484545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1489983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1794 files belonging to 4 classes.\n",
      "Found 3140 files belonging to 4 classes.\n",
      "Found 2206 files belonging to 4 classes.\n",
      "train_indoor num x,y : 1794,1794 are predicting\n",
      "train_outdoor num x,y : 3140,3140 are predicting\n",
      "train_belt num x,y : 2206,2206 are predicting\n",
      "all num x,y :7140,7140\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "last_epoch_model = tf.keras.models.load_model(path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb')\n",
    "\n",
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/belt'\n",
    "\n",
    "img_height=456\n",
    "img_width=456\n",
    "batch_size=2\n",
    "\n",
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "  layers.RandomZoom(height_factor=0.1),\n",
    "  layers.RandomContrast(0.05),\n",
    "])\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  #ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)\n",
    "\n",
    "class_names = ['1-InfectionWaste', '2-BloodSecretionWaste', '3-LabWardWaste', '4-VaccineOtherWaste']\n",
    "\n",
    "N = 200\n",
    "\n",
    "x_test_indoor = np.concatenate([ x for x,y in test_indoor_ds],axis=0)\n",
    "y_test_indoor = np.concatenate([ y for x,y in test_indoor_ds],axis=0)\n",
    "print(f\"train_indoor num x,y : {len(x_test_indoor)},{len(y_test_indoor)} are predicting\")\n",
    "x_indoor_sets = np.array_split(x_test_indoor, N)\n",
    "del x_test_indoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_indoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_indoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_indoor_sets,test_indoor_ds\n",
    "\n",
    "x_test_outdoor = np.concatenate([ x for x,y in test_outdoor_ds],axis=0)\n",
    "y_test_outdoor = np.concatenate([ y for x,y in test_outdoor_ds],axis=0)\n",
    "print(f\"train_outdoor num x,y : {len(x_test_outdoor)},{len(y_test_outdoor)} are predicting\")\n",
    "x_outdoor_sets = np.array_split(x_test_outdoor, N)\n",
    "del x_test_outdoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_outdoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_outdoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_outdoor_sets,test_outdoor_ds\n",
    "\n",
    "x_test_belt = np.concatenate([ x for x,y in test_belt_ds],axis=0)\n",
    "y_test_belt = np.concatenate([ y for x,y in test_belt_ds],axis=0)\n",
    "print(f\"train_belt num x,y : {len(x_test_belt)},{len(y_test_belt)} are predicting\")\n",
    "x_belt_sets = np.array_split(x_test_belt, N)\n",
    "del x_test_belt\n",
    "y_all_sets_predicted = []\n",
    "for x in x_belt_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_belt_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_belt_sets,test_belt_ds\n",
    "\n",
    "y_all = np.concatenate([y_test_indoor,y_test_outdoor,y_test_belt],axis=0)\n",
    "y_all_predicted = np.concatenate([y_indoor_predicted,y_outdoor_predicted,y_belt_predicted],axis=0)\n",
    "print(f\"all num x,y :{len(y_all_predicted)},{len(y_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all=7140\n",
      "TP=6536\n",
      "FP=604\n",
      "acc=0.915406162464986\n",
      "all check = 7140\n"
     ]
    }
   ],
   "source": [
    "y_all_predicted_max = np.array([],dtype=np.int)\n",
    "# acc all\n",
    "TP = 0\n",
    "FP = 0\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP = TP + 1\n",
    "    else :\n",
    "        FP = FP + 1\n",
    "    y_all_predicted_max=np.append(y_all_predicted_max,np.argmax(y_all_predicted[i]))\n",
    "print(f'all={TP+FP}')\n",
    "print(f'TP={TP}')\n",
    "print(f'FP={FP}')\n",
    "print(f'acc={TP/(TP+FP)}')\n",
    "\n",
    "# acc eachclass\n",
    "TP_eachclass = [0] * 41\n",
    "FP_eachclass = [0] * 41\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP_eachclass[y_all[i]] = TP_eachclass[y_all[i]] + 1\n",
    "    else :\n",
    "        FP_eachclass[y_all[i]] = FP_eachclass[y_all[i]] + 1\n",
    "#recheck\n",
    "print(f'all check = {sum(TP_eachclass)+sum(FP_eachclass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-InfectionWaste acc = 87.79854620976117%\n",
      "2-BloodSecretionWaste acc = 87.492795389049%\n",
      "3-LabWardWaste acc = 94.31988041853513%\n",
      "4-VaccineOtherWaste acc = 96.45025688930406%\n",
      "\n",
      "\n",
      "\n",
      "all_avg_eachclass = 91.51536972666234%\n"
     ]
    }
   ],
   "source": [
    "avg_acc_eachclass = []\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]} acc = {TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100}%')\n",
    "    avg_acc_eachclass.append(TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100)\n",
    "all_avg_eachclass = sum(avg_acc_eachclass) / len(avg_acc_eachclass)\n",
    "print(f'\\n\\n\\nall_avg_eachclass = {all_avg_eachclass}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1691,  215,    6,   14],\n",
       "       [ 152, 1518,   24,   41],\n",
       "       [  28,   29, 1262,   19],\n",
       "       [  12,   45,   19, 2065]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# for using scikit-learn's built-in metrics\n",
    "from sklearn.metrics import *\n",
    "# for using tesnorflow/keras' built-in metrics\n",
    "import tensorflow.keras.backend as K\n",
    "''' ndarray of shape (n_classes, n_classes)\n",
    "Confusion matrix whose i-th row and j-th column entry indicates the number of samples with  {true label being i-th row class} and {predicted label being column j-th class}.\n",
    "> Example\n",
    ">>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    ">>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    ">>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    " \n",
    "       \n",
    "'''\n",
    "# \n",
    "confusionMat = confusion_matrix(y_all, y_all_predicted_max, labels=range(len(class_names)))\n",
    "confusionMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87.79854621, 11.16303219,  0.31152648,  0.72689512],\n",
       "       [ 8.76080692, 87.49279539,  1.3832853 ,  2.36311239],\n",
       "       [ 2.09267564,  2.16741405, 94.31988042,  1.4200299 ],\n",
       "       [ 0.56048575,  2.10182158,  0.88743578, 96.45025689]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatFloat = confusionMat.astype('float64')\n",
    "confusionMatFloatPercent=confusionMatFloat/confusionMatFloat.sum(axis=1)[:,None]  # divided by number of sample in each class (sum of each row)\n",
    "confusionMatFloatPercent*=100\n",
    "confusionMatFloatPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMat, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (14,14))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvEAAAMYCAYAAABCBLgfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABiP0lEQVR4nO3dd5xU9dWA8efsAoKCIKhg7xV7V4wFa2yJLdVoLDHmjV0TS+yJRk1MojGJmlgTYxLT7L2hWLH3qNilWFBQUNp5/5i7uMDuzoDMLheeL5/57Nw2c2bmMnPmzLm/G5mJJEmSpPJo6OgAJEmSJM0Yk3hJkiSpZEziJUmSpJIxiZckSZJKxiRekiRJKhmTeEmSJKlkOtX7DpZc82eOYal289Qj63Z0CJrL9OqyXEeHoLlI4keq2k+wUnR0DK3ptuQ3Z8v/DOPeuKrdnjMr8ZIkSVLJmMRLkiRJJVP3dhpJkiRpVoqwDu0zIEmSJJWMSbwkSZJUMrbTSJIkqVTCOrTPgCRJklQ2JvGSJElSydhOI0mSpFJxdBor8ZIkSVLpmMRLkiRJJWM7jSRJkkrFdhor8ZIkSVLpmMRLkiRJJWM7jSRJkkolIjo6hA5nJV6SJEkqGZN4SZIkqWRsp5EkSVLJWIf2GZAkSZJKxiRekiRJKhnbaSRJklQqnuzJSrwkSZJUOibxkiRJUsnYTiNJkqRSsZ3GSrwkSZJUOibxkiRJUsnYTiNJkqRSCevQPgOSJElS2ViJlyRJUql4YKuVeEmSJKl0TOIlSZKkkrGdRpIkSaViO42VeEmSJKl0TOIlSZKkkrGdRpIkSaViO42VeEmSJKl0TOIlSZKkkrGdRpIkSaUSREeH0OGsxEuSJEklYxIvSZIklYztNJIkSSoVR6exEi9JkiSVjkm8JEmSVDK200iSJKlUbKexEi9JkiSVjkm8JEmSVDK200iSJKlUbKexEi9JkiSVjkm8JEmSVDK200iSJKlkrEP7DEiSJEklYxIvSZIklYztNJIkSSoVR6exEi9JkiSVjkm8JEmSVDI1tdNExLzAUcCSmfm9iFgBWCkzr69rdJIkSdI0bKepvRJ/KfAZsHEx/Tbws7pEJEmSJKlNtSbxy2Xm2cAEgMwcC0TdopIkSZLUqlpHpxkfEd2ABIiI5ahU5iVJkqR2FR7WWXMSfwpwM7BERFwJDAD2rVdQkiRJklpXUxKfmbdGxKPARlTaaA7LzPfqGpkkSZKkFtU6Os0dmbkVcEML8yRJkqR24+g0VZL4iOgKzAssGBEL8PnBrPMDi9U5NkmSJEktqFaJ/z5wOLAo8CifJ/GjgfPrF5YkSZKk1rSZxGfmucC5EXFIZv62nWKSJEmSWhXhSOe1NhQNj4geABFxQkT8OyLWqWNckiRJklpRaxJ/YmaOiYhNga2Bi4E/1C8sSZIkSa2pdZz4ScXfHYGLMvOGiPhZnWKSJEmSWuXoNLVX4t+OiAuBrwM3RsQ8M7CtJEmSpFmo1kT8a8AtwHaZ+SHQG/hRvYKSJEmS1Lpaz9g6Fvh3RCwcEUsWs1+oX1iSJElSy8KGkNqegYjYJSJeAl4F7in+3lTPwCRJkiS1rNavMT8FNgL+l5nLUBmh5sG6RSVJkiSpVbWOTjMhM9+PiIaIaMjMuyLiN/UMTJIkSWqJo9PUnsR/GBHdgUHAlRExEvikfmFJkiRJak2bX2MiYoHi6leAscARwM3AK8DO9Q1NkiRJUkuqVeJfjIj3gMHA/cDgzLy8/mFJkiRJLbOdpkolPjMXBr5KJYnfmMowkyMi4pqI+HE7xCdJkiRpGlV74jPzf8D/gMsiYjlgB+AwYFvg7PqGJ0mSJGlabSbxEbEJsAmVKvwSwFAqQ0vuBTxW9+gkSZKkaXiyp+qV+PuoJOu/Bv5TnLlVkiRJUgeqlsQvSqUSvwnw/YjoRCWpfwB4IDOH1jk+SZIkSdNoM4nPzOHAv4sLETEvsB9wKrAM0FjvACVJkqSpODpN1Z74nlT64Zuq8WsDLwHXURmxRpIkSVI7q9ZO8zJF6wxwGvBIZo6re1SSJEmSWlWtnWah9gpEkiRJqoUne6phnHiAiFgROBpYuvk2mTmwPmFJkiRJak1NSTxwNXAB8CdgUv3CkSRJklRNrUn8xMz8Q10jkSRJkmoQER0dQoerNYm/LiL+D/gP8FnTzMz8oC5RzYH232sDvrnb2mQmL7z0LkefdC1XXvht5pu3CwAL9p6PJ555h+8dcfV02x5/+EAGbrYCEcF9Dw7l5LNuBWD1Vfpxzk93oes8nbjrvpenzNfc7acn/pXBg55jgd7dueo/xwJwxy1P8Mc/3MxrQ0dw6VVHsEr/JWvetsk/rhzEP/92Hw2NDQzYbFUOOXKXuj8Wlc+gQY9y+ul/ZPLkyey55zYceOCeUy2/6qqb+Otfb6ChoYF55+3KT396MMsvvySjRo3m0EPP5JlnXmLXXbfipJMO6qBHoLK5d9CjnH76n5g8eRJ77LktBx64x1TLf37Gn3jooacBGPfpZ3zw/kc8MuQq3n57JIccfAaTJycTJ05kr7124hvf/HJHPARpptSaxO9T/P1Rs3kJLDtrw5kz9V24B/t+awO22vUCPvtsIr8/ezd23r4/e+x7xZR1Ljhnd26763/Tbbvumouz3lpLsO0eFwHwr8v2YaP1luLBIa9z+glf5phTb+Dxp9/m8t99gy0GLMfdg19pt8el2dNOX9mQPb/5JU79yZVT5i27Qj/O+vW+nHnaP2Z4W4AhD7/EoLue4S//+jFdunTig/fH1CV2ldukSZM47bQLuPTSn9K3bx/22ONIBg7ckOWX//xL4847b843i0Tpjjse4uc/v5iLLz6VeebpwmGHfZuXXnqDl156vaMegkqmss9dyCWXnkbfvn3Yc4+jGDhwg6n2ueOOP2DK9T//+Xqef67yObnQQgvwt7//gi5dOvPJJ+PYeedD2HLgBvTt26fdH4c0M2o6tDczl2nhYgI/Azo1NtB1nk40NgbdunVmxLsfT1nWfb4uDNhgaW6568XptstM5pmnE507N9KlSyOdOzXw3vsfs/CC3ek+3zw8/vTbAPzruqfZbuBK7fZ4NPtae73lmL/nvFPNW2bZfiy1TN+Z2hbg338fzN77b0WXLpXv/b379Jg1wWqO8tRTL7HUUouwxBL96NKlMzvuuBl33PHQVOt07/75/jVu3Kc0/SI+77xdWW+9/swzT+f2DFkl99RTL7Fks31uhx2/NN0+19wNNwxix502A6BLl8506VLZ38aPn0BOntwuMWvWCBpmy0t7qnV0ms7AD4DNill3Axdm5oQ6xTVHGTFyDBdd/gAP3nIon346gUEPvMq9Dwydsny7LVdi8EOv8fEn46fb9rGn3ub+R15jyO2HEwGX/20IL7/6PmusugjDR3xeDR0+YjT9FjaxUn288fpInnhsKBf89ga6dOnMoUd/hVVXa7klR3OvESPep1+/BadM9+3bh6eemv4XxiuvvIFLL/0vEyZM5PLLT2/PEDWHGTHifRZpts/167sgTz41fUEM4O23R/L2WyPYaKM1pswbNuxdvn/gabzxxjB+9ON9rcKrVGr9yvAHYF3g98Vl3WKeatCzR1e22XIlBuxwPutvcy7zduvMrjuuNmX5Ll/uzzU3PdvitkstsQDLL7MgG257Lhtscy6bbLA0G6y9RHuFLgEwadJkRn80louvPIJDjtqF44++jMzs6LBUUt/+9o7cfvsfOfroffjDH/7e0eFoLnHjDfey7Xab0NjYOGXeIossxLXX/ZZbbr2Q//7nTt57b1QHRijNmFqT+PUzc5/MvLO47Aus39rKEXFgRAyJiCEfv//IrIm0xDbdaBnefPtDPhg1lokTJ3PzHS+w7pqLA7BAr26stdqi3HnvSy1uu/3AlXj86bcZO24CY8dN4O7Br7DOmoszfOQY+vX9vPLer+/8DB9pn7LqY+G+vdhi6zWICPqvvhQNEXw46pOODkuzmb59+zB8+HtTpkeMeL/NyuaOO27G7bc/2B6haQ7Vt28fhjXb54aPeK/Vfe7GGwex446btbisb98+rLDCkgwZ8lxd4tSsF9EwW17aU633NikilmuaiIhlaWO8+My8KDPXy8z1uvdpNdefa7w9/CPWWWMxunatdC8N2HAZXn618qaz4zarcMegl/lsfMtP5zvDR7PRukvR2Bh06tTARusuycuvvsfI9z7m408+Y+3VFwNg951X59YWeuqlWWHzgavz6MOVL5pvvDaSCRMm0WuB+To4Ks1uVl99BV577R3efHM448dP4IYbBjFw4AZTrfPaa+9MuX733UNYaqlF2ztMzUFWX30FXn/tHd4q9rkbb7iXgQM3nG69oa+8xUejP2HttVeeMm/48Pf49NPKgHsfffQxjz72PMsss1i7xS59UbWOTvMj4K6IGAoEsBSwb92imsM88fQ73Hjb89z4twOYNGkyz74wgr/+83EAdt6uP7+/ZPBU66+x6iJ8e891OObUG7jhtufZZIOlufWf34dM7r7/FW6/p5JMnXD6zZzz053pOk9n7hr8Mnfd58g0ghN+fDmPPfIKH374MTttdTIH/vDLzN9zXn55xr/4cNTHHPF/F7Hiyotx3oU/4N2RH3H6yX/jN3/4fqvb7rLbRuy864b87MSr+OauZ9K5cydOPv1bjtGr6XTq1MhJJx3EAQeczKRJk9l9961ZYYWlOPfcv7Daaiuw1VYb8pe/XM8DDzxBp06dmH/+7px11uFTth84cH8+/ngsEyZM5PbbH+SSS06bapQRaVqdOjVy4knfZ/8DTmHylH1uSc4790pWW215Bm5VSehvuHEQO+7wpanet1555U3OOvMSIoLMZL/9vspKKy3dQY9EmnFRa19rRMwDNA1/8mJmftbW+k2WXPNnNs6q3Tz1yLodHYLmMr26LFd9JWkWSfxIVfsJVpptqzUrbvD72fI/w/8e/r92e87arMRHxMDMvDMidptm0fLFN9d/1zE2SZIkSS2o1k6zOXAnsHMLyxIwiZckSZLaWZtJfGaeXFw9LTNfbb4sIpapW1SSJElSa9p3IJjZUq1Pwb9amPfPWRmIJEmSpNpU64lfGegP9JymL35+oGs9A5MkSZLUsmo98SsBOwG9mLovfgzwvTrFJEmSJLXOYY6r9sRfA1wTERtn5gPtFJMkSZKkNtTaE39QRPRqmoiIBSLikvqEJEmSJKkttZ6xdY3M/LBpIjNHRcTa9QlJkiRJaoPtNDVX4hsiYoGmiYjoTe1fACRJkiTNQrUm4ucAD0TE1cX0nsDp9QlJkiRJUltqSuIz84qIGAIMLGbtlpnP1S8sSZIkqRWe7GmGnoLewCeZeT7wrmdslSRJkjpGTUl8RJwMHAMcV8zqDPylXkFJkiRJal2tPfG7AmsDjwFk5jsR0aNuUUmSJEmtSEenqbmdZnxmJpAAETFf/UKSJEmS1JZak/h/RMSFQK+I+B5wO/DH+oUlSZIkqTVtttNExDyZ+Vlm/jIitgFGAysBJ2Xmbe0SoSRJktSc3TRVe+IfANaJiD9n5ncAE3dJkiSpg1VL4rtExLeATSJit2kXZua/6xOWJEmSpNZUS+IPAr4N9AJ2nmZZAibxkiRJal8N9tO0mcRn5n3AfRExJDMvbqeYJEmSJLWhpnHiM/PiiNgEWLr5Npl5RZ3ikiRJktSKmpL4iPgzsBzwBDCpmJ2ASbwkSZLalyd7qvmMresBqxYnfJIkSZLUgWo92dMzQL96BiJJkiSpNrVW4hcEnouIh4HPmmZm5i51iUqSJElqjd00NSfxp9QzCEmSJGluEBFHAAdQOb70aWBfYBHgb0Af4FHgO5k5vq3bqXV0mnu+ULSSJEnSXC4iFgMOpXKs6biI+AfwDWAH4NeZ+beIuADYH/hDW7fVZhIfEWOofEuYbhGQmTn/zDwASZIkaaaV+2RPnYBuETEBmBcYBgwEvlUsv5xKF8zMJ/GZ2eMLhylJkiSJzHw7In4JvAGMA26l0j7zYWZOLFZ7C1is2m3VOjrNFBFx4IxuI0mSJM3pIuLAiBjS7HLgNMsXAL4CLAMsCswHbD8z91Xrga3NHQRcNDN3JkmSJH1hs+nJnjLzItrOk7cGXs3MdwEi4t/AAKBXRHQqqvGLA29Xu68ZrsTjoD6SJEnSzHgD2Cgi5o2IALYCngPuAvYo1tkHuKbaDc1MEr8zQETsOxPbSpIkSXOlzHwI+CfwGJXhJRuoVO6PAY6MiJepDDN5cbXbmuF2msx8q7h6KnDpjG4vSZIkfSEl7gvJzJOBk6eZPRTYYEZup9oQk0+1tgjoOyN3JEmSJGnWqFaJ7wtsB4yaZn4A99clIkmSJEltqpbEXw90z8wnpl0QEXfXIyBJkiSpTeU+2dMsUe1kT/u3sexbrS2TJEmSVD8zM068JEmS1HEsxM/UEJOSJEmSOpBJvCRJklQyttNIkiSpVDLsp7ESL0mSJJWMSbwkSZJUMrbTSJIkqVwcJ95KvCRJklQ2JvGSJElSydhOI0mSpHKxm8ZKvCRJklQ2JvGSJElSydhOI0mSpHLxZE9W4iVJkqSyMYmXJEmSSsZ2GkmSJJWLJ3uyEi9JkiSVjUm8JEmSVDK200iSJKlc7KaxEi9JkiSVjUm8JEmSVDK200iSJKlcPNmTlXhJkiSpbEziJUmSpJKxnUaSJEnlYjuNlXhJkiSpbEziJUmSpJKxnUaSJEnlYhnap0CSJEkqG5N4SZIkqWRsp5EkSVK5ODqNlXhJkiSpbEziJUmSpJKxnUaSJEnlYjeNlXhJkiSpbEziJUmSpJKxnUaSJEmlkg3201iJlyRJkkrGJF6SJEkqGdtpJEmSVC6e7MlKvCRJklQ2JvGSJElSydhOI0mSpHKxm8ZKvCRJklQ2JvGSJElSydhOI0mSpHLxZE9W4iVJkqSyMYmXJEmSSsZ2GkmSJJWLJ3uyEi9JkiSVjUm8JEmSVDJ1b6d5bsgm9b4LaYpV17u/o0PQXOb1J5fu6BA0F5mckzo6BM1FGmfnjpXZObZ2YiVekiRJKhmTeEmSJKlkHJ1GkiRJ5eLJnqzES5IkSWVjEi9JkiSVjO00kiRJKhfbaazES5IkSWVjEi9JkiSVjO00kiRJKpW0m8ZKvCRJklQ2JvGSJElSydhOI0mSpHJxdBor8ZIkSVLZmMRLkiRJJWM7jSRJksolbKexEi9JkiSVjEm8JEmSVDK200iSJKlcHJ3GSrwkSZJUNibxkiRJUsnYTiNJkqRysQztUyBJkiSVjUm8JEmSVDK200iSJKlcPNmTlXhJkiSpbEziJUmSpJKxnUaSJEnl4smerMRLkiRJZWMSL0mSJJWM7TSSJEkqlXR0GivxkiRJUtmYxEuSJEklYzuNJEmSysUytE+BJEmSVDYm8ZIkSVLJ2E4jSZKkcvFkT1biJUmSpLIxiZckSZJKxnYaSZIklYsne6qtEh8RfSPi4oi4qZheNSL2r29okiRJklpSazvNZcAtwKLF9P+Aw+sQjyRJkqQqak3iF8zMfwCTATJzIjCpblFJkiRJrWmI2fPSnk9Bjet9EhF9gASIiI2Aj+oWlSRJkqRW1Xpg65HAtcByETEYWAjYs25RSZIkSWpVrUn8s8DmwEpAAC/i8JSSJEnqCA5OU3Mi/kBmTszMZzPzmcycADxQz8AkSZIktazNSnxE9AMWA7pFxNp8/r1nfmDeOscmSZIkqQXV2mm2A74LLA6cw+dJ/Bjg+PqFJUmSJLUs23kkmNlRm0l8Zl4OXB4Ru2fmv9opJkmSJEltqLUnfvGImD8q/hQRj0XEtnWNTJIkSVKLak3i98vM0cC2QB/gO8CZdYtKkiRJak1Hn9SpRCd7aopqB+CKzHwWB/eRJEmSOkStSfyjEXErlST+lojoAUyuX1iSJEmSWlPryZ72B9YChmbm2IjoA+xbt6gkSZKk1oQNITUl8Zk5OSJeBVaMiK51jkmSJElSG2pK4iPiAOAwKuPFPwFsROWMrQPrFpkkSZKkFtXaE38YsD7wemZuCawNfFivoCRJkqRWNcyml3ZU6919mpmfAkTEPJn5ArBS/cKSJEmS1JpaD2x9KyJ6Af8FbouIUcDr9QpKkiRJapUHtradxEfEWsCTmblrMeuUiLgL6AncXOfYJEmSJLWgWiX+T8CyEfEocD8wGHggM8fUPTJJkiRJLWozic/M9SJiXmADYBPgUODPETEcGJyZ/9cOMUqSJEmfa7CdpmpPfGaOBe6OiEeAh4ABwN7A9nWOTZIkSVILqvXEf4tKBX4t4DOgKZHfNDOH1z06SZIkSdOpVom/EHgRuAAYlJn/q39IkiRJUhtsp6maxPcC1qRSjT8lIlYChlE5W+sDmXlnfcOTJEmSNK1qB7ZOAh4rLudHRF9gT+Bw4DSgsd4BSpIkSZpatZ74NahU4ZsuXagMNflbKsNNSpIkSe0qPdlT1Xaay4D7gJuAEzLzjbpHJEmSJKlN1dpp1mmvQCRJkiTVpuo48QARMQA4BViq2CaAzMxl6xeaJEmS1IKGjg6g49WUxAMXA0cAjwKT6heOJEmSpGpqTeI/ysyb6hqJJEmSpJrUmsTfFRG/AP5N5cytAGTmY3WJSpIkSWqNo9PUnMRvWPxdr9m8BAbO2nAkSZIkVVNTEp+ZW9Y7EEmSJEm1qXV0mp7AycBmxax7gNMy86N6BSZJkiS1qMF2mloH6LkEGAN8rbiMBi6tV1CSJEmSWldrT/xymbl7s+lTI+KJOsQjSZIkqYpak/hxEbFpZt4HU07+NK5+YUmSJEmtsJ2m5iT+B8DlRW98AB8A361XUJIkSZJaV+voNE8Aa0bE/MX06HoGJUmSJKl1bSbxEbFXZv4lIo6cZj4AmfmrOsYmSZIkTc9umqqV+PmKvz1aWJazOBZJkiRJNWgzic/MC4urt2fm4ObLioNbJUmSJLWzWg9s/S2wTg3zJEmSpLpKR6ep2hO/MbAJsNA0ffHzA431DEySJElSy6pV4rsA3Yv1mvfFjwb2qFdQkiRJklpXrSf+HuCeiLgsM1+PiHkzc2w7xSZJkiRNL2ynaahxvUUj4jngBYCIWDMifl+/sCRJkiS1ptYDW38DbAdcC5CZT0bEZvUKak535RV38N9/DSYCll9hMU7+2d7MM0/nKcvPOetqhjz8PwA+/XQ8H3wwhnseqAzJP2zYB/z0pL8wYvgoIuC8PxzMoov16ZDHodnX/nttwDd3W5vM5IWX3uXok67lygu/zXzzdgFgwd7z8cQz7/C9I65ucfvu83Xhjv8cxC13vchJP78FgJ23W5WDDxhAY2MDdwx6iZ//5s52ezwqj+OP+y133z2EPn16ct315023/I7bH+Lcc/9KQ0PQ2NjI8cfvz7rrrQrAL86+jHvueZTJk5NNBqzJT35ywJTzkkgtGTbsPY475jzee/8jIuBrX9uG7+y901Tr3HHHw/z23KuIhgY6NTZy7PH7su66qwDwzjvvctIJf2D48Pcgggsv/AmLLb5wRzwUaYbVmsSTmW9O82Y6adaHM+cbOeJD/nblXVx9zUl07dqFY476I7fcNIRdvrrxlHWOOmbPKdf/duVdvPj8m1OmTz7uMvY78MtstMkqjB37KRG1/piiuUXfhXuw77c2YKtdL+Czzyby+7N3Y+ft+7PHvldMWeeCc3bntrv+1+ptHP3DLXjo0TemTPfq2Y3jj9iKHb95MR+MGsuvfroLAzZYmsEPv1bPh6IS2nW3gXx7rx049phzW1y+0cZrMHCrDYgIXnzhNQ4//BfcdPPveOyxF3jssRe45trfAPCtbx3Pww8/w4Ybrt6O0atsOjU28uNjvsuq/Zflk4/HscfuP2LjTdZk+eWXmLLORhutzsCB61f2uRdf48jDz+GGm34LwHHH/JbvH7Q7mwxYk08+GUdDg5+ppeHoNDW307wZEZsAGRGdI+Jo4Pk6xjVHmzRxMp99NoGJEyfx6bjxLLRQz1bXveXGIWy3w/oADH1lGBMnTWajTSoVhHnn7Uq3bl3aJWaVS6fGBrrO04nGxqBbt86MePfjKcu6z9eFARsszS13vdjitquv0o8F+8zHoAeGTpm35OK9eO2ND/hgVOWQmPseepUvb71yfR+ESmn99fvTs2f3VpfPN1+3KdX1seM+nXI9Aj4bP54JEyYyfvxEJk6YyIIL9mqPkFViCy28AKv2XxaA+bp3Y9nlFmfkiA+mWqf5Pjdu7GdTrr/88ptMmjSJTQasOWW9bt3macfopS+m1kr8QcC5wGLA28CtwA/rFdScbOG+vdjru1uz49Y/YZ6undlok1XYeMCqLa477J33efvt91h/w5UAeP21EfTo0Y2jD7uQd95+jw02WplDjtiVxkYrB/rciJFjuOjyB3jwlkP59NMJDHrgVe5tlpBvt+VKDH7oNT7+ZPx020bACUdtw2HH/5dNN1pmyvzX3xjFskv3YfFFezJsxGi23XJFunR2lFnNnNtue5BfnfNnPvjgIy648AQA1l57ZTbccHW+tOm+ZMK399qB5ZZbosotSZ97+62RPP/8q6yx5grTLbv9tof49a/+wvsfjOaCC44H4LXX3qFHj/k49JCzeeutkWy88eocedReNDb63qZyqJr9RUQjcG5mfjsz+2bmwpm5V2a+38Y2B0bEkIgYcsmfrp+lAZfd6I8+4Z67nuS6W37KzXeeybhx47nxuodaXPeWm4aw9bbrTEnSJ02azOOPvczhR+/GFX87lrffeo/r/vtAe4avEujZoyvbbLkSA3Y4n/W3OZd5u3Vm1x1Xm7J8ly/355qbnm1x272/vh533fcyw0eOmWr+R2M+5Sen38Tvzt6Nf166D2+98xGTJmVdH4fmXNtssxE33fw7zv/dcZx37l8BeP31YQx95S3uvudi7hl0MQ8++DRDhrS8n0rT+uSTcRx26C847rh96d593umWb73Nhtxw0285//wfc955VwGVX8UfffR5fvTjvfnH1Wfx1psj+O9/7mrv0DWzYja91BJ6RK+I+GdEvBARz0fExhHROyJui4iXir8LVLudqkl8Zk4CloqImvs2MvOizFwvM9fb74Cdqm8wF3nowRdYbLEFWaB3Dzp3bmTgVmvx5BNDW1z31puGsN2X15sy3bdvL1ZaeQkWX2IhOnVqZIuBa/HC82+0uK3mXptutAxvvv0hH4way8SJk7n5jhdYd83FAVigVzfWWm1R7rz3pRa3XWeNxdnnG+sx+MaDOeHIrdl9pzU49rAtAbj9npf4yl6XsuvelzH0tfd59fVWv8dLNVl//f68+eYIRn0wmttve5A111yR+ebrxnzzdWOzL63DE4+33PIlNTdhwkQOP/QX7LTzl9hm243aXHe99fvz1psjGDVqNP369WHllZdmiSX60alTI1ttvQHPPfdqO0Wtudy5wM2ZuTKwJpUW9WOBOzJzBeCOYrpNtbbTDAUGR8S1wCdNMzPzVzMa9dyu3yK9efqpVxk3bjxdu3bm4YdeYNX+S0233qtDhzN69FjWWGvZKfNWXW1pxowey6gPxrBA7x488vCLrNp/yfYMXyXw9vCPWGeNxejatROffjqRARsuw1PPvQPAjtuswh2DXuaz8S0fl37Y8f+dcn2PXdZgjf6LcOa5lcpUn97z8v4HY+nZoyvf+dq6/N+P/133x6I5z+uvD2PJJfsRETz77CuMHz+BXgv0YJFFF+Lqf9zKxImTyEweeeQZ9t5n544OV7O5zOTEE37Pssstznf33aXFdZrvc889O5Tx4yfSq1cP5p9/PsaM+YQPPviI3r178uCDz7Daasu18yPQ3CYiegKbAd8FyMzxwPiI+AqwRbHa5cDdwDFt3VatSfwrxaWBqc/cqhm0+hrLsNU2a/Ptr51Bp8YGVlp5CXbbc1P+cP51rNp/STbfsnKAza03DWHbL6831fBqjY0NHH707hy0/7kkySqrLsmue2zaUQ9Fs6knnn6HG297nhv/dgCTJk3m2RdG8Nd/Pg7Aztv15/eXDJ5q/TVWXYRv77kOx5x6Q5u3e8qPt2PVFStDr/3mont59fUP2lxfc6cjjzyHRx5+hlGjRrP5ZvtzyCHfYOLEypfGb3xze2695QGuueYuOnVqZJ6u8/DrXx9NRLDddhvz4INPscvOhxEBm35pHQYO3KCDH41md4899gLXXnMPK664JLt+9SgADj/iWwwb9h4A3/jGdtx264Ncc83ddOrUia7zdOGcXx9JRGWI0x/9eB/2++4pZEL//suyx55bd+TD0QyYXQcSiogDgQObzbooMy9qNr0M8C5waUSsCTwKHAb0zcxhxTrDgb5V7yuzvn2tH0+408ZZtZtV17u/o0PQXOb1J3fv6BA0F5mcju6s9tMYq8224zguff49s2V++drBm7f5nEXEesCDwIDMfCgizgVGA4dkZq9m643KzDb74mv6HlM02De/4QUi4pZatpUkSZIEwFvAW5nZNKrJP4F1gBERsQhA8XdktRuq9ceIhTLzw6aJzBwFeEozSZIktbuI2fNSTWYOp3L+pZWKWVsBzwHXAvsU8/YBrql2W7X2xE+KiCUz843KExdLAbPlzxiSJEnSbOwQ4Mpi5MehwL5UCuv/iIj9gdeBr1W7kVqT+J8A90XEPVRGwfwSUzftS5IkSaoiM58A1mth0VYzcjs1JfGZeXNErAM0DcB6eGa+NyN3JEmSJM0KtbSuzOlqPbA1gO2BdTLzemDeiHDsL0mSJKkD1Hpg6++BjYFvFtNjgN/VJSJJkiRJbaq1J37DzFwnIh6Hyug0RTO+JEmS1K7CfpqaK/ETIqKRYkSaiFgImFy3qCRJkiS1qtYk/jzgP8DCEXE6cB9wRt2ikiRJktSqWkenuTIiHuXzoW++mpnP1y8sSZIkqWV201SpxEfEvBHRGSAzXwBuB7oAq7RDbJIkSZJaUK2d5mZgaYCIWB54AFgW+GFE/Ly+oUmSJElqSbV2mgUy86Xi+j7AVZl5SDEyzaPAcXWNTpIkSZqG7TTVK/HZ7PpA4DaAzByPo9NIkiRJHaJaJf6piPgl8DawPHArQET0qnNckiRJklpRLYn/HnAYlb74bTNzbDF/VeCXdYxLkiRJalHUOkj6HKzNJD4zxwFntjD/fuD+egUlSZIkqXVtJvER8TRT98VPJTPXmOURSZIkSWpTtXaanYq/Pyz+/rn4uxdtJPeSJElSvTg6TfV2mtcBImKbzFy72aJjIuIx4Nh6BidJkiRperUeFhARMaDZxCYzsK0kSZKkWahaO02T/YFLIqInEMAoYL+6RSVJkiS1osF2mtqS+Mx8FFizSOLJzI/qGpUkSZKkVtXUEhMRPSPiV8AdwB0RcU5TQi9JkiSpfdXa134JMAb4WnEZDVxar6AkSZKk1kTMnpf2VGtP/HKZuXuz6VMj4ok6xCNJkiSpilor8eMiYtOmiWKkmnH1CUmSJElSW2qtxP8AuLzZ6DQfAPvULSpJkiSpFZ7sqfbRaZ6gMjrN/MX06HoGJUmSJKl1Mzo6zZ3AnY5OI0mSJHWcWttpLgGeoTIyDcB3qIxOs1s9gpIkSZJaE/bTODqNJEmSVDaOTiNJkiSVzBcZnea79QpKkiRJak3UWoaegzk6jSRJklQybSbxEXFkK/MByMxf1SEmSZIkSW2oVonv0S5RSJIkSTVycJoqSXxmntpegUiSJEmqTZuHBURE14jYJyJ2iYofR8T1EXFuRCzYXkFKkiRJ+ly1dporgAnAfMBRVE74dD6wKXAZsFM9g5MkSZKmZTtN9SR+1cxcLSI6AW9l5ubF/Jsj4sk6xyZJkiSpBdVG2RwPkJkTgXemWTapLhFJkiRJalO1SvziEXEelRM8NV2nmF6srpFJkiRJLbCdpnoS/6Nm14dMs2zaaUmSJEntoNoQk5dPOy8iDszMi+oXkiRJkqS2VKvEt+QgwCRekiRJHaLBdpqqB7a2xKdNkiRJ6kBVk/iIWDkitoqI7sWsnYv529c1MkmSJEktqnbG1kOBa4BDgGci4iuZ+Vax+Ix6BydJkiRNK2L2vLSnaj3x3wPWzcyPI2Jp4J8RsXRmnottNZIkSVKHqJbEN2TmxwCZ+VpEbEElkV8Kk3hJkiSpQ1TriR8REWs1TRQJ/U7AgsDqdYxLkiRJalFHt83MDu001ZL4vYHhzWdk5sTM3BvYrG5RSZIkSWpVtZM9vdXGssGzPhxJkiRJ1czMyZ4kSZKkDhOe7WmmTvYkSZIkqQOZxEuSJEklYzuNJEmSSqW9R4KZHVmJlyRJkkrGJF6SJEkqGdtpJEmSVCq201iJlyRJkkrHJF6SJEkqGdtpJEmSVCq201iJlyRJkkrHSrwkSZJKpcFKvJV4SZIkqWxM4iVJkqSSsZ1GkiRJpeKBrVbiJUmSpNIxiZckSZJKxnYaSZIklUpYhrYSL0mSJJWNSbwkSZJUMrbTSJIkqVQcncZKvCRJklQ6JvGSJElSydhOI0mSpFIJ+2msxEuSJEllYxIvSZIklYztNJIkSSoVu2msxEuSJEmlYxIvSZIklYztNJIkSSoV22msxEuSJEmlYxIvSZIklYztNJIkSSoV22msxEuSJEmlYxIvSZIklUzd22nm7dS33nchTfHaE7t2dAiay/Rc9hcdHYLmIh8N/VFHhyDNFhpsp7ESL0mSJJWNSbwkSZJUMo5OI0mSpFKxncZKvCRJklQ6JvGSJElSydhOI0mSpFJpiOzoEDqclXhJkiSpZEziJUmSpJKxnUaSJEml4ug0VuIlSZKk0jGJlyRJkkrGdhpJkiSVilVonwNJkiSpdEziJUmSpJKxnUaSJEml4smerMRLkiRJpWMSL0mSJJWM7TSSJEkqFU/2ZCVekiRJKh2TeEmSJKlkbKeRJElSqViF9jmQJEmSSsckXpIkSSoZ22kkSZJUKo5OYyVekiRJKh2TeEmSJKlkbKeRJElSqURkR4fQ4azES5IkSSVjEi9JkiSVjO00kiRJKhVHp7ESL0mSJJWOSbwkSZJUMrbTSJIkqVSsQvscSJIkSaVjEi9JkiSVjO00kiRJKpUGT/ZkJV6SJEkqG5N4SZIkqWRsp5EkSVKpeLInK/GSJElS6ZjES5IkSSVjO40kSZJKxSq0z4EkSZJUOibxkiRJUsnYTiNJkqRScXQaK/GSJElS6ZjES5IkSSVjO40kSZJKpSGyo0PocFbiJUmSpJIxiZckSZJKxnYaSZIklYqj01iJlyRJkkrHJF6SJEkqGdtpJEmSVCpWoX0OJEmSpNKpKYmPir0i4qRiesmI2KC+oUmSJElqSa3tNL8HJgMDgdOAMcC/gPXrFJckSZLUIk/2VHsSv2FmrhMRjwNk5qiI6FLHuCRJkiS1otae+AkR0QgkQEQsRKUyL0mSJKmd1VqJPw/4D7BwRJwO7AGcWLeoJEmSpFZ4sqcak/jMvDIiHgW2AgL4amY+X9fIJEmSJLWopiQ+Iv6cmd8BXmhhniRJkqR2VGs7Tf/mE0V//LqzPhxJkiSpbWVvpyly6SHA25m5U0QsA/wN6AM8CnwnM8e3dRttHtgaEcdFxBhgjYgYXVzGACOBa2bJo5AkSZLmLocBzVvTzwJ+nZnLA6OA/avdQJtJfGb+PDN7AL/IzPmLS4/M7JOZx32RyCVJkqS5TUQsDuwI/KmYDirnYvpnscrlwFer3U6t7TTXR8R8mflJROwFrAOcm5mvz2jgkiRJ0hdR6xjps6nfAD8GehTTfYAPM3NiMf0WsFi1G6n1OfgDMDYi1gSOAl4BrpiRaCVJkqQ5WUQcGBFDml0OnGb5TsDIzHz0i95XrZX4iZmZEfEV4PzMvDgiqvbqSJIkSXOLzLwIuKiNVQYAu0TEDkBXYH7gXKBXRHQqqvGLA29Xu69aK/FjIuI4YC/ghohoADrXuK0kSZI0yzREzpaXajLzuMxcPDOXBr4B3JmZ3wbuonIyVYB9qGEAmVqT+K8DnwH7Z+ZwKt8QflHjtpIkSZJadwxwZES8TKVH/uJqG9R6xtbhwK+aTb+BPfGSJEnSTMnMu4G7i+tDgQ1mZPtaz9i6EfBbYBWgC9AIfJyZPWfkziRJkqQvquwne5oVam2nOR/4JvAS0A04APh9vYKSJEmS1Lqah9nMzJeBxsyclJmXAtvXLyxJkiRJral1iMmxEdEFeCIizgaGUfpx9iVJklRGJqG1PwffKdY9GPgEWALYvV5BSZIkSWpdm5X4iHgfeAgYDNwPPJSZp7ZHYJIkSZJaVq2dZhlgI2AT4Dhg3Yh4lUpSPzgz/1Hn+CRJkqSpODpNlSQ+M0cDtxYXImI+YF/gcCqtNSbxkiRJUjur1k6zKJUq/CbA+sXsR4ETgAfqG5okSZKkllRrp3kLeAz4NXBsZo6vf0iSJElS6yKyo0PocNWS+AHAxsCuwJER8RqVCvwDwJDM/Ky+4UmSJEmaVrWe+KaE/VcAEbE0sDNwObA40LXO8UmSJEmaRtWTPUXEynzeFz8A6AU8CFxQ18gkSZKkFjg6TfUDW98D3qFSjR8EnJmZL7dHYJIkSZJaVq0Sv1xmftQukUiSJEk1aOjoAGYD1ZL4n0a0/ntFZh46a8ORJEmSVE21LzKPFpeuwDrAS8VlLaBLXSOTJEmS1KJqo9NcDhARPwA2zcyJxfQFwL31D0+SJEmaWoPjxNfcUrQAMH+z6e7FPEmSJEntrOoQk4Uzgccj4i4ggM2AU+oV1Jxs2LD3OPaY83j//Q8hgq99bRv23nunqdbJTM44/WIGDXqMrl3n4YyfH0z//ssB8MtfXsE99zwKwA9+sCc77LBpez8ElUgt+9vQoW9x/HHn89xzQzn88G+x3/5fBeDVoW9z5JHnTFnvzTdHcMih32CffXZux0egMvjBd7dmn69vRkRw+d8H8ftLb5uy7OD9t+OMn3ydpdc9lA9GfTzVdkss2ocrLziYhoagc6dGLrziDi75691069qFK373A5ZZcmEmTZrMTXc+ySln/7O9H5ZK4Pjjfsvddw+hT5+eXHf9ea2u9/RTL/GNbxzDOb86mu2334Tnnx/KKadcyCcfj6WhoYGD/DxVCdUyTnwD8CKwYXEBOCYzh9czsDlVY2MDPz5mH/r3X45PPh7H7rsfzSabrMnyyy8xZZ1Bgx7j9deHcfMtv+PJJ//HaadexN//cRZ33z2E554byn/+8yvGj5/APnufyGabrUP37vN24CPS7KyW/a1nz+785IT9ueP2h6fadpllF+M///0VAJMmTWKLzb/H1ltviNTcKisuxj5f34wtd/0Z4ydM5N+XHcnNdz7J0NdHstgiC7DVl/rzxtvvtbjt8Hc/ZOs9Tmf8+InMN+88PHjzT7nx9if4aPRYzvvjLdz74At07tzIdX/5Edtsvjq33fN0Oz86ze523W0g395rB4495txW15k0aRK//OUVDBiw1pR5XbvOw1lnHcbSSy/KiBEfsMfuR7Hppmsx//zd2yFqzQqOE19DO01mTgZ+l5nDM/Oa4mICP5MWXrj3lKr6fN27sdxyizNixPtTrXPnHQ/zla9sQUSw1lorMXr0J4wc+QGvvPIW6623Kp06NTLvvF1ZcaWluffexzviYagkatnf+vTpxeqrr0CnTo2t3s6DDzzNEkv0ZbHFFq5rvCqflZZbhCFPvsq4T8czadJkBj/0Ijtvtw4APz/hm5x45tVkK62rEyZMYvz4iQDM06UTDcWn8rhPx3Pvgy9MWefJZ15n0X52cGp666/fn5492068//LnG9h2u43p3afnlHnLLLMYSy+9KAB9+/amd++efPDB6LrGKs1qtfbE3xERu0db401qhr391kief/5V1lxzxanmjxjxAf0WWXDKdL9+fRg54gNWXmlp7rv3ccaN+4xRo0bz8EPPMHxYyxUuaVqt7W+1uPHG+9hxxy/VISqV3XP/e5tN1l+B3r3mo1vXLmy7xeosvkhvdth6LYYNH8UzL7zZ5vaLLbIA9994Ks8N/iW/ufAmho/8cKrlPXt0Y/ut1uKe+5+v46PQnGrEiPe57faH+OY3t291naee+h8TJkxkySX7tWNk0hdXa0/894EjgYkR8SmVvvjMzPlbWjkiDgQOBPjDBSdz4IF7zopY5yiffDKOQw89m2OP26/mdpgBm67F08+8zLe+eRwL9J6ftdZakYZGT3eg6mZmf2syfvwE7rzzEY44cq86Racy+98rw/j1hTfxn8uPYuy4z3jq+Tfp0qUzR//fTnx1n3Oqbv/2sFFsssPJ9Fu4F1ddeDD/vWkI775XqYg2NjZwybkHceHlt/Pam+/W+6FoDnTG6Rdz9NF709DQ8mflyJEf8OMf/YYzzzqs1XU0e7KdpsYkPjN7zMiNZuZFwEUAk/NZxwCaxoQJEzns0F+w886bse22G023vG/f3lNV2IcPf5+F+/YG4KCD9uCgg/YA4Oijfj3l50CpNdX2t2ruvfdxVl11WRZcsNesD05zhD//417+/I/KqMMnHb0b7743mp22WZvBN5wKwGL9FuDe605my6/+lJHvtdyyMHzkh1Oq+tfcVDl4/7wz9uGV10ZMdaCsNCOeeeZljjzylwB8OGoMg+55jE6dGth66434+OOxHPT9n3H4EXux1lordXCk0oyrtRJPRCwArEDlxE8AZOagegQ1J8tMTjjhdyy73GJ8d99dWlxny4Hr89crb2KHHTflySf/R48e87Lwwr2ZNGkSo0ePZYEFevDii6/x4v9e48wBnjRXratlf6vmhhvuZccdHbVBrVuwTw/ee38Miy/am122W5etdvsZf7js9inLnx50Npt/5bTpRqdZtN8CfDDqYz79bAK95p+Xjddbgd9dcisAJx65K/P36MbBx17Wng9Fc5g77rxoyvVjjz2XLbZYn6233ojx4ydw8A9/zle+sgXbb79JB0YozbyakviIOAA4DFgceALYCHgAGFi3yOZQjz32Atdecw8rrrgUu371SAAOP+LbDCsq79/4xnZsvvm6DBr0GNtt+3+VISbPOBiAiRMn8Z29fgJUDlI8++zD2zwYUaplf3v33VHsuceP+PjjcTQ0BFdccT3X33Ae3bvPy9ixn3L/4Cc59dSDOvJhaDb3l9//kN69ujNh4iSOOvkvfDRmXKvrrr360uz3rS045LjLWGn5RTj9+K+TCRFw3h9v4bkX32bRfgvwo4N35sWX3+He604G4KIr7uCKf3iOQU3tyCPP4ZGHn2HUqNFsvtn+HHLIN5g4cRIA32ijD/7mmwYzZMhzfPjhGP7znzsB+PmZh7LKKsu2S9z64sx+ILK1YQOarxTxNLA+8GBmrhURKwNnZOZu1ba1nUbSnKzXctX7vqVZ5aOhP+roEDQXCVaZbTvPf/b47bNlfnnC2lu323NW61Ecn2bmpwARMU9mvgDYQCZJkiR1gFp74t+KiF7Af4HbImIU8Hq9gpIkSZJa0xCzZSG+XbWZxEfEWsCTmblrMeuUiLgL6AncXOfYJEmSJLWgWiX+T8CyEfEocD8wGHggM8fUPTJJkiRJLWozic/M9SJiXmADYBPgUODPETEcGJyZ/9cOMUqSJElTeLKnGnriM3MscHdEPAI8BAwA9gZaH7tJkiRJUt1U64n/FpUK/FrAZ0BTIr9pZg6ve3SSJEmSplOtEn8h8CJwATAoM/9X/5AkSZKk1tlOUz2J7wWsSaUaf0pErAQMo3K21gcy8876hidJkiRpWtUObJ0EPFZczo+IvsCewOHAaXjWW0mSJKndVeuJX4NKFb7p0oXKUJO/pTLcpCRJktSuGm2nqdpOcxlwH3ATcEJmvlH3iCRJkiS1qVo7zTpN1yOiS1GZT+DFzBxf7+AkSZIkTa/qOPEAEbEDlZFqXgECWCYivp+ZN9UzOEmSJGlajk5TYxIP/ArYMjNfBoiI5YAbqLTZSJIkSWpHDTWuN6YpgS8MBcbUIR5JkiRJVVQbnWa34uqQiLgR+AeVnvg9qZy9VZIkSWpXDZEdHUKHq9ZOs3Oz6yOAzYvr7wLd6hKRJEmSpDZVG51m3/YKRJIkSVJtah2dpiuwP9Af6No0PzP3q1NckiRJUoscnab2A1v/DPQDtgPuARbHA1slSZKkDlFrEr98Zp4IfJKZlwM7AhvWLyxJkiRJral1nPgJxd8PI2I1YDiwcH1CkiRJklrX2NEBzAZqTeIviogFgBOAa4HuwIl1i0qSJElSq2pqp8nMP2XmqMwclJnLZubCwHt1jk2SJElSC2qtxLfk18C/ZlUgkiRJUi0cnab2A1tb4tMnSZIkdYAvksR7vltJkiSpA7TZThMRT9Nysh5A37pEJEmSJLWhIawlV+uJ36ldopAkSZJUszaT+Mx8fdp5EbFTZl5fv5AkSZIktWVmRqc5DTCJlyRJUododHiVmTqw1adNkiRJ6kBVk/iI2CAi1i+urwpcFRE71D0ySZIkSS2qNjrNycCXgU4RcRuwIXAXcGxErJ2Zp7dDjJIkSdIUnuypek/8HsBawDzAcGDxzBwdEb8EHgJM4iVJkqR2Vq2dZmJmTsrMscArmTkaIDPHAZPrHp0kSZKk6VSrxI+PiHmLJH7dppkR0ROTeEmSJHUA22mqJ/GbZeZnAJnZPGnvDOxTt6gkSZIktarayZ4+a2X+e8B7dYlIkiRJUptm5mRPkiRJUoexnWbmTvYkSZIkqQOZxEuSJEklYzuNJEmSSqUxsqND6HBW4iVJkqSSMYmXJEmSSsZ2GkmSJJWKVWifA0mSJKl0TOIlSZKkkrGdRpIkSaXiyZ6sxEuSJEmlYxIvSZIklYztNJIkSSoV22msxEuSJEmlYxIvSZIklYztNJIkSSqVxsiODqHDWYmXJEmSSsYkXpIkSSoZ22kkSZJUKo5OYyVekiRJKh2TeEmSJKlkbKeRJElSqdhOYyVekiRJKh2TeEmSJKlkbKeRJElSqdhOYyVekiRJKh2TeEmSJKlkbKeRJElSqTTaTmMlXpIkSSobk3hJkiSpZGynkSRJUqk0RHZ0CB3OSrwkSZJUMibxkiRJUsnYTiNJkqRSsQrtcyBJkiSVjkm8JEmSVDK200iSJKlUGjzZk5V4SZIkqWxM4iVJkqSSsZ1GkiRJpdJoO42VeEmSJKlsTOIlSZKkkrGdRpIkSaXSENnRIXQ4K/GSJElSyZjES5IkSSVjO40kSZJKxZM9WYmXJEmSSsckXpIkSSoZ22kkSZJUKrbTWImXJEmSSsckXpIkSSqZurfTNETnet+FNMXknNDRIWgu89HQYzo6BM1F5l3ylI4OQXORcW9c1dEhtMoqtM+BJEmSVDom8ZIkSVLJODqNJEmSSiUcncZKvCRJklQ2VuIlSZJUKhbircRLkiRJpWMSL0mSJJWM7TSSJEkqFQ9stRIvSZIklY5JvCRJklQyttNIkiSpVKxC+xxIkiRJpWMSL0mSJJWM7TSSJEkqlYjs6BA6nJV4SZIkqWRM4iVJkqSSsZ1GkiRJpeK5nqzES5IkSaVjEi9JkiSVjO00kiRJKpWwn8ZKvCRJklQ2JvGSJElSydhOI0mSpFKxm8ZKvCRJklQ6JvGSJElSydhOI0mSpFJpsJ/GSrwkSZJUNibxkiRJUsnYTiNJkqRSsZvGSrwkSZLULiJiiYi4KyKei4hnI+KwYn7viLgtIl4q/i5Q7bZM4iVJkqT2MRE4KjNXBTYCfhgRqwLHAndk5grAHcV0m2ynkSRJUqlESftpMnMYMKy4PiYingcWA74CbFGsdjlwN3BMW7dlJV6SJElqZxGxNLA28BDQt0jwAYYDfattbxIvSZIkzQIRcWBEDGl2ObCV9boD/wIOz8zRzZdlZgJZ7b5sp5EkSVKpzK7dNJl5EXBRW+tERGcqCfyVmfnvYvaIiFgkM4dFxCLAyGr3ZSVekiRJagcREcDFwPOZ+atmi64F9imu7wNcU+22rMRLkiRJ7WMA8B3g6Yh4oph3PHAm8I+I2B94HfhatRsyiZckSVKpzK7tNNVk5n20Hv5WM3JbttNIkiRJJWMSL0mSJJWM7TSSJEkqlYay9tPMQlbiJUmSpJKpOYmPiG4RsVI9g5EkSZJUXU1JfETsDDwB3FxMrxUR19YxLkmSJKlFMZte2lOtlfhTgA2ADwEy8wlgmbpEJEmSJKlNtSbxEzLzo2nm5awORpIkSVJ1tY5O82xEfAtojIgVgEOB++sXliRJktSyCGvJtVbiDwH6A58BfwU+Ag6rV1CSJEmSWldrJX7HzPwJ8JOmGRGxJ3B1XaKSJEmS1KpaK/HH1ThPkiRJqquOHoVmdhidps1KfER8GdgBWCwizmu2aH5gYj0DkyRJktSyau007wBDgF2AR5vNHwMcUa+gJEmSJLWuzSQ+M58EnoyIv2bmBICIWABYIjNHtUeAkiRJUnPR3r0rs6Fae+Jvi4j5I6I38Bjwx4j4dR3jkiRJktSKWpP4npk5GtgNuCIzNwS2ql9YkiRJklpT6xCTnSJiEeBrNBtmUpIkSWpvtVah52S1PgenAbcAL2fmIxGxLPBS/cKSJEmS1JqaKvGZeTXNTuyUmUOB3esVlCRJkqTW1ZTER0RXYH+gP9C1aX5m7lenuCRJkqQWOTpN7e00fwb6AdsB9wCLUxkrXpIkSVI7qzWJXz4zTwQ+yczLgR2BDesXliRJkqTW1Do6zYTi74cRsRowHFi4PiFJkiRJrbObpvYk/qLiTK0nAtcC3YvrkiRJktpZm0l8RPwGuB+4KTNHUemHX7Yd4pIkSZLUimqV+JeBrwJnR+Uw4PuLy2DgycycXNfoJEmSpGk4Ok2VJD4zzwfOB4iIRYFNissRwELA/PUOUJIkSdLUqvbER6UEvzqV5H0AsCqVs7VeUd/QJEmSJLWkWk/8bVSq7U8ADwJnZObz7RCXJEmS1CK7aaqPEz8UmAysUFyWj4gF6x6VJEmSpFZV64n/PkBEzA9sRKWl5ocRsRDwTGbuU/8QJUmSJDVX6zjxnwFjgXHF9cWBLvUKSpIkSWpNg/00bbfTRMSvI+IhYBhwKtADuABYKTNXb4f4JEmSJE2jWiX+VeCvwIjMfKMd4pEkSZJURbWe+PMAIuJpKsNMSpIkSR3Kbprqo9M0eSwi1q9rJJIkSZJqUuuBrRsC346I14FPqHwBysxco26RSZIkSWpRrUn8dnWNQpIkSapRRHZ0CB2upnaazHwdWAIYWFwfW+u2kiRJkmatmhLxiDgZOAY4rpjVGfhLvYKSJEmS1Lpa22l2BdYGHgPIzHciokfdopIkSZJa4eg0tbfEjM/MBBIgIuarX0iSJEmS2lJrEv+PiLgQ6BUR3wNuB/5Yv7AkSZIktaamdprM/GVEbAOMBlYCTsrM2+oamSRJktSCsJ+m5p54iqTdxF2SJEnqYLWOTrNbRLwUER9FxOiIGBMRo+sdnCRJkqTp1VqJPxvYOTOfr2cwkiRJUjV209R+YOsIE3hJkiRp9tBmJT4idiuuDomIvwP/BT5rWp6Z/65faJIkSZJaUq2dZudm18cC2zabTsAkXpIkSe2q1laSOVmbSXxm7gsQEQMyc3DzZRExoJ6BzckGDXqU00//I5MnT2bPPbfhwAP3nGr5v/99O2effSl9+/YBYK+9dmTPPbcD4J13RnLCCb9l2LD3iAguuuhkFl+8b7s/BpXDsGHvcewx5/H++x9CBF/72jbsvfdOU60zdOhbHH/c+Tz33FAOP/xb7Lf/V6csu/fexzjj9EuYPHkye+yxNd87cDekttw76FFOP/1PTJ48iT323JYDD9xjquXvvPMuxx7zG8aM+ZhJkyZz1NH7sPnm6zF+/AROPvn3PPPMyzREcPxPvseGG67eQY9Cs7Mf7rc9+35zIBHBpVfdyfkX3wTAD767Hd/fexsmTU5uvvNxfnLGX1vcvqEhGHz9Gbwz4gN23/cXAFx0zkF8acNV+GjMWAAOPOoCnnru9fZ5QNJMqvXA1t8C69QwT1VMmjSJ0067gEsv/Sl9+/Zhjz2OZODADVl++SWnWm+HHb7ESScdNN32xxzzaw466GsMGLA2n3wyjoYGD+1Q6xobG/jxMfvQv/9yfPLxOHbf/Wg22WRNll9+iSnr9OzZnZ+csD933P7wVNtOmjSJn572Ry6+5GT69u3D1/b8MVsOXH+qbaXmKu9vF3LJpafRt28f9tzjKAYO3GCq97c//OHvfPnLA/jmt3bg5Zff4MADT+POO//E1VffCsB11/2W99//kO9971T++c9zaGiw3qbPrbri4uz7zYF8aecTGD9hItf++VhuvP0xFl+0Dzttuy4bbH8s48dPZKE+87d6Gwfv92VefPltevToNtX848+4kv/c+HArW0mznzbfHSNi44g4ClgoIo5sdjkFaGyXCOcwTz31EksttQhLLNGPLl06s+OOm3HHHQ/VtO3LL7/BxImTGDBgbQDmm68b3bp1rWe4KrmFF+5N//7LATBf924st9zijBjx/lTr9OnTi9VXX4FOnab+L/3UUy+z5JKf76s77LApd97hB5xa99RTL7Fks/e3HXb80nTvbxHBxx+PA2DMmLEsvHBvAF55+U022nANoLJPzt9jPp555uX2fQCa7a28wmI88vjLjPt0PJMmTebeB5/nq1/egAO/sw2//P21jB8/EYB33295FOzF+vVm+63W5tK/3dWeYasOImbPS3uqVuLoAnSnUrHv0ewyGtijje3UihEj3qdfvwWnTPft22e6pArg1lvvZ+edD+HQQ3/OsGHvAvDaa28z//zzcfDBZ/DVrx7GWWddwqRJk9otdpXb22+N5PnnX2XNNVesaf2RI96n3yJ9pkz37deHESM+qFd4mgOMGPE+izR7f+vXd8Hp3t8OPvibXHvd3Wy+2b58/8BTOeGEAwFYaeWlufPOh5g4cRJvvTmcZ599hWHD3mvP8FUCz774JgM2WJnevbrTrWsXtt9yLRZfpA/LL9OPARuszKBrfsqt/ziJdddYtsXtf3HK3vzkjL8yefLk6Zad8qOv8/AtZ3H2Sd+hS5eaz4UpdZhqPfH3APdExKXAB8W8j9sjsLnZlltuwE47bU6XLp35299u4phjfsMVV5zOxImTGTLkOf7733NZZJGFOOKIs/j3v+9gzz23rX6jmqt98sk4Dj30bI49bj+6d5+3o8PRXOyGGwax664D2W+/XXn88Rc45se/5rrrf8vuu2/D0FfeYo/dj2TRRRdi7bVXprHRVhpN7cWX3+GcP1zLdVcex9ixn/Hkc68zafJkOnVqpHfP7mz2lRNZb83l+MvvD2OVTQ+batsvb7U2I98bzeNPv8qXNlplqmUnnfU3ho/8kC5dOvG7M7/HUT/YhZ+f69gdmr1VfYeMiB8A9wGvA69HxOsR8X9VtjkwIoZExJCLLvr7LAp1ztC3bx+GD/+8ujRixPtTDmBtssAC89OlS2cA9txzW559tvKTcr9+fVhllWVYYol+dOrUyFZbbcRzz73SfsGrlCZMmMhhh/6CnXfejG233ajm7Rbu24fhwz6voo4Y/j59+/auR4iaQ/Tt24dhzd7fho94b7r3t3/98za+/OVNAVh77ZX57LPxjBo1mk6dGjnu+AP47zXn8vs/nMDoMZ+w9NKLtmv8KofL/343A3b8CdvseRoffvQJLw0dxtvDPuC/N1fa/YY8+QqTM1mwd4+pttt4vZXYaZt1eGHweVxx/qFssUl/LvnNDwEYPvJDAMaPn8gV/7ib9dZarl0fk2ZGzKaX9lOtJ/4EKsNMbpGZfTKzD7Al8OViWYsy86LMXC8z1zvwwK/P2ohLbvXVV+C1197hzTeHM378BG64YRADB24w1TojR37esnDnnQ+z3HJLTNl29OhP+OCDjwB46KGnpjsgVmouMznhhN+x7HKL8d19d5mhbVdffXlef30Yb701gvHjJ3Djjfex5cD16xSp5gSrr74Cr7/2Dm8V72833nAvAwduONU6iyyyEA888BQAr7zyJp99NoHevXsybtxnjB37KQCDBz9Op8YG39/UoqaDVpdYtA9f2X59/n7NYK67dQibb7wqAMsv048unTvx3gdjptrupLP+xvIbHszKAw5l74PP4+77n2W/w38HQL+Fe01Zb5ft1ue5F99snwcjfQHVmr6+A6yZmZ82zcjMoRHxNeBJ4Gf1DG5O1KlTIyeddBAHHHAykyZNZvfdt2aFFZbi3HP/wmqrrcBWW23In/98HXfe+RCNjY307NmDn/+88pNgY2MjxxyzH/vscwKQ9O+/nK00atNjj73Atdfcw4orLsWuXz0SgMOP+PaUXuNvfGM73n13FHvu8SM+/rgy2tEVV1zP9TecR/fu83LCiQdwwP6nMXnyZHbbfStWWMGkSq3r1KmRE0/6PvsfcAqTp7y/Lcl5517Jaqstz8CtNuSYY/fjxBPO5/LLriEi+PmZhxERvP/+hxyw/yk0NAR9+/bhrLOP7OiHo9nUVRceQe8FujNhwiQOP/FSPho9lsv/fhcX/uIghtx2NuPHT+SAI/8AwCJ9F+D3Z32PXb97dpu3eem5B7Ngnx5EBE89+zqHHP+n9ngo0hcSmdn6wogXMnPlGV02tf+1fgfSLDY5J3R0CJrLRHgAnNrPvEue0tEhaC4y7o2rZttxrEd9dv1smV8uMM9O7facVeuJfzsitpp2ZkQMBIbVJyRJkiRJbalWQjoUuCYi7gMeLeatBwwAvlLPwCRJkiS1rNoQk89GxGrAt4D+xexBwPeb98lLkiRJ7SXCIWirNnMWyfolEbEUsEJm3h4R3SKiR2aOqba9JEmSpFmrpq8xEfE94J/AhcWsxYH/1ikmSZIkSW2o9beIH1Lpgx8NkJkvAQvXKyhJkiSpdR19UqfZ/GRPzXyWmeObJqIyptpsObSPJEmSNKerNYm/JyKOB7pFxDbA1cB19QtLkiRJUmtqPUvJscD+wNPA94EbAU9nJkmSpHYX7dy6MjuqKYnPzMnAH4uLJEmSpA5UUxIfEQOAU4Clim0CyMxctn6hSZIkSWpJre00FwNHUDlr66T6hSNJkiRVYztNrUn8R5l5U10jkSRJklSTWpP4uyLiF8C/gc+aZmbmY3WJSpIkSVKrak3iNyz+rtdsXgIDZ204kiRJUtsiah0lfc5V6+g0W9Y7EEmSJEm1aTOJj4i9MvMvEXFkS8sz81f1CUuSJElqjQe2VqvEz1f87VHvQCRJkiTVps0kPjMvLP6e2j7hSJIkSaqmpqMCIuLyiOjVbHqBiLikblFJkiRJrYjZ9F97qvXQ3jUy88OmicwcBaxdl4gkSZIktanWJL4hIhZomoiI3tQ+PKUkSZKkWajWRPwc4IGIuLqY3hM4vT4hSZIkSa1r79aV2VGt48RfERFD+PzkTrtl5nP1C0uSJElSa2pK4iNiI+DZzDy/mJ4/IjbMzIfqGp0kSZKk6dTaE/8H4ONm0x8X8yRJkqR21jCbXtpPrfcWmZlNE5k5GQ9slSRJkjpErUn80Ig4NCI6F5fDgKH1DEySJElSy2pN4g8CNgHeBt4CNgQOrFdQkiRJUmsiYra8tKdaR6cZCXyjzrFIkiRJqkGto9N0BfYH+gNdm+Zn5n51ikuSJElSK2ptp/kz0A/YDrgHWBwYU6+gJEmSpNbFbHppP7Um8ctn5onAJ5l5ObAjlb54SZIkSe2s1iR+QvH3w4hYDegJLFyfkCRJkiS1pdax3i+KiAWAE4Frge7FdUmSJKldRTu3rsyO2kziI+I54K/AVZk5iko//LLtEZgkSZKkllVrp/kmMB9wa0Q8HBFHRMQi7RCXJEmSpFa0WYnPzCeBJ4HjImIj4OvAQxHxCvDXzPxjO8QoSZIkNVPrYZ1zrpqfgcx8MDOPAPYGegHn1ysoSZIkSa2r9WRP61NprdkdeBW4ELi6jnFJkiRJakW1A1vPoNJC8wHwN2BAZr7VHoFJkiRJLXF0muqV+E+B7TPzpaYZEbFTZl5f37AkSZIktabNnvjMPK15Al84rY7xSJIkSaqi1pM9NefvF5IkSeowEaajMzM+zzuzPApJkiRJNat2YOu1084CNm+an5m71CswSZIkSS2r1k6zOPAc8CcgqSTx6wHn1DkuSZIkqRW201Rrp1kPeBT4CfBRZt4NjMvMezLznnoHJ0mSJGl6bVbiM3My8OuIuLr4O6LaNpIkSZLqq6aEvDjB054RsSMwur4hSZIkSa2LmRqbZc4yQ1X1zLwBuKFOsUiSJEmqgV9jJEmSpJKxv12SJEkl4+g0VuIlSZKkkjGJlyRJkkrGdhpJkiSVSoTtNFbiJUmSpJIxiZckSZJKxnYaSZIklYztNFbiJUmSpJIxiZckSZJKxnYaSZIklUpYh/YZkCRJksrGJF6SJEkqGdtpJEmSVDKOTmMlXpIkSSoZk3hJkiSpZGynkSRJUqmE7TRW4iVJkqSyMYmXJEmSSsZ2GkmSJJVKhO00VuIlSZKkkjGJlyRJkkrGdhpJkiSVjHVonwFJkiSpZEziJUmSpJKxnUaSJEml4smerMRLkiRJpWMSL0mSJJWM7TSSJEkqGdtprMRLkiRJJWMSL0mSJJWM7TSSJEkqlQjbaazES5IkSSVjEi9JkiSVjO00kiRJKhnr0D4DkiRJUsmYxEuSJEklYzuNJEmSSiU82ZOVeEmSJKlsTOIlSZKkkonM7OgY1IKIODAzL+roODT3cJ9Te3J/U3tyf9OcyEr87OvAjg5Acx33ObUn9ze1J/c3zXFM4iVJkqSSMYmXJEmSSsYkfvZl757am/uc2pP7m9qT+5vmOB7YKkmSJJWMlXhJkiSpZObKJD4iLomIkRHxTBvrfFzD7XwpIp6NiCciotsMxvDViFi12fRpEbH1jNxGsV1ExHsRsUAxvUhEZERs2myddyOizwze7uERMe+MxjOnioglIuKuiHiueM0Pa2Gd7xbP9RPFOv9seg4j4pSIOHoWxLF0034bEfNGxJUR8XREPBMR90VE9y96H23c9xYRsUmz6YMiYu+ZvK3HI2Kt4nqniPg4IvZqtvzRiFhnBm/zuxGx6MzEMyeJiK4R8XBEPFnsh6e2sM6U/ajG27wsIvZoYf4sfx2bbfvdiDg/InpFxPsREcX8jYv3uMWL6Z4R8UFEzNDnWUQcPzNxzU0iorF4ja+fZv7JEfHzaeatFRHPz6L7nen3lmL7/hFxZ0S8GBEvRcSJzfafad/HWty3Z+C+DouI3zSbvjAibm82fUhEnDeDt7lWROwwszFp7jFXJvHAZcD2s+B2vg38PDPXysxxM7jtV4EpSXxmnpSZt7e+esuy0g/1ILBxMWsT4PHiLxGxEvB+Zr4/gzd9OGAS/7mJwFGZuSqwEfDD5l/Cmvl7sT/0B8YDX69jTIcBIzJz9cxcDdgfmPBFbjAiOrWxeAuK/QogMy/IzCtm8q4GN7utNYH/8fk+Ox+wHPDkDN7md4G5PokHPgMGZuaawFrA9hGxUZ3ua5a9jhHR2NL8zPwQGAasUsya6j2Oyv/HhzNz8gzGbhJf3WFAS4n5VUz/3vaNYv4X9kXeW4qC2rXAmZm5EpX9chPg/4pVtqDZ+9gXUXwxeGCa21sT6Nlsf94EuH8Gb3otwCReVc2VSXxmDgI+qGXd4lv73UVV9YWi8hkRcQDwNeCnEXFlse6PIuKRiHiqefUrIvYu5j0ZEX8uqgC7AL8oqrbLNa8GRMRWRfXj6aj8ajBPMf+1iDg1Ih4rlq1c3MX9fP4msgnwa6ZO6gdHRPeIuKPZtl8pbnO+iLihiO2ZiPh6RBxKJRm6KyLuKtbbNiIeKLa/OupY8Z0dZeawzHysuD6GygfbYq2tXyTD8wGjWli2VkQ8WOwT/4nPf0Vpbf66xevzJPDDZje1CPB2sxhfzMzPim32iko19omiMtRYzN++eA2fjIg7inmnFPvlYODPEbFQRPyr2JcfiYgBEbE0cBBwRHGbX4pmvy60EfvdEXFWEcv/IuJLRbjT7rMXUPngAtgAeDQzJ0XEf6NSzX02Ig4sbrOx+P/yTLEvH1H831kPuLKIr1vxvN1TbH9LRCzS5os8h8iKpl8SOxeXmg5+iojvFa/5k8U+0PyL/NYRMaR4HXcq5s3061jc38cRcU6xb28cEfsWt/8wMKDZfbf0Htd8enBUfl24t9i/HyveZ5t+nRxU7BfPFPvumUC3Yl7T+3eL/2fmVlH5pWNH4E/TLsvM/wGjImLDZrO/BlzV2j4UEX2L94Yni0vT6zPV52Mxr/l7S4vvIcX7wC/i88/c7xdxfAsYnJm3FrGOBQ4Gjm3pfazYZrOIuD8ihkazqny08Jle7GcvRsQVwDPACGDF4j2nJzAOeAJYvbiZpv2ztedlz2K/fLLYT7sApwFfL2L8elQ+py8pnoPHo/j8lsjMufICLA0808byj4u/WwAfAYtT+dLzALBpsewyYI/i+rZUjn6PYr3rgc2A/lSqUwsW6/Wedtvm00BX4E1gxWL+FcDhxfXXgEOK6/8H/Km4vjlwZ3H9XqA7MKSY/iOVCm0nYP5i3oLAy0WsuwN/bBZHz2b3tWCz9QcB8xXTxwAndfRr2MH7zhtNz2ez+d8F3qXyBj6ieC0ai2WnAEcX158CNi+unwb8pob5mxXXf9G031JJlkYW++TPgBWK+asA1wGdi+nfA3sDCxX71jLT7IunAI8C3Yrpv/L5Pr4k8Py0j2EGHtPdwDnF9R2A24vrSwFDi+tXASsDdwE9gJ8AP50mxm5UPjD7AOsCtzWLo1ez+1qvuN6ZSuK3UDH9deCSjt532nEfbSz2w4+Bs1rZh6d7/wP6NLv+Mz5/v7kMuJnKe9sKwFtU3qtm+nUsphP4WnF9ESr/rxYCulCp8p9fLNun6fWjUoXvCtxXTN8GbEXll8OuxbwV+Pw98CjgJ82elx7F9Y+bPdYW/8909OvYwfvQP4v/a1sA17ew/Gjg18X1jZo9363tQ3/n88+yRqAnrX8+nsLn7y130/J7yIHACcX1eYAhwDLAr4DDWoh3FDA/07+PXQZcXezbqwIvF/Nb+0xfGpgMbNTsNu4qlm0HnEnlM/f/qBR63qjyvDwNLFZc71X8/W7Tvl9MnwHs1bRO8ZzN19H7iJeOv8yVlfiZ8HBmvpWVn2ufoPKfeFrbFpfHgceofJitAAwErs7M9wAys9ovACsBr2al0gFwOZU3hyb/Lv4+2iyOR4C1o/LzdeesVOGGRsTyFFUAKm9EZ0TEU8DtVN5c+lJ5A9mmqHR8KTM/aiGmjai8uQ2OiCeofKAuVeVxzJGi8gvEv6h8GI1uYZW/Z+ZaQD8qz+2Pptm+J5U36nuKWZdTqQK1Nr9XMX9QMf/PTbeVmU8Ay1JJ7HsDj0TEKlQSmnWL6SeK6WWpvI6DMvPVYvvm++K1+XlL2NbA+cW21wLzRxu/vLQWe7NVpttnM/N1oEtE9KPyf+VFKvvxhny+zwIcWlRpHwSWoPJ/aiiwbET8NiK2B1p6HVYCVgNuKx7HCVS+iM8VMnNSsR8uDmwQEavVuOlqRTX7aSrtgv2bLftHZk7OzJeovAYrf8HXEWASlf9PFNvcnZnvZuZ4Kklfk/uBTSJiGeC1zPyUSjdDdyr7+kNUvrj9sYj9aj5vV3wE2DciTgFWz8ovadNq7f/MXCkqv7SMzMxH21jt78AeUTkWoXkrTWv70EDgDzBl//yI2j8fW/rc2xbYu3i9HqLyBX+F6baszX+Lffs5Kp+LTbff0mc6wOuZ+WCz7Zt+KdqESlHlgWbTTa00rT0vg4HLIuJ7VL7ctGRbKr8kPEHlS01XKgUWzeXa6n+da0TEElSqMAAXZOYF06zyWbPrk2j5eQsq/fEXTnPbh8yyQKeOZUocmTk2Il4C9qPyZgOVD8sdgIWpfLDuQ6XCtW5mToiI16hUrf4XlQPPdgB+FhF3ZOZpLTy22zLzm7P4sZRKRHSmknBcmZn/nna/AT5tWjczMyKuAw6hUpmpi+IL27+Bf0fEZCqv43jg8sw8bpr4d27jpj5pdr2BSpXp0+YrROW4sJkx3T5buB/YExhWPF8PUmmh2AB4ICK2oPKFYuNiH7+byj47KiLWpFL1OojKz/j7TXOfATybmRszF8vMD6PSErdjRPylmH0SlV9OWnIZ8NXMfDIivkulCjvl5qa9+eLvTL2OxbafZuakGh7HS8UX2p2pJEhQSej2pZLUf1wk6SOo9CQ3UPx/zMxBEbEZldaQyyLiVzl9v3XQwv+ZudgAYJeoHFzZlcoX+Zuo/FoClV9ir42IV6n8Erw7n7dwXkbr+9DMauk9JKhUs29pvmJELMnURQQiYlkqv7yMbuV9rPlnfDT729Jn+tJM/X4JlUT8ICrP1e+o/CK7avG3KYm/jBael8w8KCptSTsCj0bEui3EF8DumfliS8Fr7mUlHsjMN7NyMOJaLSTwtboF2K+pYhkRi0XEwsCdwJ5RjA4TEb2L9cdQ+cl5Wi8CSxdVdIDvAPe0sN607qdyMGrTB9wDVA5KejAzk8pPlyOLBH5Likp6VEbzGJuZf6FS0W0aSaJ5fA8CA5piKvrzVqwhpjlGVN75L6bSWvIrqGm/2RR4pfmMovo0qlkv5neAe9qY/yHwYXw+2tC3m8U0ID7vPe9C5UPjdeAOKhWyhYtlvSNiKSqv42ZFNbP5vjitW6l8+Wi6n7WKqy3us63F3sptN9fSPrs3MLy4zZ7AqCLxW5nKLwlExIJAQ2b+i0qFvaV99kVgoYjYuNimc0Q0ryrPsaJyTEOv4no3YBsqX2ia9tVr29i8BzCs+ML67WmW7RkRDRGxHJUqdVNCMVOvYwseAjaPiD7F/e85zfIHqbynNb+fw/m82t+TyheJyVT2wabjQJaicgD4H6n0dzftLxOK+4HW/8/MlTLzuMxcPDOXplJlvzMzv9zCPnQVleMThmbmW8W81vahO4AfwJR+9p60/vlYi1uAHzS9hhGxYlR+jb4S2DSK0d6K/wPnAWcX27X22dvS7bf0md6SB6js1wtl5sjiM/dd4Ct8vn+2+LxExHKZ+VBmnlRss0QLMd4CHFJ8DhERa9cQv+YCc2USHxFXUflPt1JEvBUR+3/R28zKQTR/pVJ5eppKP2GPzHwWOB24p/g5+VfFJn8DfhSVg1SWa3Y7n1KpLl1d3M5kKlXeagZT+WBt+oB7jMpP6U1VgCuB9Yrb3Bt4oZi/OvBw8TPdyVR69aDSC3hzRNyVme9S6dG7KirtOA9Q+WlxbjKASmIwMCoHGz0RLQ8B1nQw0lPA2sBPW1hnHyoHNT9Fpa/9tCrz9wV+V7xGzctIy1HZr56m8pPvEOBfxU/CJwC3Frd1G7BI8ToeSKVq/yRTtys0dyiVfeWpiHiOSoUJKr867BpTHxBW7TG1Zap9NjOHUUm8mvbZm4FOURm27kwqSRxUWsHuLp6PvwBN1dPLgAuK+Y1UjjE5q3isTzCLRqQogUWoHJT+FJVWktsy8/oW1mt6/2u67AmcSCWZHszn7xFN3gAeBm4CDmr2S83Mvo5TKbY7pbidwUw/KspgKgnOkGL6geJ+m+7n98A+xeu9Mp9XS7cAnoyIx6kcG3FuMf8i4KmIuLK1/zMtxampXE2lLaT5qDSt7UOHAVsW71ePAqu28flYiz8BzwGPRWW41AuBTkVb4FeAEyLiRSptjY8A5xfbtfU+NkVrn+mtrDuKSgL+bLPZD1D5JbxpdKbWnpdfRDFMMJV9+UkqPfarFjF+ncrnSGcq++uztPy5ormQZ2yVJEmSSmaurMRLkiRJZWYSL0mSJJWMSbwkSZJUMibxkiRJUsmYxEuSJEklYxIvSZIklYxJvCRJklQyJvGSJElSyfw/08eehmpSkQUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1008x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMatFloatPercent, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (14,14))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\".2f\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
