{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteCropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset_path='D:/DatasetMedicalWasteCroppedBalanced/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/belt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=600\n",
    "img_width=600\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 files belonging to 4 classes.\n",
      "Using 3095 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-InfectionWaste', '2-BloodSecretionWaste', '3-LabWardWaste', '4-VaccineOtherWaste']\n",
      "number of class = 4\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_number = len(class_names)\n",
    "print(class_names)\n",
    "print(f'number of class = {class_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 files belonging to 4 classes.\n",
      "Using 773 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1794 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3140 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2206 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"vertical\"),\n",
    "  layers.RandomRotation(0.100),\n",
    "  layers.RandomZoom(height_factor=0.025,width_factor=0.025),\n",
    "  #layers.RandomContrast(0.300),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  # ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 600, 600, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# Test -> Fetching Mini Batch\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:-1]: # this is where I changed your code\n",
    "    model.add(layer)    \n",
    "\n",
    "# Freeze the layers \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add 'softmax' instead of earlier 'prediction' layer.\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input,EfficientNetB7\n",
    "\n",
    "efficientnetB0_model = keras.applications.EfficientNetB7(input_shape=(img_height,img_width,3),include_top=True,weights=\"imagenet\",classifier_activation=\"softmax\")\n",
    "\n",
    "efficientnetB0_model_nooutput = efficientnetB0_model.layers[-3].output\n",
    "custom_efficientnetB0_model = Model(inputs = efficientnetB0_model.input, outputs = efficientnetB0_model_nooutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freez Extractor+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 600, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 600, 600, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 600, 600, 3)  7           rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 601, 601, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 300, 300, 64) 1728        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 300, 300, 64) 256         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 300, 300, 64) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 300, 300, 64) 576         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 300, 300, 64) 256         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 300, 300, 64) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 64)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 64)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 16)     1040        block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 64)     1088        block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 300, 300, 64) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 300, 300, 32) 2048        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 300, 300, 32) 128         block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 300, 300, 32) 128         block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 300, 300, 32) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 300, 300, 32) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 300, 300, 32) 128         block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 300, 300, 32) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 300, 300, 32) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 300, 300, 32) 128         block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 300, 300, 32) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 32)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 300, 300, 32) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 300, 300, 32) 128         block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (Dropout)          (None, 300, 300, 32) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 300, 300, 32) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_bn (BatchNormalization) (None, 300, 300, 32) 128         block1d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1d_activation (Activation) (None, 300, 300, 32) 0           block1d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_squeeze (GlobalAvera (None, 32)           0           block1d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_excite (Multiply)    (None, 300, 300, 32) 0           block1d_activation[0][0]         \n",
      "                                                                 block1d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_bn (BatchNormal (None, 300, 300, 32) 128         block1d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1d_drop (Dropout)          (None, 300, 300, 32) 0           block1d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_add (Add)               (None, 300, 300, 32) 0           block1d_drop[0][0]               \n",
      "                                                                 block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 300, 300, 192 6144        block1d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 300, 300, 192 768         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 300, 300, 192 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 301, 301, 192 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 150, 150, 192 1728        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 150, 150, 192 768         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 150, 150, 192 0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 192)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 150, 150, 192 0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 150, 150, 48) 9216        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 150, 150, 48) 192         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 150, 150, 288 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 150, 150, 288 1152        block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 150, 150, 288 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 288)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 150, 150, 288 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 150, 150, 48) 192         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 150, 150, 48) 0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 150, 150, 48) 0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 150, 150, 288 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 150, 150, 288 1152        block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 150, 150, 288 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 288)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 150, 150, 288 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 150, 150, 48) 192         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 150, 150, 48) 0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 150, 150, 48) 0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 150, 150, 288 0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 150, 150, 288 1152        block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 150, 150, 288 0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 288)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 150, 150, 288 0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 150, 150, 48) 192         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (Dropout)          (None, 150, 150, 48) 0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 150, 150, 48) 0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 150, 150, 288 0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 150, 150, 288 1152        block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 150, 150, 288 0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 288)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 150, 150, 288 0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 150, 150, 48) 192         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (Dropout)          (None, 150, 150, 48) 0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 150, 150, 48) 0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_activation (Acti (None, 150, 150, 288 0           block2f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2f_bn (BatchNormalization) (None, 150, 150, 288 1152        block2f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2f_activation (Activation) (None, 150, 150, 288 0           block2f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_squeeze (GlobalAvera (None, 288)          0           block2f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_excite (Multiply)    (None, 150, 150, 288 0           block2f_activation[0][0]         \n",
      "                                                                 block2f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_bn (BatchNormal (None, 150, 150, 48) 192         block2f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2f_drop (Dropout)          (None, 150, 150, 48) 0           block2f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_add (Add)               (None, 150, 150, 48) 0           block2f_drop[0][0]               \n",
      "                                                                 block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_activation (Acti (None, 150, 150, 288 0           block2g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2g_bn (BatchNormalization) (None, 150, 150, 288 1152        block2g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2g_activation (Activation) (None, 150, 150, 288 0           block2g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_squeeze (GlobalAvera (None, 288)          0           block2g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_excite (Multiply)    (None, 150, 150, 288 0           block2g_activation[0][0]         \n",
      "                                                                 block2g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_bn (BatchNormal (None, 150, 150, 48) 192         block2g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2g_drop (Dropout)          (None, 150, 150, 48) 0           block2g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_add (Add)               (None, 150, 150, 48) 0           block2g_drop[0][0]               \n",
      "                                                                 block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 150, 150, 288 1152        block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 150, 150, 288 0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 153, 153, 288 0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 75, 75, 288)  7200        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 75, 75, 288)  1152        block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 75, 75, 288)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 288)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 75, 75, 288)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 75, 75, 80)   23040       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 75, 75, 80)   320         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 75, 75, 480)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 75, 75, 480)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 480)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 75, 75, 480)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 75, 75, 80)   320         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 75, 75, 80)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 75, 75, 80)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 75, 75, 480)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 75, 75, 480)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 480)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 75, 75, 480)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 75, 75, 80)   320         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 75, 75, 80)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 75, 75, 80)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 75, 75, 480)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 75, 75, 480)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 480)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 75, 75, 480)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 75, 75, 80)   320         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (Dropout)          (None, 75, 75, 80)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 75, 75, 80)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 75, 75, 480)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 75, 75, 480)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 480)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 75, 75, 480)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 75, 75, 80)   320         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (Dropout)          (None, 75, 75, 80)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 75, 75, 80)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_activation (Acti (None, 75, 75, 480)  0           block3f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3f_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3f_activation (Activation) (None, 75, 75, 480)  0           block3f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_squeeze (GlobalAvera (None, 480)          0           block3f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_excite (Multiply)    (None, 75, 75, 480)  0           block3f_activation[0][0]         \n",
      "                                                                 block3f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_bn (BatchNormal (None, 75, 75, 80)   320         block3f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3f_drop (Dropout)          (None, 75, 75, 80)   0           block3f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_add (Add)               (None, 75, 75, 80)   0           block3f_drop[0][0]               \n",
      "                                                                 block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_activation (Acti (None, 75, 75, 480)  0           block3g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3g_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3g_activation (Activation) (None, 75, 75, 480)  0           block3g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_squeeze (GlobalAvera (None, 480)          0           block3g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_excite (Multiply)    (None, 75, 75, 480)  0           block3g_activation[0][0]         \n",
      "                                                                 block3g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_bn (BatchNormal (None, 75, 75, 80)   320         block3g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3g_drop (Dropout)          (None, 75, 75, 80)   0           block3g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_add (Add)               (None, 75, 75, 80)   0           block3g_drop[0][0]               \n",
      "                                                                 block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 75, 75, 480)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 77, 77, 480)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 38, 38, 480)  4320        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 38, 38, 480)  1920        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 38, 38, 480)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 480)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 38, 38, 480)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 38, 38, 160)  76800       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 38, 38, 160)  640         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 38, 38, 960)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 38, 38, 960)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 960)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 38, 38, 960)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 38, 38, 160)  640         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 38, 38, 160)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 38, 38, 160)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 38, 38, 960)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 38, 38, 960)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 960)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 38, 38, 960)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 38, 38, 160)  640         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 38, 38, 160)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 38, 38, 160)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 38, 38, 960)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 38, 38, 960)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 960)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 38, 38, 960)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 38, 38, 160)  640         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 38, 38, 160)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 38, 38, 160)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 38, 38, 960)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 38, 38, 960)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 960)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 38, 38, 960)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 38, 38, 160)  640         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 38, 38, 160)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 38, 38, 160)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 38, 38, 960)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 38, 38, 960)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 960)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 38, 38, 960)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 38, 38, 160)  640         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (Dropout)          (None, 38, 38, 160)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 38, 38, 160)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 38, 38, 960)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 38, 38, 960)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 960)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 38, 38, 960)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 38, 38, 160)  640         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (Dropout)          (None, 38, 38, 160)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 38, 38, 160)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_activation (Acti (None, 38, 38, 960)  0           block4h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4h_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4h_activation (Activation) (None, 38, 38, 960)  0           block4h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_squeeze (GlobalAvera (None, 960)          0           block4h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_excite (Multiply)    (None, 38, 38, 960)  0           block4h_activation[0][0]         \n",
      "                                                                 block4h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_bn (BatchNormal (None, 38, 38, 160)  640         block4h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4h_drop (Dropout)          (None, 38, 38, 160)  0           block4h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_add (Add)               (None, 38, 38, 160)  0           block4h_drop[0][0]               \n",
      "                                                                 block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_activation (Acti (None, 38, 38, 960)  0           block4i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4i_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4i_activation (Activation) (None, 38, 38, 960)  0           block4i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_squeeze (GlobalAvera (None, 960)          0           block4i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_excite (Multiply)    (None, 38, 38, 960)  0           block4i_activation[0][0]         \n",
      "                                                                 block4i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_bn (BatchNormal (None, 38, 38, 160)  640         block4i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4i_drop (Dropout)          (None, 38, 38, 160)  0           block4i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_add (Add)               (None, 38, 38, 160)  0           block4i_drop[0][0]               \n",
      "                                                                 block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_activation (Acti (None, 38, 38, 960)  0           block4j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4j_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4j_activation (Activation) (None, 38, 38, 960)  0           block4j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_squeeze (GlobalAvera (None, 960)          0           block4j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_excite (Multiply)    (None, 38, 38, 960)  0           block4j_activation[0][0]         \n",
      "                                                                 block4j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_bn (BatchNormal (None, 38, 38, 160)  640         block4j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4j_drop (Dropout)          (None, 38, 38, 160)  0           block4j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_add (Add)               (None, 38, 38, 160)  0           block4j_drop[0][0]               \n",
      "                                                                 block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 38, 38, 960)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 38, 38, 960)  24000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 38, 38, 960)  3840        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 38, 38, 960)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 960)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 38, 38, 960)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 38, 38, 224)  215040      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 38, 38, 224)  896         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 38, 38, 1344) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 38, 38, 1344) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1344)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 38, 38, 224)  896         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 38, 38, 224)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 38, 38, 224)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 38, 38, 1344) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 38, 38, 1344) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1344)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 38, 38, 224)  896         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 38, 38, 224)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 38, 38, 224)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 38, 38, 1344) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 38, 38, 1344) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1344)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 38, 38, 224)  896         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 38, 38, 224)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 38, 38, 224)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 38, 38, 1344) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 38, 38, 1344) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1344)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 38, 38, 224)  896         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 38, 38, 224)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 38, 38, 224)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 38, 38, 1344) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 38, 38, 1344) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1344)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 38, 38, 224)  896         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (Dropout)          (None, 38, 38, 224)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 38, 38, 224)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 38, 38, 1344) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 38, 38, 1344) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1344)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 38, 38, 224)  896         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (Dropout)          (None, 38, 38, 224)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 38, 38, 224)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_activation (Acti (None, 38, 38, 1344) 0           block5h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5h_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5h_activation (Activation) (None, 38, 38, 1344) 0           block5h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_squeeze (GlobalAvera (None, 1344)         0           block5h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5h_activation[0][0]         \n",
      "                                                                 block5h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_bn (BatchNormal (None, 38, 38, 224)  896         block5h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5h_drop (Dropout)          (None, 38, 38, 224)  0           block5h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_add (Add)               (None, 38, 38, 224)  0           block5h_drop[0][0]               \n",
      "                                                                 block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_activation (Acti (None, 38, 38, 1344) 0           block5i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5i_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5i_activation (Activation) (None, 38, 38, 1344) 0           block5i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_squeeze (GlobalAvera (None, 1344)         0           block5i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5i_activation[0][0]         \n",
      "                                                                 block5i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_bn (BatchNormal (None, 38, 38, 224)  896         block5i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5i_drop (Dropout)          (None, 38, 38, 224)  0           block5i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_add (Add)               (None, 38, 38, 224)  0           block5i_drop[0][0]               \n",
      "                                                                 block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_activation (Acti (None, 38, 38, 1344) 0           block5j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5j_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5j_activation (Activation) (None, 38, 38, 1344) 0           block5j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_squeeze (GlobalAvera (None, 1344)         0           block5j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5j_activation[0][0]         \n",
      "                                                                 block5j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_bn (BatchNormal (None, 38, 38, 224)  896         block5j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5j_drop (Dropout)          (None, 38, 38, 224)  0           block5j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_add (Add)               (None, 38, 38, 224)  0           block5j_drop[0][0]               \n",
      "                                                                 block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 38, 38, 1344) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 41, 41, 1344) 0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 19, 19, 1344) 33600       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 19, 19, 1344) 5376        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 19, 19, 1344) 0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1344)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 19, 19, 1344) 0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 19, 19, 384)  516096      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 19, 19, 2304) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 19, 19, 2304) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 2304)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 19, 19, 384)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 19, 19, 384)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 19, 19, 2304) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 19, 19, 2304) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 2304)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 19, 19, 384)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 19, 19, 384)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 19, 19, 2304) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 19, 19, 2304) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 2304)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 19, 19, 384)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 19, 19, 384)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 19, 19, 2304) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 19, 19, 2304) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 2304)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 19, 19, 384)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 19, 19, 384)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 19, 19, 2304) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 19, 19, 2304) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 2304)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 19, 19, 384)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 19, 19, 384)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 19, 19, 2304) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 19, 19, 2304) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 2304)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (Dropout)          (None, 19, 19, 384)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 19, 19, 384)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 19, 19, 2304) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 19, 19, 2304) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 2304)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (Dropout)          (None, 19, 19, 384)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 19, 19, 384)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 19, 19, 2304) 0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 19, 19, 2304) 0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 2304)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (Dropout)          (None, 19, 19, 384)  0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 19, 19, 384)  0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_activation (Acti (None, 19, 19, 2304) 0           block6j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6j_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6j_activation (Activation) (None, 19, 19, 2304) 0           block6j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_squeeze (GlobalAvera (None, 2304)         0           block6j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6j_activation[0][0]         \n",
      "                                                                 block6j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6j_drop (Dropout)          (None, 19, 19, 384)  0           block6j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_add (Add)               (None, 19, 19, 384)  0           block6j_drop[0][0]               \n",
      "                                                                 block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6k_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_activation (Acti (None, 19, 19, 2304) 0           block6k_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6k_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6k_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6k_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6k_activation (Activation) (None, 19, 19, 2304) 0           block6k_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_squeeze (GlobalAvera (None, 2304)         0           block6k_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6k_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6k_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6k_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6k_activation[0][0]         \n",
      "                                                                 block6k_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6k_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6k_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6k_drop (Dropout)          (None, 19, 19, 384)  0           block6k_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_add (Add)               (None, 19, 19, 384)  0           block6k_drop[0][0]               \n",
      "                                                                 block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6l_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_activation (Acti (None, 19, 19, 2304) 0           block6l_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6l_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6l_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6l_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6l_activation (Activation) (None, 19, 19, 2304) 0           block6l_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_squeeze (GlobalAvera (None, 2304)         0           block6l_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6l_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6l_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6l_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6l_activation[0][0]         \n",
      "                                                                 block6l_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6l_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6l_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6l_drop (Dropout)          (None, 19, 19, 384)  0           block6l_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_add (Add)               (None, 19, 19, 384)  0           block6l_drop[0][0]               \n",
      "                                                                 block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6m_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_activation (Acti (None, 19, 19, 2304) 0           block6m_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6m_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6m_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6m_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6m_activation (Activation) (None, 19, 19, 2304) 0           block6m_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_squeeze (GlobalAvera (None, 2304)         0           block6m_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6m_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6m_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6m_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6m_activation[0][0]         \n",
      "                                                                 block6m_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6m_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6m_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6m_drop (Dropout)          (None, 19, 19, 384)  0           block6m_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_add (Add)               (None, 19, 19, 384)  0           block6m_drop[0][0]               \n",
      "                                                                 block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6m_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 19, 19, 2304) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 20736       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 19, 19, 2304) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 2304)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 19, 19, 2304) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 19, 19, 640)  1474560     block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 19, 19, 3840) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 19, 19, 3840) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3840)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 19, 19, 640)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 19, 19, 640)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 19, 19, 3840) 0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 19, 19, 3840) 0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3840)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (Dropout)          (None, 19, 19, 640)  0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 19, 19, 640)  0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_activation (Acti (None, 19, 19, 3840) 0           block7d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7d_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7d_activation (Activation) (None, 19, 19, 3840) 0           block7d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_squeeze (GlobalAvera (None, 3840)         0           block7d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7d_activation[0][0]         \n",
      "                                                                 block7d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7d_drop (Dropout)          (None, 19, 19, 640)  0           block7d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_add (Add)               (None, 19, 19, 640)  0           block7d_drop[0][0]               \n",
      "                                                                 block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 19, 19, 2560) 1638400     block7d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 19, 19, 2560) 10240       top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 19, 19, 2560) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2560)         0           top_activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 64,097,687\n",
      "Trainable params: 0\n",
      "Non-trainable params: 64,097,687\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "custom_efficientnetB0_model.trainable = False\n",
    "for layer in custom_efficientnetB0_model.layers:\n",
    "    layer.trainable = False\n",
    "## Freez\n",
    "#custom_inceptionv3_model.layers[-1].trainable = True\n",
    "#custom_inceptionv3_model.layers[-2].trainable = True\n",
    "#custom_inceptionv3_model.layers[-3].trainable = True\n",
    "print(custom_efficientnetB0_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(custom_efficientnetB0_model, to_file=\"InceptionRemoveOutput.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Feature Extractor\n",
    "model.add(custom_efficientnetB0_model)\n",
    "# Classifier\n",
    "#DeepDense\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(len(class_names), activation='softmax', trainable=True))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 2560)              64097687  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2622464   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 66,724,251\n",
      "Trainable params: 2,626,564\n",
      "Non-trainable params: 64,097,687\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = ['1WayConnectorforFoley', '2WayConnectorforFoley', '2WayFoleyCatheter', '3WayConnectorforFoley', '3Waystopcock', 'AlcoholBottle', 'AlcoholPad', 'BootCover', 'CottonBall', 'CottonSwap', 'Dilator', 'DisposableInfusionSet', 'ExtensionTube', 'FaceShield', 'FrontLoadSyringe', 'GauzePad', 'Glove', 'GuideWire', 'LiquidBottle', 'Mask', 'NGTube', 'NasalCannula', 'Needle', 'OxygenMask', 'PPESuit', 'PharmaceuticalProduct', 'Pill', 'PillBottle', 'PrefilledHumidifier', 'PressureConnectingTube', 'ReusableHumidifier', 'SodiumChlorideBag', 'SterileHumidifierAdapter', 'SurgicalBlade', 'SurgicalCap', 'SurgicalSuit', 'Syringe', 'TrachealTube', 'UrineBag', 'Vaccinebottle', 'WingedInfusionSet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[-1]._name = 'Classifier'\n",
    "#model.layers[-2]._name = 'InceptionV3'\n",
    "#print(len(model.layers))\n",
    "#tf.keras.utils.plot_model(model, to_file=\"Incepv3_FreezExtractorOurOutputLayer.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/2000\n",
      "97/97 [==============================] - 273s 2s/step - loss: 0.2171 - accuracy: 0.9186 - val_loss: 0.0677 - val_accuracy: 0.9754\n",
      "Epoch 2/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0710 - accuracy: 0.9751 - val_loss: 0.0784 - val_accuracy: 0.9715\n",
      "Epoch 3/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0307 - accuracy: 0.9919 - val_loss: 0.0553 - val_accuracy: 0.9806\n",
      "Epoch 4/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.0906 - val_accuracy: 0.9651\n",
      "Epoch 5/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.0630 - val_accuracy: 0.9806\n",
      "Epoch 6/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.0552 - val_accuracy: 0.9819\n",
      "Epoch 7/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0327 - accuracy: 0.9874 - val_loss: 0.0576 - val_accuracy: 0.9806\n",
      "Epoch 8/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0288 - accuracy: 0.9919 - val_loss: 0.0618 - val_accuracy: 0.9793\n",
      "Epoch 9/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.0535 - val_accuracy: 0.9858\n",
      "Epoch 10/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.0517 - val_accuracy: 0.9858\n",
      "Epoch 11/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0408 - val_accuracy: 0.9909\n",
      "Epoch 12/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 13/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.0489 - val_accuracy: 0.9909\n",
      "Epoch 14/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0760 - val_accuracy: 0.9767\n",
      "Epoch 15/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0554 - val_accuracy: 0.9871\n",
      "Epoch 16/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0615 - val_accuracy: 0.9871\n",
      "Epoch 17/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.0506 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 18/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0459 - val_accuracy: 0.9909\n",
      "Epoch 19/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0437 - val_accuracy: 0.9935\n",
      "Epoch 20/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.3993e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9948\n",
      "Epoch 21/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0460 - val_accuracy: 0.9935\n",
      "Epoch 22/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 23/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.5766e-04 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 24/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.6418e-04 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 25/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.2416e-04 - accuracy: 0.9997 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 26/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2531e-04 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 27/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.0659e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 28/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5471e-04 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 29/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1592e-04 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 30/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.8621e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 31/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.5399e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 32/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6734e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 33/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.8198e-04 - accuracy: 0.9994 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 34/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5138e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 35/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0371e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 36/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.6442e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 37/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.6433e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 38/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5741e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 39/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3606e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 40/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.4478e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 41/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.4942e-04 - accuracy: 0.9997 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 42/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.6254e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 43/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8963e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 44/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1089e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 45/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.5006e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 46/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.0096e-04 - accuracy: 0.9997 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 47/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6466e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 48/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9818e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 49/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4498e-04 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 50/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2934e-04 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 51/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9887e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 52/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.1057e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 53/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8752e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 54/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4369e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 55/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4065e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 56/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1501e-04 - accuracy: 0.9997 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 57/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6882e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 58/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.7359e-04 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 59/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5280e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 60/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5035e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 61/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2518e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 62/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9366e-04 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 63/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5013e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 64/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3275e-04 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9935\n",
      "Epoch 65/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0404e-04 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9935\n",
      "Epoch 66/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8190e-04 - accuracy: 0.9997 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 67/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9762e-04 - accuracy: 0.9997 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 68/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1014e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 69/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9095e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 70/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9878e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 71/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3817e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 72/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0719e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 73/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6119e-04 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 74/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7337e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 75/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1786e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9935\n",
      "Epoch 76/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.7989e-04 - accuracy: 0.9997 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 77/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2571e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 78/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8402e-04 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 79/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2921e-04 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 80/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7597e-04 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 81/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0178e-04 - accuracy: 0.9997 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 82/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0695e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 83/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3194e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 84/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3182e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 85/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.2628e-04 - accuracy: 0.9997 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 86/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0003e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 87/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9586e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 88/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0610e-04 - accuracy: 0.9997 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 89/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8793e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 90/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2215e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 91/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6289e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 92/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.3388e-04 - accuracy: 0.9997 - val_loss: 0.0378 - val_accuracy: 0.9935\n",
      "Epoch 93/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1154e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9935\n",
      "Epoch 94/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3128e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9935\n",
      "Epoch 95/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.2241e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9935\n",
      "Epoch 96/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2064e-04 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9935\n",
      "Epoch 97/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4378e-04 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9935\n",
      "Epoch 98/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1767e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 99/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7141e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 100/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3993e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 101/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4831e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 102/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.7805e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 103/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5208e-04 - accuracy: 0.9997 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 104/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8471e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 105/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6539e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 106/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4560e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 107/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2279e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 108/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2262e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 109/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4046e-04 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 110/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3061e-04 - accuracy: 0.9997 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 111/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.9970e-05 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 112/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1509e-04 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 113/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3050e-04 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 114/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 1.9878e-04 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9948\n",
      "Epoch 115/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.8867e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 116/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 1.1671e-04 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 117/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0376e-04 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 118/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5716e-04 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 119/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0195e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 120/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.3643e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9948\n",
      "Epoch 121/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.5707e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9948\n",
      "Epoch 122/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.7270e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 123/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2925e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 124/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.6668e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 125/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.4429e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 126/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2499e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 127/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.8144e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 128/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.5846e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 129/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.8827e-04 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 130/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.4326e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 131/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.6202e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 132/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.6091e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 133/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.0132e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 134/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.3883e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 135/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.4531e-04 - accuracy: 0.9997 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 136/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.1975e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 137/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.4457e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 138/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.1599e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9948\n",
      "Epoch 139/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.2074e-05 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 140/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.6153e-05 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 141/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.0154e-05 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 142/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.6178e-04 - accuracy: 0.9997 - val_loss: 0.0377 - val_accuracy: 0.9935\n",
      "Epoch 143/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.0900e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 144/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.0453e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 145/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.9170e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 146/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.4630e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 147/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.6064e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 148/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.6899e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 149/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.4452e-04 - accuracy: 0.9997 - val_loss: 0.0385 - val_accuracy: 0.9935\n",
      "Epoch 150/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.4267e-04 - accuracy: 0.9997 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 151/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.2329e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 152/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.6702e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 153/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.9526e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 154/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.7770e-04 - accuracy: 0.9997 - val_loss: 0.0375 - val_accuracy: 0.9935\n",
      "Epoch 155/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2481e-04 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 156/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2709e-04 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9948\n",
      "Epoch 157/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.8948e-04 - accuracy: 0.9997 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 158/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.0184e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 159/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.0915e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 160/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.3223e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 161/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.6735e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 162/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.1457e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 163/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.3600e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 164/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.9670e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 165/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 166/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.1202e-04 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 167/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.1754e-04 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 168/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.0864e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 169/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.2561e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 170/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.3593e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 171/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.5490e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 172/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.7737e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 173/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.4255e-04 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 174/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.1219e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 175/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.3323e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 176/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.3114e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 177/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.9250e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 178/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.5435e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 179/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.6647e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 180/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.5897e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 181/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.6303e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 182/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.5907e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 183/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.4004e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 184/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 9.3856e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 185/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.3091e-04 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 186/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.1818e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 187/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.4871e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 188/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2123e-04 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 189/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.2758e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 190/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.0979e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 191/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.1688e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 192/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.5900e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 193/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.9826e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 194/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.0439e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 195/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.4287e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 196/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.9984e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 197/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1478e-04 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 198/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.7765e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 199/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.7236e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 200/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.0499e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.1217e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 202/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4462e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 203/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9737e-04 - accuracy: 0.9997 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 204/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.7450e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 205/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0643e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 206/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1022e-04 - accuracy: 0.9997 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 207/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0878e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 208/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.8741e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 209/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.6855e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 210/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.5520e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 211/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6705e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 212/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7841e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 213/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6024e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 214/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.6028e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 215/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0402e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 216/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1596e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 217/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1731e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 218/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.8697e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 219/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1142e-04 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 220/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.9273e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 221/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.1491e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 222/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1462e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 223/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0927e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 224/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0382e-04 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 225/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.7532e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 226/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5459e-04 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 227/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9036e-04 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 228/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1029e-04 - accuracy: 0.9997 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 229/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0205e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 230/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.1245e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 231/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.1511e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 232/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2557e-04 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 233/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9709e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 234/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.5315e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 235/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.9949e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 236/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.6863e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 237/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3508e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 238/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.2841e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 239/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1067e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 240/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4954e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 241/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.1005e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 242/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2968e-04 - accuracy: 0.9997 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 243/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3179e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 244/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.1621e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 245/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.5085e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 246/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1335e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 247/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.8028e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 248/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1726e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 249/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9179e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 250/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 251/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5238e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 252/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.3865e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 253/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1659e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 254/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.6894e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 255/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7728e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 256/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9893e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 257/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.8286e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 258/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5067e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 259/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8616e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 260/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7411e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 261/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1439e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 262/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5313e-04 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 263/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2459e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 264/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9247e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 265/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.1592e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 266/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5550e-04 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 267/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1029e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 268/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8706e-04 - accuracy: 0.9997 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 269/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5927e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 270/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.1061e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 271/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8698e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 272/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.7270e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 273/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.0898e-04 - accuracy: 0.9997 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 274/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4946e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 275/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.5758e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 276/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4376e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 277/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2520e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 278/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1527e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 279/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0302e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 280/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9729e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 281/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9360e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 282/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9466e-04 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 283/2000\n",
      "97/97 [==============================] - 215s 2s/step - loss: 5.6293e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 284/2000\n",
      "97/97 [==============================] - 212s 2s/step - loss: 3.3959e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 285/2000\n",
      "97/97 [==============================] - 212s 2s/step - loss: 3.3455e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 286/2000\n",
      "97/97 [==============================] - 218s 2s/step - loss: 5.2942e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 287/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.7494e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 288/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4734e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 289/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8154e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 290/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.2739e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 291/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7742e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 292/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.5112e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 293/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4979e-04 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 294/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.6763e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 295/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3386e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 296/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9322e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 297/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3151e-04 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 298/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1516e-04 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 299/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8731e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 300/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0239e-04 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 301/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1303e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 302/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.6833e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 303/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.0154e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 304/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9800e-04 - accuracy: 0.9997 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 305/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4059e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 306/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.9675e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 307/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.7241e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 308/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9304e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 309/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.2776e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 310/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2063e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 311/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5332e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 312/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.6090e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 313/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0795e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 314/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8169e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 315/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.8971e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 316/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6695e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 317/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.5882e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 318/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.0813e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 319/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.7560e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 320/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.8988e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 321/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7826e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 322/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1333e-04 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 323/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0067e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 324/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5105e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 325/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2996e-04 - accuracy: 0.9997 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 326/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8266e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 327/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.5786e-05 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 328/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7017e-04 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 329/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2195e-05 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 330/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3366e-05 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 331/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3973e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 332/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2471e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 333/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4489e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 334/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1947e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 335/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8582e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9935\n",
      "Epoch 336/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0044e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 337/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4971e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 338/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.6637e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 339/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.2093e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 340/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 3.2933e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 341/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2394e-04 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 342/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.9539e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 343/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.7425e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 344/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4097e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 345/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8086e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 346/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.5216e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 347/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.1146e-04 - accuracy: 0.9997 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 348/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7743e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 349/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7017e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 350/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.0830e-05 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 351/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.8338e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 352/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.9889e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 353/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.0074e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 354/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.9771e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 355/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3648e-05 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 356/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.8555e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 357/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7877e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 358/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9113e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 359/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.5179e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 360/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0899e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 361/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.4951e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 362/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6580e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 363/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.2236e-05 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 364/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5903e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 365/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.5306e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 366/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1830e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 367/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8091e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 368/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.8873e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 369/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8988e-05 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 370/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8442e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 371/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3768e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 372/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0257e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 373/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2159e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 374/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.4650e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 375/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2338e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 376/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1158e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 377/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.0309e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 378/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.5080e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 379/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.5329e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 380/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.9116e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 381/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8015e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 382/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8714e-05 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 383/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5226e-05 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 384/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2148e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 385/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9375e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 386/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.7722e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 387/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1372e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 388/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.2477e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 389/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.6567e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9935\n",
      "Epoch 390/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7466e-05 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 391/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.7427e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 392/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9810e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 393/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5653e-05 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 394/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3766e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 395/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.0856e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9935\n",
      "Epoch 396/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0094e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 397/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9093e-05 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 398/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4499e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 399/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.2125e-04 - accuracy: 0.9997 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 400/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3157e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0531e-05 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 402/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8053e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 403/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6532e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 404/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0258e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 405/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5329e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 406/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9745e-04 - accuracy: 0.9997 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 407/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8236e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 408/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6087e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 409/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6030e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 410/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.7836e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 411/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1588e-04 - accuracy: 0.9997 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 412/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3255e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9935\n",
      "Epoch 413/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4596e-05 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9935\n",
      "Epoch 414/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4310e-05 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 415/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8473e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 416/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0432 - val_accuracy: 0.9935\n",
      "Epoch 417/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1114e-05 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9935\n",
      "Epoch 418/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.9937e-05 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9935\n",
      "Epoch 419/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9582e-05 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 420/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3454e-04 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 421/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.4960e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 422/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2659e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 423/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1917e-04 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 424/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.5036e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 425/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8419e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 426/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6030e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 427/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3706e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 428/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9235e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 429/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.9862e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 430/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1964e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 431/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4036e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 432/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4154e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 433/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9295e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 434/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8727e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 435/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.7506e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 436/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4530e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 437/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 5.7518e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 438/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0271e-05 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 439/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.1748e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 440/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.1268e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 441/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8030e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 442/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3554e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 443/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0413e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 444/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8986e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 445/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.5423e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 446/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9021e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 447/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7117e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 448/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2175e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 449/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7838e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 450/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0755e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 451/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4004e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 452/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6427e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 453/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2865e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 454/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3150e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 455/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.7331e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 456/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9245e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 457/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3408e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 458/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8356e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 459/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6059e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 460/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.8201e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 461/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6411e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 462/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1319e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 463/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4809e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 464/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9087e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 465/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8788e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 466/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3139e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 467/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1557e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 468/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3453e-04 - accuracy: 0.9997 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 469/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3631e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9935\n",
      "Epoch 470/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.7135e-05 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9935\n",
      "Epoch 471/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9943e-05 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
      "Epoch 472/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7515e-05 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 473/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6500e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 474/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7764e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 475/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1544e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 476/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8476e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 477/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.1238e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 478/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3760e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 479/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0167e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 480/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4701e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 481/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1299e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 482/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2723e-04 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 483/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4039e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 484/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0636e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 485/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5877e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 486/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5502e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 487/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 1.3849e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 488/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0885e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 489/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8585e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 490/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.8355e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 491/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9829e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 492/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9543e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 493/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3599e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 494/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.0809e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 495/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1163e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 496/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8510e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 497/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1852e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 498/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3935e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 499/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.2801e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 500/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.6361e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 501/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4322e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 502/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2278e-04 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 503/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8300e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 504/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 505/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6743e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 506/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1292e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 507/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.4805e-04 - accuracy: 0.9997 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 508/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2179e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 509/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3192e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 510/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7797e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 511/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.9102e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 512/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.5286e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 513/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6887e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 514/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7237e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 515/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6833e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 516/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9582e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 517/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2359e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 518/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6604e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 519/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6957e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 520/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9774e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 521/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.8136e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 522/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0936e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 523/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.6737e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 524/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3182e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 525/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5885e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 526/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1078e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 527/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.5344e-05 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 528/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.1945e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 529/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1690e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 530/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 531/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8943e-04 - accuracy: 0.9997 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 532/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0008e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 533/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.7842e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 534/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 535/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1267e-05 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9935\n",
      "Epoch 536/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8653e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 537/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5945e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 538/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1069e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 539/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2387e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 540/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8013e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 541/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0737e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 542/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1541e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 543/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.0041e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 544/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2463e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9935\n",
      "Epoch 545/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5119e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9935\n",
      "Epoch 546/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9100e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 547/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0497e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 548/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0312e-04 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 549/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7855e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 550/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2688e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 551/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2794e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 552/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.9829e-05 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 553/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.9076e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 554/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5504e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 555/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.3719e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 556/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1595e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 557/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 1.1336e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 558/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0749e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 559/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9172e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 560/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0983e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 561/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.3159e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 562/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8142e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 563/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4191e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 564/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0372e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 565/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3396e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 566/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3429e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 567/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.4212e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 568/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.3333e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 569/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3667e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 570/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9109e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 571/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4470e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 572/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5851e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 573/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.4017e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 574/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3906e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9935\n",
      "Epoch 575/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2423e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 576/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.2804e-04 - accuracy: 0.9997 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 577/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6457e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 578/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.5166e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 579/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0377e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 580/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8974e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 581/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.0059e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 582/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6324e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 583/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2575e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 584/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6597e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 585/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8944e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 586/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3103e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 587/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 3.7930e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 588/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2622e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 589/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1567e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 590/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.4047e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9935\n",
      "Epoch 591/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3451e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 592/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1736e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 593/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.7188e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 594/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8373e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 595/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7538e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 596/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3916e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 597/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6159e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
      "Epoch 598/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2628e-05 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 599/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2313e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 600/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7110e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5933e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 602/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1551e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 603/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0130e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 604/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.7343e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 605/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.9473e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 606/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.1456e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 607/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 5.7970e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 608/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8563e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 609/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2865e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 610/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2932e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 611/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.2211e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 612/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2576e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 613/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9064e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 614/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.3081e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 615/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.5089e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 616/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0344e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 617/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0282e-04 - accuracy: 0.9997 - val_loss: 0.0373 - val_accuracy: 0.9935\n",
      "Epoch 618/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1122e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9935\n",
      "Epoch 619/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.7215e-06 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9935\n",
      "Epoch 620/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.4997e-06 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9935\n",
      "Epoch 621/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.4508e-06 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9935\n",
      "Epoch 622/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9464e-05 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 623/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0530e-06 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 624/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1685e-05 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 625/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8601e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9935\n",
      "Epoch 626/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2158e-05 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 627/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 4.9323e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9935\n",
      "Epoch 628/2000\n",
      "97/97 [==============================] - 228s 2s/step - loss: 1.1067e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9935\n",
      "Epoch 629/2000\n",
      "97/97 [==============================] - 228s 2s/step - loss: 1.0481e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9935\n",
      "Epoch 630/2000\n",
      "97/97 [==============================] - 228s 2s/step - loss: 1.2800e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 631/2000\n",
      "97/97 [==============================] - 228s 2s/step - loss: 9.0221e-06 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 632/2000\n",
      "97/97 [==============================] - 228s 2s/step - loss: 4.3064e-05 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 633/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 5.9613e-06 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
      "Epoch 634/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.2732e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9935\n",
      "Epoch 635/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 6.6405e-06 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9935\n",
      "Epoch 636/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 9.6893e-06 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9935\n",
      "Epoch 637/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.6959e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9935\n",
      "Epoch 638/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.2084e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 639/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.8291e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 640/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.0343e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 641/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 6.1616e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 642/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 5.4012e-06 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 643/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.8443e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 644/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.0469e-05 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9948\n",
      "Epoch 645/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.1351e-05 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9948\n",
      "Epoch 646/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 1.1638e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 647/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 9.1312e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 648/2000\n",
      "97/97 [==============================] - 227s 2s/step - loss: 1.0676e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9935\n",
      "Epoch 649/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 3.1693e-05 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9948\n",
      "Epoch 650/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9449e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 651/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.3725e-06 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9948\n",
      "Epoch 652/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8591e-05 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 653/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.2491e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 654/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6015e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 655/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.0599e-06 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 656/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.5158e-06 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "Epoch 657/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1561e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 658/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.5871e-05 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9948\n",
      "Epoch 659/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.5083e-06 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9948\n",
      "Epoch 660/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9051e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 661/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3253e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 662/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4037e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 663/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5930e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 664/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7658e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 665/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5365e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 666/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7706e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 667/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2188e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 668/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.7581e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 669/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2366e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 670/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1212e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 671/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1070e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 672/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1000e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 673/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5490e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 674/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6977e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 675/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.9482e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 676/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0530e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 677/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4457e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 678/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5851e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9935\n",
      "Epoch 679/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.2734e-05 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 680/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3754e-05 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 681/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.4520e-06 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 682/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4357e-06 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 683/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.7479e-06 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 684/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.0999e-06 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 685/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.3532e-06 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 686/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.0253e-05 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9948\n",
      "Epoch 687/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4455e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 688/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2242e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 689/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9445e-05 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9948\n",
      "Epoch 690/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4883e-05 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9948\n",
      "Epoch 691/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.3017e-06 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9948\n",
      "Epoch 692/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4152e-05 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9948\n",
      "Epoch 693/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.3352e-06 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9948\n",
      "Epoch 694/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4282e-05 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9935\n",
      "Epoch 695/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2113e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9935\n",
      "Epoch 696/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2317e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 697/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8095e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 698/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2685e-05 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 699/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1799e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 700/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1686e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 701/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3802e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 702/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6184e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 703/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6292e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 704/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.0973e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9935\n",
      "Epoch 705/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4660e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 706/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3779e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 707/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.0482e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 708/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2178e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 709/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2063e-04 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 710/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.5107e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 711/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.0645e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 712/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3791e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 713/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4715e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 714/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0775e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 715/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.3945e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 716/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.7992e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 717/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.5598e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 718/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.7037e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 719/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3196e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 720/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.0050e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 721/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2692e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 722/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.0907e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 723/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.7628e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 724/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0396e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 725/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.6046e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 726/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.7977e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 727/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.7072e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 728/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.0865e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 729/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.5898e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 730/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.6345e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 731/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8027e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 732/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8295e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 733/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.1932e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 734/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.4932e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 735/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8849e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 736/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.2218e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 737/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2544e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 738/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.5820e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 739/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7317e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 740/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.3016e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 741/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0291e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 742/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.6987e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 743/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2107e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 744/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.5476e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 745/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0318e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 746/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1080e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 747/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7200e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 748/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2808e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9935\n",
      "Epoch 749/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.9122e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 750/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.6688e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9935\n",
      "Epoch 751/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.0973e-06 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 752/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.6765e-06 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 753/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0108e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 754/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.4572e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
      "Epoch 755/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.9420e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 756/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.5977e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 757/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.4140e-06 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 758/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8409e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 759/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0968e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 760/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9376e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 761/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.3838e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9935\n",
      "Epoch 762/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.2745e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9935\n",
      "Epoch 763/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.8455e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 764/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8068e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 765/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.7903e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 766/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9299e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 767/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5139e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 768/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.1972e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 769/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.6808e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 770/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4903e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 771/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.1609e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 772/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5326e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 773/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.2290e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 774/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5461e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 775/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2405e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 776/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5919e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 777/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0009e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 778/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.2642e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 779/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 1.3809e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 780/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5255e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 781/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.2023e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 782/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.2104e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 783/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0146e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 784/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.1957e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9935\n",
      "Epoch 785/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3454e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 786/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5080e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 787/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.7688e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9935\n",
      "Epoch 788/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2081e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 789/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.2284e-05 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9935\n",
      "Epoch 790/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4248e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9935\n",
      "Epoch 791/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.0878e-06 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9935\n",
      "Epoch 792/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4539e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9935\n",
      "Epoch 793/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1702e-04 - accuracy: 0.9997 - val_loss: 0.0374 - val_accuracy: 0.9935\n",
      "Epoch 794/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.8925e-06 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9935\n",
      "Epoch 795/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.9731e-06 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9935\n",
      "Epoch 796/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.9122e-06 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9935\n",
      "Epoch 797/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.5737e-06 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 798/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0451e-05 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 799/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.9744e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 800/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.8773e-06 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 9.1547e-06 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 802/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.3125e-06 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9948\n",
      "Epoch 803/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.8046e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 804/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4870e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 805/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.3903e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 806/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6195e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 807/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3056e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 808/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0665e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 809/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3505e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 810/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8253e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 811/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4451e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 812/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2723e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9935\n",
      "Epoch 813/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.5176e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 814/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.3018e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 815/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.1433e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 816/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.6660e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9935\n",
      "Epoch 817/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0926e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 818/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 9.5617e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9935\n",
      "Epoch 819/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.4824e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9935\n",
      "Epoch 820/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6382e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 821/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1049e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 822/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.5219e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 823/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9709e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 824/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2105e-04 - accuracy: 0.9997 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 825/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0459e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 826/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3335e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9935\n",
      "Epoch 827/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.5314e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 828/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.6787e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 829/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4821e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 830/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5125e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 831/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0123e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 832/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.6160e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 833/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5746e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 834/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1239e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
      "Epoch 835/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0077e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 836/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.6778e-06 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 837/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4531e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 838/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.4103e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 839/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1943e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 840/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5376e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 841/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.9965e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 842/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7329e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 843/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9037e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 844/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2810e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 845/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3516e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 846/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9575e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 847/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0851e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 848/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6051e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 849/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3583e-05 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 850/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3405e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 851/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8197e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 852/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5295e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 853/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5854e-04 - accuracy: 0.9997 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 854/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0279e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 855/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.5386e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 856/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7839e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 857/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.1175e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 858/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1585e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 859/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3589e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 860/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3545e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 861/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.3933e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 862/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 6.3731e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 863/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0092e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 864/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2825e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 865/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4691e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 866/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.5635e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 867/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5869e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 868/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7904e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 869/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8423e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 870/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5495e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 871/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2302e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 872/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.9913e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 873/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9253e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 874/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.5389e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 875/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9960e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 876/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0552e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 877/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1302e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 878/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3224e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 879/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5835e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 880/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0717e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 881/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.1986e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 882/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.8893e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 883/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0702e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 884/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5515e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 885/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.5170e-06 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 886/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6104e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 887/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7474e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 888/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1877e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 889/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2335e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 890/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2505e-06 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 891/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5182e-06 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 892/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8976e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 893/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.9932e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 894/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8675e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 895/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3155e-04 - accuracy: 0.9997 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 896/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.8738e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 897/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2355e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 898/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4592e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 899/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4386e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 900/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0239e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 901/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0068e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 902/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3874e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 903/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1424e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 904/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5736e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 905/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9748e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 906/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0325e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 907/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.6663e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 908/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2632e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 909/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6845e-04 - accuracy: 0.9997 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 910/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4888e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 911/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4763e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 912/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3974e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 913/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0763e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 914/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4903e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 915/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.8461e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 916/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3692e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 917/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.5443e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 918/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2889e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 919/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9475e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 920/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0551e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 921/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5778e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 922/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.5904e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 923/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9944e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 924/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.2544e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 925/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2293e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 926/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.3308e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 927/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8270e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 928/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.6306e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 929/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6824e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 930/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.9362e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 931/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8080e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 932/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1596e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 933/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7508e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 934/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6772e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 935/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7242e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 936/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.6742e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 937/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4382e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 938/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6470e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 939/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1627e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9935\n",
      "Epoch 940/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.1054e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 941/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3436e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 942/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 8.7494e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 943/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3722e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 944/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8093e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
      "Epoch 945/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6729e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 946/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.5281e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 947/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2097e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9935\n",
      "Epoch 948/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.5633e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 949/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 5.7345e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 950/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2307e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 951/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8475e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 952/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8469e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 953/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3887e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 954/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.5856e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 955/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3143e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 956/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.5203e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 957/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5504e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 958/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2005e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 959/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4049e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 960/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.7716e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 961/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6851e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 962/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.9416e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 963/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.7734e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 964/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.9662e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 965/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.0753e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 966/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5988e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 967/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0280e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 968/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8668e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 969/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6719e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 970/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3378e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 971/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7587e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 972/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6256e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 973/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2143e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 974/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0909e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 975/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7440e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 976/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 4.6933e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 977/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3499e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 978/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.9670e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 979/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4378e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 980/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.0269e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 981/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.5491e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 982/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6871e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 983/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9340e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 984/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9056e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 985/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7615e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 986/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2006e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 987/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8127e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 988/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4073e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 989/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1508e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 990/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9369e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 991/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0797e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 992/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4041e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 993/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.6037e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 994/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.8647e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 995/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.7151e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 996/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.4527e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 997/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.2134e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 998/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3392e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 999/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2261e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1000/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7875e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4087e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1002/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9685e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1003/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.0733e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1004/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3628e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1005/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7635e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1006/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2492e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1007/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.2636e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1008/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 5.3692e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1009/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 4.6548e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1010/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0956e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1011/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8453e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1012/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5567e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1013/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3993e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1014/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.5367e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1015/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7504e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1016/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4408e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1017/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6416e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1018/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.8341e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1019/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7096e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1020/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3616e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1021/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1380e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1022/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5496e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1023/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3557e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1024/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.5206e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1025/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0351e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1026/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3802e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1027/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6943e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1028/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.7233e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1029/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2782e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1030/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2595e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1031/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7835e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1032/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.9269e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9935\n",
      "Epoch 1033/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1593e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1034/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4936e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1035/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4071e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1036/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8316e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1037/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8241e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1038/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.9617e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 1039/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9088e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 1040/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6633e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1041/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.8613e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1042/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1893e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1043/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6773e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1044/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.8990e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1045/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1394e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1046/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9018e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1047/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7995e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1048/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2848e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1049/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2876e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 1050/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5712e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 1051/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5990e-05 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 1052/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9882e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1053/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6272e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1054/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8660e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1055/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9673e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1056/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4799e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1057/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7314e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1058/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9286e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1059/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5564e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1060/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1418e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1061/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5724e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1062/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4201e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1063/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 3.5319e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1064/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8174e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1065/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8750e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1066/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4607e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1067/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8133e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1068/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4843e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1069/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8451e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1070/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0403e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1071/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0844e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1072/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4122e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1073/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.0607e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1074/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.1099e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 1075/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9108e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1076/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4562e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1077/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4005e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1078/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.1222e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1079/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9862e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1080/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4561e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1081/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7784e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
      "Epoch 1082/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9793e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9935\n",
      "Epoch 1083/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3889e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 1084/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.5366e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 1085/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6140e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1086/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9247e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1087/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.2110e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1088/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8129e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1089/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1152e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1090/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4396e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 1091/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5202e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1092/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.1146e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1093/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8516e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1094/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2472e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9935\n",
      "Epoch 1095/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5359e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1096/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9051e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1097/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0846e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1098/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8426e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1099/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.5814e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1100/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0243e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1101/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9872e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1102/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0128e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1103/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4759e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1104/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3526e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1105/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8706e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1106/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3224e-05 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1107/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6140e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1108/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8931e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1109/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.3310e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1110/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6023e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1111/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3394e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1112/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2626e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1113/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4042e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1114/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8053e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1115/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9561e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1116/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8135e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1117/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9967e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1118/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9130e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1119/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.7746e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1120/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4190e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1121/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6328e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1122/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4796e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1123/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.9836e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1124/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6079e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1125/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.5891e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 1126/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3452e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 1127/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1691e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 1128/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9476e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 1129/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7893e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 1130/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2704e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 1131/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0423e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9935\n",
      "Epoch 1132/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4566e-05 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 1133/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9107e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 1134/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8975e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 1135/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.1369e-06 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 1136/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8708e-06 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9948\n",
      "Epoch 1137/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8661e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 1138/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4647e-05 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 1139/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3001e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1140/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5598e-05 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9948\n",
      "Epoch 1141/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.1313e-06 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 1142/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9524e-06 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9948\n",
      "Epoch 1143/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6933e-06 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9948\n",
      "Epoch 1144/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4177e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 1145/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5744e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9948\n",
      "Epoch 1146/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4992e-06 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9948\n",
      "Epoch 1147/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0490e-06 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9948\n",
      "Epoch 1148/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6573e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1149/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2814e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1150/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0488e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 1151/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.2055e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 1152/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5526e-05 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1153/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2217e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1154/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4412e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1155/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5020e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1156/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5227e-04 - accuracy: 0.9997 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 1157/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6603e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1158/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8755e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1159/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5165e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1160/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6455e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1161/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5467e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1162/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1987e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1163/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5673e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1164/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2246e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1165/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2387e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1166/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.9402e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1167/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2723e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1168/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6536e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1169/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0014e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1170/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.0439e-05 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1171/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4432e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1172/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9552e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1173/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3152e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1174/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7350e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1175/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6265e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1176/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3939e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1177/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.4360e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1178/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3908e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1179/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8913e-05 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1180/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0524e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1181/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9878e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1182/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3506e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1183/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6242e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1184/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0621e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1185/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8751e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1186/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.5286e-07 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1187/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5249e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1188/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.0235e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1189/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4322e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1190/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4583e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1191/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4678e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1192/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5006e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1193/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5579e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1194/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8346e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1195/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3637e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1196/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2369e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1197/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3766e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9935\n",
      "Epoch 1198/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6176e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9935\n",
      "Epoch 1199/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.5847e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1200/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2954e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 7.0308e-05 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1202/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6625e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1203/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.4285e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1204/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1362e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1205/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6278e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1206/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8593e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1207/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9813e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1208/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.0499e-07 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1209/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9213e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1210/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7649e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1211/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0328e-05 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1212/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0123e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1213/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1974e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1214/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3847e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1215/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.0865e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1216/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.4539e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1217/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0273e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1218/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3563e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1219/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4637e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1220/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9258e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1221/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7116e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1222/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.6752e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1223/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1003e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1224/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.9705e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1225/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.1173e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 1226/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9445e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1227/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.1543e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1228/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 4.0139e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1229/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.7996e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1230/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9770e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1231/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4767e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1232/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7388e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1233/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5432e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1234/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0866e-05 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1235/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2367e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 1236/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5144e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1237/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3330e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1238/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2113e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1239/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6923e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1240/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5804e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1241/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6788e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1242/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4664e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1243/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9648e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1244/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3475e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1245/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8176e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1246/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5314e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1247/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6411e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1248/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2849e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1249/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6684e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1250/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3449e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1251/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0325e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1252/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2235e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1253/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5575e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1254/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8671e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1255/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9698e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1256/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2847e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1257/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2869e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1258/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7778e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1259/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7707e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1260/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.3606e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1261/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1043e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1262/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4724e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1263/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1686e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1264/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3541e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1265/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5357e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1266/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4806e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1267/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8229e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1268/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7242e-05 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1269/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0517e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1270/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7532e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1271/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3261e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1272/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3582e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1273/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9243e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1274/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3864e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1275/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5513e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1276/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1316e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1277/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2369e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1278/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2442e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1279/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.0816e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1280/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4589e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1281/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6408e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1282/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5376e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1283/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.5874e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1284/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3093e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1285/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1412e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1286/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9400e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1287/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2244e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1288/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.5123e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1289/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6266e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1290/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8247e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1291/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4291e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1292/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.0749e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1293/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.7625e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9935\n",
      "Epoch 1294/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.1963e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1295/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.3800e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1296/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7937e-05 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1297/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0680e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1298/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4099e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1299/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0712e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 1300/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9468e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 1301/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0996e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1302/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0236e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1303/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3825e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9935\n",
      "Epoch 1304/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 1305/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3218e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
      "Epoch 1306/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1541e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1307/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4998e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1308/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2616e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 1309/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1244e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1310/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2976e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1311/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7129e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1312/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6677e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 1313/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2729e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1314/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1349e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1315/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0464e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1316/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.1040e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1317/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6858e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1318/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2844e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1319/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.2077e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1320/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9510e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1321/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.6585e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1322/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4405e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1323/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4134e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1324/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2400e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1325/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8639e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 1326/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4616e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 1327/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0131e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 1328/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0821e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 1329/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3123e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 1330/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.1590e-07 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 1331/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6299e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9935\n",
      "Epoch 1332/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5182e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 1333/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6707e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 1334/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8592e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9935\n",
      "Epoch 1335/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5492e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9935\n",
      "Epoch 1336/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5839e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 1337/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4971e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 1338/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9696e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 1339/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2992e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1340/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4513e-05 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1341/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1370e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1342/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2957e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1343/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0579e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1344/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9290e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 1345/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.6798e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1346/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7431e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1347/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7777e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9935\n",
      "Epoch 1348/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2016e-06 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9935\n",
      "Epoch 1349/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.3408e-06 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9935\n",
      "Epoch 1350/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.7672e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9935\n",
      "Epoch 1351/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8065e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
      "Epoch 1352/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.0718e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
      "Epoch 1353/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2298e-04 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1354/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4877e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1355/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2708e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1356/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3033e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 1357/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6080e-07 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 1358/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.0020e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 1359/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0135e-05 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 1360/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4111e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
      "Epoch 1361/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2327e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1362/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8380e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1363/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9571e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9935\n",
      "Epoch 1364/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0850e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 1365/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2624e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1366/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4578e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9935\n",
      "Epoch 1367/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3980e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 1368/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.7803e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1369/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6796e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1370/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8730e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1371/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4917e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1372/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8380e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1373/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1816e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1374/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7068e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1375/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4484e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1376/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.3270e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1377/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0274e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1378/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.4124e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1379/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2594e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1380/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2973e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1381/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 1.0566e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1382/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.9081e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 1383/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7712e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 1384/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6262e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1385/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9164e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1386/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4601e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1387/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.2468e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1388/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2662e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
      "Epoch 1389/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.4896e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 1390/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3612e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1391/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8949e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1392/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0873e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1393/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8212e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1394/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1383e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1395/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1932e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1396/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8238e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1397/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9337e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1398/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1219e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1399/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5864e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1400/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0020e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1401/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 8.1881e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1402/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2364e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1403/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7910e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1404/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1001e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1405/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4100e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1406/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7271e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1407/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.0849e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1408/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9454e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1409/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6603e-06 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1410/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1383e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1411/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5891e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1412/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7960e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 1413/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.4758e-07 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1414/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3081e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1415/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5687e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1416/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.6953e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1417/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6248e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1418/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2424e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1419/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7670e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1420/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9367e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1421/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1224e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1422/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9886e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1423/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.0139e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1424/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9095e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1425/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1084e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1426/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4341e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1427/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9232e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1428/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0209e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1429/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2462e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1430/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0845e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1431/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3168e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1432/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 4.2499e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1433/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.4985e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1434/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0263e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1435/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9508e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1436/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1330e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1437/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6985e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1438/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6662e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1439/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.7236e-07 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1440/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5032e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1441/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8434e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1442/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9406e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 1443/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0698e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 1444/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8517e-07 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 1445/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2463e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 1446/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.5446e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9935\n",
      "Epoch 1447/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3337e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9935\n",
      "Epoch 1448/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5483e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9935\n",
      "Epoch 1449/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6503e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9935\n",
      "Epoch 1450/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8041e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 1451/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6309e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 1452/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5213e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1453/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4114e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1454/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6762e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1455/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2848e-07 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1456/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7492e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1457/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6632e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1458/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0308e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1459/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0344e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1460/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5257e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1461/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7697e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1462/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6306e-06 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1463/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8938e-06 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 1464/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7782e-06 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9948\n",
      "Epoch 1465/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.2829e-07 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 1466/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.1401e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 1467/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3737e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 1468/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.4186e-06 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 1469/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6821e-06 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9948\n",
      "Epoch 1470/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3846e-06 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 1471/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 2.4421e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 1472/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6959e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 1473/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6735e-07 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 1474/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.1913e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 1475/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 4.8064e-05 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9948\n",
      "Epoch 1476/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.8305e-06 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9948\n",
      "Epoch 1477/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6457e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 1478/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5283e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 1479/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5029e-06 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9948\n",
      "Epoch 1480/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0694e-06 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9948\n",
      "Epoch 1481/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5626e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1482/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4152e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1483/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4264e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1484/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 1.4033e-06 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9948\n",
      "Epoch 1485/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1942e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1486/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.3479e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1487/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3333e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1488/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5044e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1489/2000\n",
      "97/97 [==============================] - 225s 2s/step - loss: 1.0871e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1490/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1283e-05 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 1491/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0528e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 1492/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7911e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9935\n",
      "Epoch 1493/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.1010e-04 - accuracy: 0.9997 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 1494/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3689e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 1495/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0544e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 1496/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2016e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9935\n",
      "Epoch 1497/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1096e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 1498/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4255e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 1499/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1398e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 1500/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9444e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1501/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7325e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1502/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5535e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 1503/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.8592e-07 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 1504/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1816e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 1505/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1596e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1506/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7026e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1507/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1468e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1508/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.7200e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1509/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3747e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1510/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.6140e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9935\n",
      "Epoch 1511/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4336e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1512/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.8941e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1513/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1407e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1514/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0500e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1515/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1699e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 1516/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.7684e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9948\n",
      "Epoch 1517/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.2379e-07 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1518/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.8055e-07 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1519/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.3723e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1520/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.5111e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1521/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.3349e-07 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1522/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3735e-06 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1523/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1497e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1524/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7134e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 1525/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 2.3722e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 1526/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4597e-07 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 1527/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0623e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 1528/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0248e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 1529/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.1779e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 1530/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 6.0836e-05 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
      "Epoch 1531/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0861e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1532/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1553e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1533/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6332e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1534/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0454e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1535/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3263e-05 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1536/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.6653e-05 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1537/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2202e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1538/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1717e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1539/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.9894e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1540/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0337e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1541/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.2475e-05 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1542/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 4.2829e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1543/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.3104e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1544/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.5338e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1545/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.1412e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 1546/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2236e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1547/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.2630e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1548/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.0132e-07 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1549/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.6592e-07 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1550/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8764e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1551/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1268e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1552/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3228e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9948\n",
      "Epoch 1553/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3967e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1554/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2904e-06 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9948\n",
      "Epoch 1555/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7937e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9948\n",
      "Epoch 1556/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.7435e-06 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1557/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9070e-06 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1558/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4595e-07 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9948\n",
      "Epoch 1559/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1560/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8219e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1561/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1328e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1562/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0587e-06 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9948\n",
      "Epoch 1563/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3618e-06 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9948\n",
      "Epoch 1564/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1854e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1565/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.5213e-07 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1566/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6505e-07 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9948\n",
      "Epoch 1567/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0003e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1568/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7623e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1569/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.9437e-07 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9948\n",
      "Epoch 1570/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0637e-06 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1571/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.2084e-07 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9948\n",
      "Epoch 1572/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0847e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1573/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2367e-06 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 1574/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9706e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9935\n",
      "Epoch 1575/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.6345e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
      "Epoch 1576/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.7157e-07 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9935\n",
      "Epoch 1577/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.9803e-07 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1578/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2328e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1579/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.4757e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 1580/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8494e-07 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
      "Epoch 1581/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.9933e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1582/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.4661e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9935\n",
      "Epoch 1583/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 7.6343e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
      "Epoch 1584/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1686e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
      "Epoch 1585/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2110e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9935\n",
      "Epoch 1586/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.7051e-07 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 1587/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7702e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 1588/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2957e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 1589/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.9427e-07 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 1590/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4834e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
      "Epoch 1591/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2544e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
      "Epoch 1592/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4457e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
      "Epoch 1593/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2205e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 1594/2000\n",
      "97/97 [==============================] - 226s 2s/step - loss: 5.9456e-07 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9935\n",
      "Epoch 1595/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3426e-06 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9935\n",
      "Epoch 1596/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4806e-06 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9935\n",
      "Epoch 1597/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8459e-07 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1598/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8307e-06 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
      "Epoch 1599/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5430e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 1600/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1170e-05 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7745e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1602/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4291e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1603/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1215e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1604/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.1275e-07 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1605/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.1141e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1606/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0452e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1607/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0936e-06 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 1608/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.1178e-07 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9935\n",
      "Epoch 1609/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4225e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 1610/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2394e-05 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9935\n",
      "Epoch 1611/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0404e-06 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9935\n",
      "Epoch 1612/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0744e-05 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9935\n",
      "Epoch 1613/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 3.4246e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9935\n",
      "Epoch 1614/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3318e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 1615/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0576e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1616/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3014e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1617/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.5027e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1618/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.7176e-07 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1619/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2128e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1620/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2918e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1621/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5655e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1622/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8440e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1623/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8993e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1624/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2491e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1625/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3385e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1626/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0780e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1627/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0441e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1628/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2547e-07 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1629/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0847e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1630/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0760e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1631/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.3644e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1632/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4931e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
      "Epoch 1633/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 9.0190e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
      "Epoch 1634/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.3930e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9935\n",
      "Epoch 1635/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0062e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1636/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.4651e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
      "Epoch 1637/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2044e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1638/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6407e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1639/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8281e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1640/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.4898e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1641/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9973e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1642/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4305e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1643/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0781e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1644/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.5302e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1645/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2945e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1646/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8667e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1647/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.2647e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1648/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0321e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1649/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1074e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1650/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4840e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1651/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0707e-07 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1652/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1586e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1653/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4850e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1654/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5651e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1655/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5375e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1656/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3811e-07 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 1657/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2275e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 1658/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1711e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 1659/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.5837e-07 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1660/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2616e-06 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 1661/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6536e-05 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1662/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5623e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1663/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5174e-06 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9948\n",
      "Epoch 1664/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2285e-06 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1665/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4276e-06 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1666/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1650e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1667/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.2185e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1668/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5884e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1669/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3079e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1670/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7555e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1671/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1186e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1672/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1619e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1673/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6814e-07 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1674/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4693e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1675/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.5321e-07 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1676/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8030e-07 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1677/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6838e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1678/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.9806e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1679/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9216e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1680/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.8739e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1681/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1997e-04 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1682/2000\n",
      "97/97 [==============================] - 224s 2s/step - loss: 1.2325e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1683/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.0529e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1684/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0102e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1685/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2730e-07 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1686/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6182e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1687/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9473e-07 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1688/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3195e-07 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1689/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2338e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1690/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7372e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1691/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.7354e-07 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1692/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0805e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1693/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3985e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1694/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3133e-07 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1695/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4248e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1696/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3343e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1697/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.9516e-07 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 1698/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3583e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1699/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.0970e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9935\n",
      "Epoch 1700/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5090e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9935\n",
      "Epoch 1701/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9449e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9935\n",
      "Epoch 1702/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7521e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9935\n",
      "Epoch 1703/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8032e-07 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1704/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8991e-07 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9935\n",
      "Epoch 1705/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9181e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9935\n",
      "Epoch 1706/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6301e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1707/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2555e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1708/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4445e-04 - accuracy: 0.9997 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1709/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.3772e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1710/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1214e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1711/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.9464e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1712/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1937e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1713/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.1829e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1714/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2285e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1715/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.1958e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1716/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4409e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1717/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8484e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1718/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0636e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1719/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.0790e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1720/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2787e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1721/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3158e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1722/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2811e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1723/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4402e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1724/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6093e-06 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9948\n",
      "Epoch 1725/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8228e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1726/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8912e-07 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1727/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0299e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1728/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0566e-05 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1729/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.8362e-07 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 1730/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.7969e-07 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1731/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8835e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1732/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1954e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1733/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0784e-07 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1734/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.8164e-07 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9948\n",
      "Epoch 1735/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2564e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1736/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.9063e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9948\n",
      "Epoch 1737/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.8067e-05 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9948\n",
      "Epoch 1738/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7885e-06 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1739/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8885e-07 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9948\n",
      "Epoch 1740/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1612e-07 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1741/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3605e-07 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 1742/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.9318e-06 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1743/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7425e-07 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1744/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2381e-07 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1745/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.7638e-05 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1746/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.9546e-07 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9948\n",
      "Epoch 1747/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3728e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9948\n",
      "Epoch 1748/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1124e-06 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9948\n",
      "Epoch 1749/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.7292e-06 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9948\n",
      "Epoch 1750/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5359e-05 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9948\n",
      "Epoch 1751/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5367e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1752/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2555e-06 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9948\n",
      "Epoch 1753/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2025e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9948\n",
      "Epoch 1754/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5551e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1755/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0339e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1756/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8612e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1757/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5841e-07 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1758/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0053e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1759/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0299e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1760/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.0781e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1761/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6231e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1762/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.5043e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1763/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.7099e-07 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1764/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9012e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1765/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.1785e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1766/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8620e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1767/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7397e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1768/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9393e-04 - accuracy: 0.9997 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 1769/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2975e-07 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9948\n",
      "Epoch 1770/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.6979e-06 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9948\n",
      "Epoch 1771/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1033e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1772/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0923e-05 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1773/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.5312e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1774/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2136e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1775/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5872e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1776/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.7051e-07 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1777/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2312e-06 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1778/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.4835e-07 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1779/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.1230e-07 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1780/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.0469e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1781/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9975e-07 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1782/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.5925e-07 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1783/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3760e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1784/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.4974e-07 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1785/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3737e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1786/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6875e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1787/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0744e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1788/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9087e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1789/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7326e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1790/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8637e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1791/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2558e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1792/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3947e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1793/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8315e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1794/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8771e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1795/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3110e-07 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1796/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1250e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1797/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3240e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1798/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7216e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1799/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4750e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1800/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5641e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9048e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1802/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.7152e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1803/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3839e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1804/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1659e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1805/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0034e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1806/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.9877e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1807/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8864e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1808/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3523e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1809/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5356e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1810/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.0274e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1811/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3410e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1812/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9529e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1813/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.5161e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1814/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2600e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1815/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7955e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1816/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.1612e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1817/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3646e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1818/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6608e-07 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1819/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0189e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1820/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0410e-06 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1821/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2649e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1822/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0956e-06 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1823/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2892e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1824/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6963e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1825/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3488e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1826/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.1817e-06 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1827/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 5.3546e-07 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1828/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0636e-05 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1829/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5779e-06 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9948\n",
      "Epoch 1830/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2809e-07 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9948\n",
      "Epoch 1831/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.3760e-07 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1832/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.3680e-07 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9948\n",
      "Epoch 1833/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8282e-06 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9948\n",
      "Epoch 1834/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0921e-06 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9948\n",
      "Epoch 1835/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 2.5365e-06 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9948\n",
      "Epoch 1836/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.5348e-07 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9948\n",
      "Epoch 1837/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 7.6254e-07 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9948\n",
      "Epoch 1838/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.2706e-07 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9948\n",
      "Epoch 1839/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4441e-04 - accuracy: 0.9997 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1840/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.4443e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1841/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.8265e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1842/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.3679e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1843/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.2230e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1844/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.0873e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1845/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6177e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1846/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0229e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1847/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0654e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1848/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2572e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1849/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.2864e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1850/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3530e-07 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1851/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0273e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1852/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3978e-06 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9948\n",
      "Epoch 1853/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.5396e-07 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9948\n",
      "Epoch 1854/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3979e-06 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9948\n",
      "Epoch 1855/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1463e-06 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9948\n",
      "Epoch 1856/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8158e-07 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9948\n",
      "Epoch 1857/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2032e-06 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9948\n",
      "Epoch 1858/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.9895e-06 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1859/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2379e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1860/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5213e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1861/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4516e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1862/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 5.3760e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1863/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 3.2635e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1864/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2639e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1865/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.7647e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1866/2000\n",
      "97/97 [==============================] - 221s 2s/step - loss: 2.9924e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1867/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2625e-05 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9948\n",
      "Epoch 1868/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4824e-07 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1869/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9882e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1870/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.5600e-07 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1871/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.6171e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1872/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.0779e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1873/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2540e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1874/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7986e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1875/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.2532e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1876/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1296e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1877/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5314e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1878/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4702e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1879/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.3449e-07 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1880/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4787e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1881/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.6924e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1882/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7024e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1883/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8233e-07 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1884/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9630e-07 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1885/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4280e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1886/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5249e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1887/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1897e-06 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1888/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.3506e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1889/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.9879e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9948\n",
      "Epoch 1890/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.9581e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1891/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.5860e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1892/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.6662e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1893/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.3399e-06 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1894/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1349e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1895/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1869e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1896/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.2882e-04 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1897/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.0520e-07 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9948\n",
      "Epoch 1898/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.9937e-06 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9948\n",
      "Epoch 1899/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.9547e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9948\n",
      "Epoch 1900/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.3043e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1901/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.8291e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1902/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6518e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1903/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.8915e-07 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1904/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4830e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1905/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3570e-07 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1906/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2582e-07 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1907/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.8910e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1908/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.1538e-07 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1909/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1548e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 1910/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6501e-06 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1911/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.6815e-07 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9948\n",
      "Epoch 1912/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.2977e-06 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9948\n",
      "Epoch 1913/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.7549e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1914/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6840e-07 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1915/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8202e-07 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1916/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1042e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1917/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.5730e-07 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9948\n",
      "Epoch 1918/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8851e-06 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9948\n",
      "Epoch 1919/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0668e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1920/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8769e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1921/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.9910e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1922/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1728e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1923/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.5691e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1924/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0460e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1925/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.3784e-07 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1926/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0473e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1927/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1365e-07 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1928/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1371e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1929/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.4835e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1930/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3844e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1931/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2642e-06 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1932/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4453e-06 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 1933/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4003e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1934/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3800e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1935/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6929e-04 - accuracy: 0.9997 - val_loss: 0.0433 - val_accuracy: 0.9948\n",
      "Epoch 1936/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.1400e-06 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1937/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4141e-05 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9948\n",
      "Epoch 1938/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4568e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1939/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.9866e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1940/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.8062e-06 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1941/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6770e-06 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1942/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.2528e-06 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9948\n",
      "Epoch 1943/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.1255e-06 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9948\n",
      "Epoch 1944/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6277e-07 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9948\n",
      "Epoch 1945/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.3379e-06 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
      "Epoch 1946/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2548e-06 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9948\n",
      "Epoch 1947/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0052e-07 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
      "Epoch 1948/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7087e-06 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9948\n",
      "Epoch 1949/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2758e-04 - accuracy: 0.9997 - val_loss: 0.0442 - val_accuracy: 0.9948\n",
      "Epoch 1950/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 6.8608e-07 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9948\n",
      "Epoch 1951/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5038e-07 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
      "Epoch 1952/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.7404e-07 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
      "Epoch 1953/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.4196e-06 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
      "Epoch 1954/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.0592e-06 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
      "Epoch 1955/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.2436e-06 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9948\n",
      "Epoch 1956/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.6433e-06 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9948\n",
      "Epoch 1957/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7227e-05 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1958/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.9797e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1959/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.9531e-06 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9948\n",
      "Epoch 1960/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.9786e-06 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9948\n",
      "Epoch 1961/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.0063e-06 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1962/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.6690e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1963/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6579e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1964/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.8962e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1965/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.7745e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1966/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.8139e-07 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9948\n",
      "Epoch 1967/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.6182e-07 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9948\n",
      "Epoch 1968/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 9.2154e-07 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9948\n",
      "Epoch 1969/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2459e-06 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9948\n",
      "Epoch 1970/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.4777e-06 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9948\n",
      "Epoch 1971/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.4976e-07 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9948\n",
      "Epoch 1972/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.3181e-06 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9948\n",
      "Epoch 1973/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.8105e-06 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9948\n",
      "Epoch 1974/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.5579e-07 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1975/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7622e-06 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9948\n",
      "Epoch 1976/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.1664e-06 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9948\n",
      "Epoch 1977/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.5104e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1978/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.6547e-06 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1979/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 3.4345e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1980/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.6650e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1981/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7234e-06 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9948\n",
      "Epoch 1982/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.9976e-07 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9948\n",
      "Epoch 1983/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3468e-07 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9948\n",
      "Epoch 1984/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.0007e-07 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9948\n",
      "Epoch 1985/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.1579e-07 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9948\n",
      "Epoch 1986/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.4712e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1987/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.3160e-06 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9948\n",
      "Epoch 1988/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 8.2980e-07 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9948\n",
      "Epoch 1989/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 7.4616e-07 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9948\n",
      "Epoch 1990/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.3632e-07 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9948\n",
      "Epoch 1991/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.7984e-06 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9948\n",
      "Epoch 1992/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 8.7305e-06 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9948\n",
      "Epoch 1993/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2103e-06 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9948\n",
      "Epoch 1994/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 5.3332e-07 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9948\n",
      "Epoch 1995/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 2.2976e-06 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9948\n",
      "Epoch 1996/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 4.9368e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9948\n",
      "Epoch 1997/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 1.2069e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1998/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.4500e-07 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9948\n",
      "Epoch 1999/2000\n",
      "97/97 [==============================] - 222s 2s/step - loss: 1.0022e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "Epoch 2000/2000\n",
      "97/97 [==============================] - 223s 2s/step - loss: 6.9861e-07 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB7\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "save_model_interval = 200\n",
    "checkpoint_filepath = path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch{epoch:04d}.pb' # -val_acc{val_accuracy:.2f}\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    period=save_model_interval,\n",
    "    save_best_only=False)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                  patience=5, min_lr=0.00001,cooldown=1, verbose=1)\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "history = model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS, callbacks=[model_checkpoint_callback,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.subplot(1, 2, 2)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 106s 2s/step - loss: 0.1706 - accuracy: 0.9621\n",
      "test_indoor_ds_results:test loss, test acc: [0.17060008645057678, 0.9620958566665649]\n"
     ]
    }
   ],
   "source": [
    "#indoor testset\n",
    "test_indoor_ds_results = model.evaluate(test_indoor_ds)\n",
    "print(\"test_indoor_ds_results:test loss, test acc:\", test_indoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 184s 2s/step - loss: 0.5050 - accuracy: 0.9296\n",
      "test_outdoor_ds_results:test loss, test acc: [0.5050317049026489, 0.9296178221702576]\n"
     ]
    }
   ],
   "source": [
    "#outdoor testset\n",
    "test_outdoor_ds_results = model.evaluate(test_outdoor_ds)\n",
    "print(\"test_outdoor_ds_results:test loss, test acc:\", test_outdoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 130s 2s/step - loss: 1.1769 - accuracy: 0.8291\n",
      "test_belt_ds_results:test loss, test acc: [1.1768527030944824, 0.8291024565696716]\n"
     ]
    }
   ],
   "source": [
    "#belt testset\n",
    "test_belt_ds_results = model.evaluate(test_belt_ds)\n",
    "print(\"test_belt_ds_results:test loss, test acc:\", test_belt_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB7/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read path of trained model\n",
    "import os, os.path\n",
    "trained_path = path_to_model\n",
    "models_paths = []\n",
    "for name_folder in os.listdir(trained_path):\n",
    "    if os.path.isdir(os.path.join(trained_path, name_folder)):\n",
    "        models_paths.append(os.path.join(trained_path, name_folder))\n",
    "models_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_144280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_212893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_137367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_142320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_236422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_137591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_261165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_232805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_237399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_245825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_247883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_142279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_245265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_245502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_243681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_136876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_238006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_142228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_249467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_245436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_138652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_252107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_257940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_256897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_233175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_142096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_246603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_138494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_260492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_255076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_139416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_206739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_249638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_239479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_236963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_141424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_144552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_145168) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_231591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_230772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_137408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_238177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_241187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_239802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_235749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_247817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_238243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_239973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_144321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_250311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_136934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_136145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_142661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_139996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_139100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_136355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_137856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_243074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_140263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_136196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_244051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_140054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_243615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_222463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_258547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_232568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_136396) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_237570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_143333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_147408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_260321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_253691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_260928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_243444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_244895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_238613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_242401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_139772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_140711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_248424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_142055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_233346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_250245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_234389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_136570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_247276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_146909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_228595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_142712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_139324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_245996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_137764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_255749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_232739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_136975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_251547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_235815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_254535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_144453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_238784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_242230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_142753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_145789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_257570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_146960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_240039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_137632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_141556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_146685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_147184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_147225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_147001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_235189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_237029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_259325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_250681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_257504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_147882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_144985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_148238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_145117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_258177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_141200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_231031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_234560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_236185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_257333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_141648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_256963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_253084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_145657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_137092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_252648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_247646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_143873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_147449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_146512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_230336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_141383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_145209) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_112194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_146105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_254469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_145881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_236792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_253928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_144720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_145616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_138212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_139599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_142529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_248490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_242837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_147566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_258718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_231525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_231354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_249097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_138039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_142977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_146553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_254298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_137184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_147617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_251870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_255142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_139823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_229428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_249704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_140528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_231961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_148065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_136529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_145433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_147133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_138436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_139375) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_230402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_250852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_144761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_145840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_138744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_147357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_229087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_243008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_256119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_240646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_246669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_144944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_241623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_144669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_241860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_143832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_139864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_255512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_239413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_252477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_256290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_259885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_241253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_236356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_138703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_138876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_250918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_234019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_254905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_240409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_147790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_253862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_139640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_241794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_143384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_255683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_253321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_137988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_140976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_145565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_251288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_233782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_244658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_251481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_259951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_230965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_142004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_146736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_141831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_228850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_258784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_229021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_144097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_146064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_141607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_143557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_242467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_146013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_229494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_141872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_144511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_258111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_248860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_237636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_259714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_138927) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_136744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_261535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_246062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_136237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_146237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_139151) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_234996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_142437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_140095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_141332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_240580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_140212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_144056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_146777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_140935) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_261099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_139548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_140752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_248253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_140660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_143781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_137316) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_241016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_244829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_259391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_256726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_139192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_143649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_142488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_140884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_232198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_143109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_148106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_252714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_141780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_233412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_147841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_144005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_229882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_238850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_246432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_141108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_144229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_141159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_143160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_143608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_142936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_137143) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_138304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_244288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_145392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_235578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_148014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_138968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_146461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_247039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_234626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_253255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_259154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_244222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_136703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_229948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_143201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_144893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_250074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_142885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_137815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_143425) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_146288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_138080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_232132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_138535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_233953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_138263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_239220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_140487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_252041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_145341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_140304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_249031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_260558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_146329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_247210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_235255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_256356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_140436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_147658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 106s 2s/step - loss: 0.1304 - accuracy: 0.9610\n",
      "99/99 [==============================] - 181s 2s/step - loss: 0.4139 - accuracy: 0.9185\n",
      "69/69 [==============================] - 127s 2s/step - loss: 0.9209 - accuracy: 0.8255\n",
      "Epoch200 \n",
      " test_indoor_acc=0.9609810709953308 \n",
      " test_outdoor_acc=0.9184713363647461 \n",
      " test_belt_acc=0.8254759907722473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_364814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_458617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_360525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_360749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_359237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_454459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_462088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_464640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_468718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_470078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_361421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_472942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_363154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_358565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_363877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_479572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_456043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_474763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_360265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_452426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_474156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_362930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_464033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_477191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_361197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_357901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_359909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_457839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_459831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_356964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_361645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_462259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_424776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_465247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_355129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_471121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_470751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_460438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_465076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_461652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_361686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_361370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_357137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_469907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_360474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_354233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_361146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_474327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_362093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_468282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_364590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_471965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_359685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_451383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_475370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_466290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_356572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_476821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_362706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_356117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_456821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_363470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_355353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_360316) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_430930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_357585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_451990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_477428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_467134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_465920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_477751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_357361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_476148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_358972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_472506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_473786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_464469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_453615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_365878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_359196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_478529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_365919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_360133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_452056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_357636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_354182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_361594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_366275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_363653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_362757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_358132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_457257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_456280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_477922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_440500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_460874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_359593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_357677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_364325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_449068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_366143) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_469584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_358033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_361014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_357860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_451449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_359461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_362042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_447919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_454829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_468111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_360973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_476214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_478595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_356781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_468955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_461111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_456887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_455000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_360922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_475000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_449391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_450169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_472572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_358473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_363826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_356913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_459290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_354433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_470144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_359868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_450776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_355445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_451212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_360698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_361462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_361818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_364101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_357229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_362266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_466461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_476755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_446887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_448373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_457450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_364997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_465313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_358697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_365486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_356473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_354971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_356689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_360357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_358249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_361869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_449628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_360790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_466897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_356025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_365695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_467068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_361910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_473113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_355404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_355180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_454393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_447985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_355628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_364722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_363429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_471292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_356249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_359420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_354274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_457516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_465683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_453226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_453786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_359145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_365603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_471899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_464099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_362798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_456214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_362490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_363378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_450235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_459660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_447465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_473179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_449002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_364946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_364549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_475607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_357412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_453852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_474393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_330231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_361238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_366102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_448809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_470514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_460267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_365221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_474934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_465854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_455066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_467741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_458683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_455607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_365394) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_473720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_453292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_357809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_463539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_358524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_479136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_362358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_358789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_469518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_364142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_466527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_358748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_354781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_458076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_363022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_356740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_461718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_461481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_362134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_357188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_365170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_460504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_447124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_471728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_449998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_362589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_479202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_455673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_462325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_364366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_364498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_354607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_359644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_355852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_467504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_472335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_356341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_462932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_452663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_475541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_363205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_354913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_476584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_458010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_365654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_450605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_359013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_365262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_473549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_459897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_448439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_463862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_356300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_354740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_358921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_363602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_464706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_362317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_469325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_355801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_459224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_358341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_357005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_354392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_359369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_452597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_462695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_355221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_454222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_477988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_366051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_357453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_463302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_458446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_358300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_451819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_359817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_468889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_478965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_471358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_360092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_462866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_362548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_365445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_356531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_447058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_362981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_459053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_478358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_355577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_461045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_355893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_477362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_364050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_365038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_364773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_446632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_453033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_363694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_456650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_470685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_450842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_365827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_360566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_360041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_363918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_358091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_355012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_468348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_364274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_355669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_449562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_475977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_447531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_354566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_467675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_455436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_356076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_463473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_363246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 111s 2s/step - loss: 0.1258 - accuracy: 0.9660\n",
      "99/99 [==============================] - 181s 2s/step - loss: 0.4340 - accuracy: 0.9220\n",
      "69/69 [==============================] - 127s 2s/step - loss: 0.9609 - accuracy: 0.8237\n",
      "Epoch400 \n",
      " test_indoor_acc=0.9659977555274963 \n",
      " test_outdoor_acc=0.9219745397567749 \n",
      " test_belt_acc=0.8236627578735352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_693644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_572270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_693037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_687944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_686148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_581955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_678475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_677327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_666846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_576734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_680969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_575042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_572644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_688722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_575225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_580626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_577457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_692971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_693407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_580743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_696395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_580835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_668272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_684327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_642813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_667599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_665161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_582087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_572950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_578353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_577498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_665502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_579458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_577182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_579407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_685778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_572219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_580794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_668879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_578827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_668035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_579947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_574818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_576785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_584312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_573166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_683891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_573390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_581059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_691216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_690609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_669486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_576958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_691757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_680125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_680903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_577050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_689395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_580130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_575673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_583207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_684934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_679148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_581415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_576169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_692193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_690002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_676483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_697002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_667039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_582138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_670093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_671329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_673710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_574568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_575001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_687621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_576337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_573930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_583864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_574609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_693578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_578511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_672430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_673644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_577681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_669420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_584139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_665095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_682136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_581690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_577905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_691823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_580079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_679082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_577854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_670463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_575266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_583732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_673037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_691586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_685171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_580967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_582627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_575938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_577274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_668813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_580354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_577630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_579010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_573838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_671823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_573665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_674924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_689158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_674317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_582759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_575897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_681339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_676047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_671889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_696566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_573441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_691150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_668642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_583915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_675876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_573482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_579275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_694014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_679689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_578394) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_582535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_681576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_689329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_579723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_574062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_582362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_574378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_581863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_679518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_579906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_692800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_575714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_677934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_573706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_668206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_665956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_579631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_679755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_577722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_670700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_583956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_685541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_682070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_673473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_577406) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_676654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_579682) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_697609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_680296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_579183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_583034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_575174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_675487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_576510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_574154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_671070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_666022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_574286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_695788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_695399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_583691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_573258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_579855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_678304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_583482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_582311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_674687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_685712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_678911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_671652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_581914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_683350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_673103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_578302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_578603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_582179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_583523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_670027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_575622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_575449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_572470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_581639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_694251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_579051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_689765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_577946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_677868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_677697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_695959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_686319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_583299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_573049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_680362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_579234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_696025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_574777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_684564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_677261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_580585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_581507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_582403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_686385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_667428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_582983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_675553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_666410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_582810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_576286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_665568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_578170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_694858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_697173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_666476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_580303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_576826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_683957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_573008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_677090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_669249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_576602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_576378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_674080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_574337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_580171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_697239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_578959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_686755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_690979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_583075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_581731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_576128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_687362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_692364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_684498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_572818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_676720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_672496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_548268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_672259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_584088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_688181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_573217) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_688551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_686926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_580527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_681510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_683113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_583258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_577233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_577009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_574950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_572777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_681899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_678541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_672866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_574113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_581466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_669856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_582586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_581191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_658537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_578562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_667105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_680732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_683720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_583640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_694621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_584180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_671263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_682743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_667665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_689936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_695228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_676113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_573614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_692430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_582851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_573889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_685105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_581242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_576561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_575398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_664924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_674858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_648967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_581283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_583431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_696632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_572603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_694792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_690372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_690543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_682506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_694185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_575490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_682677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_580395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_670634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_581018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_683284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_578129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_579499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_575846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_695465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_674251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_687555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_664669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_574510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_574726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_572429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_578786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_686992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_688115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_578078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_675294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_572311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_576070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_578735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_688788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 106s 2s/step - loss: 0.1389 - accuracy: 0.9627\n",
      "99/99 [==============================] - 179s 2s/step - loss: 0.4294 - accuracy: 0.9277\n",
      "69/69 [==============================] - 125s 2s/step - loss: 1.0015 - accuracy: 0.8250\n",
      "Epoch600 \n",
      " test_indoor_acc=0.9626532793045044 \n",
      " test_outdoor_acc=0.9277070164680481 \n",
      " test_belt_acc=0.8250226378440857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_891727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_801092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_797964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_910447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_796095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_884427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_794578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_794751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_792171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_886052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_790794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_793415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_796844) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_798811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_795026) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_889906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_791183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_798760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_800196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_889346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_797424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_909840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_797699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_893893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_883112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_898986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_795739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_910817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_895951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_795647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_792743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_793283) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_799259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_801499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_906805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_910381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_897165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_798984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_907412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_799748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_790661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_793914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_886223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_796752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_798188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_895714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_892941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_799524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_792585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_893570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_790620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_796803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_797648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_892334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_796579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_800155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_905638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_913482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_791407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_908996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_799035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_909603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_794843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_906198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_904336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_894130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_901974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_915019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_860830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_885122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_909233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_797923) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_793690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_796528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_790287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_907953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_793639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_799300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_797872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_888651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_801051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_795922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_795515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_792794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_912809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_897535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_876554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_894064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_886659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_791275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_796319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_792527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_890276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_791855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_906568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_883519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_886830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_793466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_895107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_791499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_801973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_889840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_800420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_913805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_894671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_790967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_799707) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_896492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_890513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_888480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_915256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_792835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_794527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_902344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_883973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_892704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_794395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_797292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_897706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_791631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_795250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_887437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_902951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_898920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_801932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_797068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_791723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_908560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_904165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_887266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_796976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_791947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_795871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_910988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_902581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_896928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_900087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_905379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_898313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_892097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_802156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_887503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_794975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_892875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_901367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_796411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_885445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_890883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_798147) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_796187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_899356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_887873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_891120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_790487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_800603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_866984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_906132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_798320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_903122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_901908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_800328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_794145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_802197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_905572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_791682) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_790328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_911595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_898379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_909774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_915190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_797251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_801657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_801224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_913976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_792626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_896558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_801448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_791458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_895885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_889280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_890447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_900153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_904772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_910210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_794186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_912202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_793242) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_901737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_800827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_796620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_911054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_800776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_793018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_793059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_792354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_895344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_899527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_798544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_795698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_899916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_885056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_797516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_799208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_894737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_908389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_798096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_790236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_884039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_801708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_797475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_799880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_800868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_915626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_911661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_912031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_793191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_894500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_912638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_912875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_790835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_900694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_802329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_801316) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_795067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_903795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_904402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_795474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_888044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_793731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_800104) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_793507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_800552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_797027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_795199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_883585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_913416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_907782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_888110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_790446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_895278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_792130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_902515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_799076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_799432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_889669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_799931) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_884863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_908019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_897772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_903729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_904943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_797740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_901130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_795423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_794354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_798371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_903558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_899593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_914583) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_893504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_901301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_912268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_884493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_794087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_801749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_801881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_791025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_802105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_798602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_800644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_797200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_905961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_891054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_907175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_891661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_882686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_906739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_794303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_886896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_914412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_793863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_900760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_791066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_907346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_914649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_911424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_793955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_792395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_799972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_792967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_889087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_905009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_799483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_898749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_791234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_900523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_885682) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_799656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_903188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_800379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_801275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_794619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_795291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_885616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_908626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_897099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_801000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_891490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_886289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_796370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_893311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_883178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_898142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_798412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_909167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_766285) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_791906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_792079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_798643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_913245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_798852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_892268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_888717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_896321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_796146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_801540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_795963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_792303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_794802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_882941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_914042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 106s 2s/step - loss: 0.1470 - accuracy: 0.9615\n",
      "99/99 [==============================] - 179s 2s/step - loss: 0.4523 - accuracy: 0.9261\n",
      "69/69 [==============================] - 126s 2s/step - loss: 1.0310 - accuracy: 0.8264\n",
      "Epoch800 \n",
      " test_indoor_acc=0.9615384340286255 \n",
      " test_outdoor_acc=0.9261146783828735 \n",
      " test_belt_acc=0.826382577419281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1128854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1122202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1112167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1009719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1100723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1012564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1012182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1103482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1017296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1122439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1015736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1112537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1115136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1105910) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1009062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1016225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1008324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1013104) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1017520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1020234) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1016449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1124842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1009103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1129091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1124776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1110978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1011452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1112708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1012391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1010208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1115743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1017245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1116957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1013776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1114529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1131842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1015237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1130675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1104933) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1014657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1129632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1101622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1019969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1116179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1016889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1125212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1130068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1110741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1116416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1012223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1119167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1014407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1017072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1010872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1105540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1126426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1012432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1106688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1115809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1123609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1019485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1102010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1112101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1117564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1012124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1017561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1014183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1104326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1121159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1020366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1010116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1013236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1127877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1122373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1117023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1019577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1118731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1124169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1126056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1013287) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1123046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1114358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1016797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1106517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1121766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1110912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1106081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1013328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1010432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1014356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_984322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1018905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1133056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1019037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1122980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1113751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1125383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1015512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1100978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1017693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1009444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1011727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1115202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1015105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1101215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1018864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1127270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1013012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1117393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1010564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1122809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1020010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1121832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1018192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1108313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1102530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1016184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1120552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1128418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1019261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1015013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1012839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1120618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1131519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1107383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1011004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1011055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1094591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1112774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1101149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1012656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1015553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1011676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1121595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1015064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1116350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1113144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1011900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1009271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1113922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1107706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1020193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1009220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1116786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1125449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1019786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1113988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1108484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1110134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1125990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1019745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1104089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1010391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1124235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1103093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1013959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1109764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1111930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1131453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1011279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1114595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1017968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1013460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1018365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1123998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1014616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1009760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1132620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1120988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1011951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1129025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1109527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1107124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1013063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1124605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1009943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1018233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1102464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1019918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1018813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1102076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1117953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1020142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1133227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1109698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1130846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1008524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1128484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1016581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1105303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1017113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1109157) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1107317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1016357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1118124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1103719) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1110305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1133293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1017337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1113315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1126597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1127204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1018416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1078867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1008273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1085021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1019353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1127811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1011503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1014840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1017744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1011228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1107943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1014881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1104867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1123416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1108920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1119945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1107877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1102900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1127640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1009892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1016848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1015461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1019694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1009536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1130239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1120011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1016133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1015777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1130305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1011544) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1014448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1129461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1017021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1019312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1017469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1016680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1101556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1018681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1013735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1012340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1108550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1014789) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1118560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1132013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1008365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1016408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1110371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1130912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1009312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1011096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1129698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1012880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1010831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1018009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1119338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1014565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1118190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1008698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1009984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1125819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1008483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1017917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1014000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1117630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1015685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1013552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1105474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1133663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1016001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1010663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1012788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1109091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1018640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1018589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1019129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1014132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1014224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1018141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1011992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1015288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1120381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1008831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1132449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1010340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1104260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1010780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1126663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1010622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1113381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1010167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1119404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1132686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1103653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1009495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1106147) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1127033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1118797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1008872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1012615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1019088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1111348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1015960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1106754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1011320) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1011768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1103159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1128247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1119774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1114965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1015329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1013511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1131282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1104696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1132079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1019536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1015909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1115572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1121225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1016639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1018457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1013908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1013684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1111607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1111541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1009668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1008657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1009004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1123675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1017785) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 107s 2s/step - loss: 0.1480 - accuracy: 0.9643\n",
      "99/99 [==============================] - 181s 2s/step - loss: 0.4525 - accuracy: 0.9261\n",
      "69/69 [==============================] - 129s 2s/step - loss: 1.0649 - accuracy: 0.8268\n",
      "Epoch1000 \n",
      " test_indoor_acc=0.9643255472183228 \n",
      " test_outdoor_acc=0.9261146783828735 \n",
      " test_belt_acc=0.8268359303474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1337441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1324554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1228245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1233325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1339025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1233773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1341083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1237955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1228817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1344027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1348949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1328408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1234885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1341453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1231548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1325743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1234394) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1234676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1344093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1232602) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1346284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1343856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1227929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1233946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1237573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1346521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1229316) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1231141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1333609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1335060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1234038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1232826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1326587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1237125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1236718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1333239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1321756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1321690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1228377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1232485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1340476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1234170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1339196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1229041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1324725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1330204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1228153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1332395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1342272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1235954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1350657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1235282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1235109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1351330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1235150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1343249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1234618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1227349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1348342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1322970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1347669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1228868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1335430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1227573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1237823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1230825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1326521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1344634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1229713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1334453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1230219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1348712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1335990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1329578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1228601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1233498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1227308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1332566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1226310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1227041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1229265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1227481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1230260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1329967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1330574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1231324) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1228659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1296904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1325354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1233142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1324118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1232918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1226361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1232444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1351700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1338655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1348276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1345914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1236626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1237731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1338589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1236494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1234262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1230161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1319659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1336768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1347128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1228021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1233814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1330138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1337982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1344463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1238006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1328949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1342813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1234926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1333173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1341646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1322297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1318760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1350050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1235333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1236901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1237782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1229937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1345307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1339262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1322733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1342035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1338418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1233590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1230917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1226561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1337811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1312628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1338048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1323340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1235598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1349556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1228909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1333846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1227980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1349319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1235557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1229581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1336227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1228428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1230693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1202359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1325161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1341017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1320937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1330745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1229357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1333780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1232877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1233101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1234221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1226868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1233549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1335667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1234445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1319252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1236942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1231945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1339803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1350486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1321196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1236270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1321519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1345070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1319186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1323947) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1233997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1228469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1230876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1329015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1231497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1232393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1329644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1227532) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1334387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1232037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1327564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1231365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1348105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1231996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1328778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1322126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1303058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1232261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1226694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1234486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1228204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1234834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1327194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1346455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1236005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1345677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1235781) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1326957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1347062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1232653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1339869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1236178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1340239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1329385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1321130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1334994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1236402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1227705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1232220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1233366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1237074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1238403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1231813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1331959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1327801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1229092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1226520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1351093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1349490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1228700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1229489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1230652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1342206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1347498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1334216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1336597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1238179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1351264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1349879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1331352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1233050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1236850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1337204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1331181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1339632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1341712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1342879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1336834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1237349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1230377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1320113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1233722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1229805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1236453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1238047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1227099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1238271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1324184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1328171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1345848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1335601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1343486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1322904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1235822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1226402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1231721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1333002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1343420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1324791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1319015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1320501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1325914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1230029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1332632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1227797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1236677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1320047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1330811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1350723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1231772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1235506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1237614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1236046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1233274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1322363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1327735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1237522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1236229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1227140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1232169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1328342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1337375) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1347735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1342642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1231100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1323511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1230428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1340410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1229764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1325420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1231589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1232694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1327128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1336161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1230601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1227756) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1231049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1331418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1235058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1237390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1235730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1340846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1332025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1226909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1227257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1226735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1334823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1229133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1235374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1231273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1331788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1346891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1234717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1237166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1229540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1325980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1320567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1344700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1323577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1237298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1350116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1348883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1238230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1230469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1345241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1319593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1229988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1326350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 119s 2s/step - loss: 0.1567 - accuracy: 0.9627\n",
      "99/99 [==============================] - 184s 2s/step - loss: 0.4690 - accuracy: 0.9280\n",
      "69/69 [==============================] - 129s 2s/step - loss: 1.1112 - accuracy: 0.8241\n",
      "Epoch1200 \n",
      " test_indoor_acc=0.9626532793045044 \n",
      " test_outdoor_acc=0.928025484085083 \n",
      " test_belt_acc=0.824116051197052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1558513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1540770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1456308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1559120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1561286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1453767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1450731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1444398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1444772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1452299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1451403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1565099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1562064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1557906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1557840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1548004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1546986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1564928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1454938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1548848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1452207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1556692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1447302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1556626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1521095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1446414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1456084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1446017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1538604) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1542762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1562671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1537696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1568523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1546815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1451983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1455992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1564558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1541984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1445966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1454531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1453146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1452963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1545772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1544387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1566920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1449982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1449850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1448198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1543391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1453594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1562130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1514941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1449626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1448862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1551210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1449178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1451311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1446854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1541007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1455203) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1554198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1444347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1551646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1565165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1452922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1564321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1559749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1451535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1569367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1420396) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1558883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1447577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1451362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1555848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1445569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1544994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1547422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1455386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1455651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1456043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1563885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1453095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1553097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1560850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1539233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1545231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1543780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1450206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1566749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1568087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1451627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1452871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1562737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1447842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1447078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1554264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1548611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1449809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1559054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1568694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1448730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1544624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1555412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1552253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1451179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1454714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1540941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1448465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1445834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1546445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1447750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1563951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1544017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1445078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1446946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1449310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1454979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1450481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1565706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1445793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1553704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1550062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1541377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1563107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1543198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1452754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1565772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1448025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1453187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1551039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1569301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1558276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1569130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1556019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1454215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1549455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1546379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1446241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1542155) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1550603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1555241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1559683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1551817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1453543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1455768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1456267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1557299) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1450257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1537630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1445177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1447618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1539167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1548782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1448297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1446465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1545838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1553031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1567356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1558447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1446737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1455610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1446905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1448256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1448414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1445386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1565535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1537223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1450430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1456216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1449086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1450690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1447170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1444598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1563714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1557233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1545601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1560916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1538150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1549996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1447974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1450955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1557062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1455860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1450863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1452713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1446190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1560243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1546208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1452258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1543457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1555478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1453411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1454439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1547681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1444905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1549389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1450033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1566379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1451851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1446282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1542221) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1445294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1445518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1449402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1455427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1451586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1542591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1449137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1452075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1454307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1446506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1551276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1445345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1543951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1445742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1450298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1454663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1447129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1452034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1560679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1450639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1538084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1536797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1449361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1452655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1550669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1444731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1554805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1549218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1452431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1568153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1556085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1566313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1539556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1454490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1451810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1449758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1563344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1544558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1446696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1541548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1539793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1560072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1455162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1455111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1447801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1547052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1550432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1454042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1444439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1557669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1542828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1566986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1453319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1456440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1450914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1545165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1447526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1451138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1567916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1553467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1563278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1566142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1446058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1552490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1454755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1554871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1567527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1554027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1554634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1448066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1561457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1448638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1447394) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1449534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1530665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1444946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1452523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1455559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1562500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1445610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1453818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1561523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1548241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1548175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1540163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1568760) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1444557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1450074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1560309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1455335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1447353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1553638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1541614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1453859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1449585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1540334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1559490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1539727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1561893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1569737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1551883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1451087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1567593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1538974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1547615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1453370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1552424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1556455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1537289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1452482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1448689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1448506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1538538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1446638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1552860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1454266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1450522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1455819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1454887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1537052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1453991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1448954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1445136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1540400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1453635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1454083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1451759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1549825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1448913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1564492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 109s 2s/step - loss: 0.1652 - accuracy: 0.9615\n",
      "99/99 [==============================] - 184s 2s/step - loss: 0.4738 - accuracy: 0.9283\n",
      "69/69 [==============================] - 129s 2s/step - loss: 1.1484 - accuracy: 0.8264\n",
      "Epoch1400 \n",
      " test_indoor_acc=0.9615384340286255 \n",
      " test_outdoor_acc=0.9283439517021179 \n",
      " test_belt_acc=0.826382577419281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1778953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1670112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1663779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1665655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1760192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1668559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1672792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1666726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1673856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1785023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1664733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1668951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1764416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1673372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1669175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1672527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1764852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1672079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1783136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1662635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1663871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1777091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1667887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1666293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1671896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1760628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1664451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1774122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1763202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1664227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1662435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1669888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1669572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1781315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1760865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1732978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1771741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1672120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1670560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1758807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1782529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1666899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1665879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1780101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1674304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1787338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1674345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1671000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1663331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1786731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1775706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1757593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1761817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1667398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1754834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1774729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1779560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1673596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1770897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1780167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1756121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1673897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1769683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1672252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1777527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1668727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1774492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1669124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1665614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1755260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1663173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1781751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1665166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1671183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1672568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1666103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1739132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1784786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1668900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1762661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1664319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1667795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1787404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1671132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1759651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1782358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1673148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1757764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1786124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1781381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1670336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1758978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1672700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1763809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1673805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1763268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1768033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1762054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1777720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1672476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1663647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1674253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1786560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1778716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1670519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1778887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1761494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1668992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1760258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1780537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1778346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1770461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1767492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1664095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1672975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1667846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1760799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1662476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1772671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1766885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1665339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1668243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1673240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1670020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1785953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1755667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1759044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1768640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1758437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1665115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1666543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1666011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1670692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1668335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1761428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1671804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1672751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1667174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1670468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1673647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1762424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1664942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1780774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1781144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1757830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1670244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1670908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1777786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1667571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1662809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1778109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1670295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1776484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1759585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1666675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1673423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1755733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1668294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1763638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1669623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1786190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1664278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1771134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1759414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1771675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1665563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1769076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1769247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1663382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1755326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1672344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1670959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1775336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1669348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1662983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1662768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1671407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1663830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1674029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1784957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1768469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1783809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1666767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1664983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1766041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1775270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1768706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1668467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1666950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1784416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1772064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1673688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1761235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1769313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1667439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1664543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1763875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1776550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1784179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1784350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1781988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1783572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1776920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1668070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1664502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1671448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1673199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1769854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1665838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1673464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1757204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1669664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1772908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1756641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1767426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1783743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1638433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1766819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1668518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1766212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1756575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1668676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1765023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1671855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1663115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1782965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1775877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1773449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1673016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1671672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1670750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1674080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1773278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1669399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1772235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1669216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1665207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1755089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1756187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1668111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1773515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1786797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1672924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1769920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1785393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1662942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1771504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1764245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1760021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1778280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1774056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1748702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1672028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1671356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1674121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1770527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1767255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1763031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1779930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1669440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1787167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1666334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1783202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1766648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1765718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1765652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1764482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1777157) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1664891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1781922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1779323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1662594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1772301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1674477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1665431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1669847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1664675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1773885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1775943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1767862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1779494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1666235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1662384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1762595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1664054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1775099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1757270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1671224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1670071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1665787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1765089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1671631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1785630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1787774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1771068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1782595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1666451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1757011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1663423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1663606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1785564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1663555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1765459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1667663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1761988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1670791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1668768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1666991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1666062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1766278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1672303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1664003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1667622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1667215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1772842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1780708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1669796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1770290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1774663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1776313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1663214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1664774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1758371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1758200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1768099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1666502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1667347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1665390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1668019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1667123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1671580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 109s 2s/step - loss: 0.1472 - accuracy: 0.9660\n",
      "99/99 [==============================] - 183s 2s/step - loss: 0.4945 - accuracy: 0.9293\n",
      "69/69 [==============================] - 129s 2s/step - loss: 1.1395 - accuracy: 0.8273\n",
      "Epoch1600 \n",
      " test_indoor_acc=0.9659977555274963 \n",
      " test_outdoor_acc=0.9292993545532227 \n",
      " test_belt_acc=0.8272892236709595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1979272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1887701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1993373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1888787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_2005204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1890381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1883203) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1890605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1889261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1981305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1983060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1984685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1997597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1884712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1892514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1993743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1886988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1881251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1884048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1992700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1991315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1976237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1976844) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1888996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1892290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1972871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1978295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1973297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1984078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1887833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1883824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1881592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1998138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_2003430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1974678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1978836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1888057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1887161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1880805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1890289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1983126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1986743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1891842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1889393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1980698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1883916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1885211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1997967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1888332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1886713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1891893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1890513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1889617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1889169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1988498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1891460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_2000566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1891409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1976474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1996753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1882712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1981846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1987957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1888505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_2001173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1886107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_2002216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1881419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1986506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1974224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_2001780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1892117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1889485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1881816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1885608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1989105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1985463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1883020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1979531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1983755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1882770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1885659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1888597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1998574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1978058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1987284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1982519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1882488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1880846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1995564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1978665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1882580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_2000395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1984922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1885700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1881460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1981675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_2001239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_2004161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1882091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1891934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1888556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_2004597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1999959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1882356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1995757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1990101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1880979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_2004227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1887660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1881020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1999181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_2001609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1993136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1996924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1982453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1887884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1882539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1884330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1856470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1880472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1886504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1993980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1977081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1886555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_2005441) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1989541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1889933) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1995128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1966739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1890737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1975241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_2005375) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1974158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1975048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1981068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1890564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1884140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1890065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1973770) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1886372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1890829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1989712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1881643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1890116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1880513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_2002387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1983689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1980091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1981239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1892158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1883651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_2000025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1881684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1982889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1892066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1889709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1987891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1884272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1886937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1886148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1885028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1975801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1891053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1883692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1886596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1983496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1887253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1973126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1987113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1993307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1883152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1890961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1986070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1887609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1977015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1989171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1987720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1884099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1996317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1994521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1883376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1988934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1991922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1974612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1884539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1883875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1887385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1980461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1994587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1979854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1889892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1951015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1978229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1979465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1985292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1891236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1884804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1888373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1889444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1882928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1999788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1996990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1994957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1887212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1888945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_2002823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1885252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1992159) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1882132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1892341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1990879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1990708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1997531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1884488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1888108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1982282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1881908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1890157) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1880631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1990338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_2002994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1998204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1889841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1973704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1883244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1986136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1999418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1886056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1883468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_2003990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_2004834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1996383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_2003060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1891277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1884987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1891012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1881210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1990945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1892382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1973363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1886280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1889037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1975307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1976408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1884936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1975630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1884371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1980632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_2001846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1888149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_2003601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1885384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1984315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1880421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1888281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1995823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1885924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1989778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1999352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1884580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1887925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1975867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1985529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1881152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_2000632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1992766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1891501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1891684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1888729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_2004768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1886331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1997360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1988327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1998745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1882315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1885476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1889668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1996146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_2002453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1882264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1993914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1881867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1977451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1886805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1882979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1981912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1890340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1988564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1987350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1891633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1887477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1885160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1978902) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1994350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1888828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1995194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1992093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1889220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1986677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1886764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1882811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_2003667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1990272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1985899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1885435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1891185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1884763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1980025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_2001002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1883427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1977688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1887436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1992529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1881368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1885883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1880672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1957169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1984249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1882040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1890788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1885832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_2005811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1977622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1887029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1891725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1991486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1998811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1991552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1883600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1984856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 125s 2s/step - loss: 0.1687 - accuracy: 0.9632\n",
      "99/99 [==============================] - 184s 2s/step - loss: 0.4869 - accuracy: 0.9299\n",
      "69/69 [==============================] - 129s 2s/step - loss: 1.1657 - accuracy: 0.8273\n",
      "Epoch1800 \n",
      " test_indoor_acc=0.9632107019424438 \n",
      " test_outdoor_acc=0.9299362897872925 \n",
      " test_belt_acc=0.8272892236709595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_2099288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_2107481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_2101505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_2101637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_2200926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_2107257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_2098709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_2100301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_2202352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_2210566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_2219646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_2208745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_2219883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_2107970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_2211951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_2108601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_2202959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_2109222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_2101240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_2101281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_2099904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_2223848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_2103065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_2198498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_2220253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_2197568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_2205928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_2104801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_2211344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_2194445) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_2100749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_2108194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_2223241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_2214790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_2102408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_2201163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_2203329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_2108642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_2101861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_2219276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_2210196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_2109538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_2107298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_2103421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_2221097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_2106186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_2193667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_2212017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_2222027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_2199342) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_2100169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_2100807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_2219210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_2106634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_2106318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_2098883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_2102617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_2197891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_2109971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_2218432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_2205757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_2104409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_2205321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_2107522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_2207815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_2110551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_2105473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_2098550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_2211780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_2200319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_2099016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_2110195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_2206535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_2101953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_2102576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_2209959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_2103472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_2106766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_2201097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_2099680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_2104842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_2105738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_2100576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_2192649) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_2110154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_2191163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_2100128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_2101413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_2205150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_2109670) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_2217389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_2109762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_2109930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_2190908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_2210737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_2074507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_2102367) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_2100617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_2105198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_2214420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_2216611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_2212994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_2109879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_2107654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_2198128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_2196095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_2204780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_2216782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_2208138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_2104541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_2215634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_2107929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_2108377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_2195052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_2107878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_2102309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_2109721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_2103920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_2212387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_2109497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_2107074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_2103289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_2106824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_2107705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_2203566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_2100848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_2107033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_2194274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_2101057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_2102177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_2104974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_2110327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_2217996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_2215397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_2201533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_2216241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_2108825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_2102841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_2101189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_2100393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_2201726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_2211410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_2196939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_2106865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_2110378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_2197502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_2195488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_2214961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_2102973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_2106542) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_2101688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_2103024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_2221638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_2103869) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_2212624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_2202722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_2107430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_2098458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_2099629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_2105025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_2193085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_2204107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_2175206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_2192261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_2102085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_2203936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_2099247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_2105646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_2212558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_2195659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_2206364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_2204714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_2208375) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_2194511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_2205994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_2207142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_2199105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_2102800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_2103513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_2110103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_2198669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_2099945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_2207749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_2106145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_2206601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_2108550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_2198735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_2106982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_2198062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_2192195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_2213794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_2222634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_2199712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_2194881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_2214183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_2108153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_2196873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_2104750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_2099405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_2222805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_2109273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_2101016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_2193344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_2106593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_2102749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_2098509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_2202893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_2109049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_2108998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_2104185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_2201792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_2191807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_2222264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_2104144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_2196332) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_2195725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_2108326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_2100525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_2223478) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_2108418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_2105422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_2196266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_2099057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_2200490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_2109314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_2217455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_2211173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_2219039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_2106369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_2205387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_2107206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_2104368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_2206971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_2215027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_2195118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_2199883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_2105290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_2098842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_2104592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_2196702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_2099189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_2191334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_2213231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_2207208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_2102136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_2202286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_2103737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_2103197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_2107746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_2193838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_2193904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_2105870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_2184776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_2204173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_2218669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_2100077) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_2099853) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_2199949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_2108102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_2210803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_2213860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_2099497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_2106410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_2220424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_2213165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_2169052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_2214354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_2222871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_2219817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_2216848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_2104317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_2216004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_2193278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_2101729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_2108774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_2209523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_2192715) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_2106094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_2098668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_2208982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_2223412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_2105514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_2208916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_2109090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_2207578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_2218603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_2104633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_2110419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_2218062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_2105921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_2102525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_2216175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_2100965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_2197309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_2217218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_2213601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_2103645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_2101464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_2199276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_2105066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_2220490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_2222198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_2103696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_2202115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_2101912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_2108866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_2109446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_2191400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_2221704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_2103961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_2209352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_2103248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_2203500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_2221031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_2099721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_2208309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_2220860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_2104093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_2215568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_2209589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_2100352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_2221467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_2105962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_2217825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_2099456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_2105249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_2204543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_2191741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_2105697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_2210130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_2200556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 110s 2s/step - loss: 0.1706 - accuracy: 0.9621\n",
      "99/99 [==============================] - 184s 2s/step - loss: 0.5050 - accuracy: 0.9296\n",
      "69/69 [==============================] - 129s 2s/step - loss: 1.1769 - accuracy: 0.8291\n",
      "Epoch2000 \n",
      " test_indoor_acc=0.9620958566665649 \n",
      " test_outdoor_acc=0.9296178221702576 \n",
      " test_belt_acc=0.8291024565696716\n"
     ]
    }
   ],
   "source": [
    "test_indoor_acc = []\n",
    "test_outdoor_acc = []\n",
    "test_belt_acc = []\n",
    "test_indoor_loss = []\n",
    "test_outdoor_loss = []\n",
    "test_belt_loss = []\n",
    "\n",
    "for lm_idx,plmodel in enumerate(models_paths):\n",
    "    loaded_model=tf.keras.models.load_model(plmodel)\n",
    "    ## -> keep loss / acc in each epoch\n",
    "    #indoor\n",
    "    test_indoor_results = loaded_model.evaluate(test_indoor_ds)\n",
    "    test_indoor_loss.append(test_indoor_results[0]) # append loss\n",
    "    test_indoor_acc.append(test_indoor_results[1]) # append acc\n",
    "    #outdoor\n",
    "    test_outdoor_results = loaded_model.evaluate(test_outdoor_ds)\n",
    "    test_outdoor_loss.append(test_outdoor_results[0]) # append loss\n",
    "    test_outdoor_acc.append(test_outdoor_results[1]) # append acc\n",
    "    #belt\n",
    "    test_belt_results = loaded_model.evaluate(test_belt_ds)\n",
    "    test_belt_loss.append(test_belt_results[0]) # append loss\n",
    "    test_belt_acc.append(test_belt_results[1]) # append acc\n",
    "    # printout\n",
    "    lm_idx_show = (lm_idx+1) * save_model_interval\n",
    "    print(f\"Epoch{lm_idx_show:03d} \\n test_indoor_acc={test_indoor_acc[lm_idx]} \\n test_outdoor_acc={test_outdoor_acc[lm_idx]} \\n test_belt_acc={test_belt_acc[lm_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "test_avg_acc = []\n",
    "for i in range(len(test_indoor_acc)):\n",
    "    tmp_avg = (test_indoor_acc[i] + test_outdoor_acc[i] + test_belt_acc[i]) / 3.0\n",
    "    test_avg_acc.append(tmp_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(200, 2200, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Testing(EvaluationModel) Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss / acc in each epoch graph ploting\n",
    "#EPOCHS = 400\n",
    "import matplotlib.pyplot as plt\n",
    "epochs_range = range(save_model_interval,EPOCHS+save_model_interval,save_model_interval)\n",
    "print(epochs_range)\n",
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, test_indoor_acc, label='IndoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_outdoor_acc, label='OutdoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_belt_acc, label='OnConveyorBeltDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_avg_acc, label='Average Tesing Accuracy',linewidth=3)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Testing(EvaluationModel) Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max acc -> 0.9075287779172262\n",
      "max index -> 7\n",
      "The [Epoch] of max acc -> 1600\n"
     ]
    }
   ],
   "source": [
    "#Find Max Index and Value\n",
    "print(f\"max acc -> {max(test_avg_acc)}\")\n",
    "max_index = test_avg_acc.index(max(test_avg_acc))\n",
    "print(f\"max index -> {max_index}\")\n",
    "print(f\"The [Epoch] of max acc -> {(max_index+1)*save_model_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, test_indoor_loss, label='IndoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_outdoor_loss, label='OutdoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_belt_loss, label='OnConveyorBeltDS Tesing Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Testing(EvaluationModel) Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9609810709953308,\n",
       " 0.9659977555274963,\n",
       " 0.9626532793045044,\n",
       " 0.9615384340286255,\n",
       " 0.9643255472183228,\n",
       " 0.9626532793045044,\n",
       " 0.9615384340286255,\n",
       " 0.9659977555274963,\n",
       " 0.9632107019424438,\n",
       " 0.9620958566665649]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9184713363647461,\n",
       " 0.9219745397567749,\n",
       " 0.9277070164680481,\n",
       " 0.9261146783828735,\n",
       " 0.9261146783828735,\n",
       " 0.928025484085083,\n",
       " 0.9283439517021179,\n",
       " 0.9292993545532227,\n",
       " 0.9299362897872925,\n",
       " 0.9296178221702576]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8254759907722473,\n",
       " 0.8236627578735352,\n",
       " 0.8250226378440857,\n",
       " 0.826382577419281,\n",
       " 0.8268359303474426,\n",
       " 0.824116051197052,\n",
       " 0.826382577419281,\n",
       " 0.8272892236709595,\n",
       " 0.8272892236709595,\n",
       " 0.8291024565696716]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1304190754890442,\n",
       " 0.12579086422920227,\n",
       " 0.13893462717533112,\n",
       " 0.14701977372169495,\n",
       " 0.14799119532108307,\n",
       " 0.1567154824733734,\n",
       " 0.1651608794927597,\n",
       " 0.14721105992794037,\n",
       " 0.1686922311782837,\n",
       " 0.17060008645057678]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4139007329940796,\n",
       " 0.43400096893310547,\n",
       " 0.4294317662715912,\n",
       " 0.45225271582603455,\n",
       " 0.45249947905540466,\n",
       " 0.46896377205848694,\n",
       " 0.47378382086753845,\n",
       " 0.4945491850376129,\n",
       " 0.4869449734687805,\n",
       " 0.5050317049026489]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.920891284942627,\n",
       " 0.9609311819076538,\n",
       " 1.0014827251434326,\n",
       " 1.030958652496338,\n",
       " 1.0649118423461914,\n",
       " 1.1111806631088257,\n",
       " 1.1483875513076782,\n",
       " 1.1394944190979004,\n",
       " 1.1657131910324097,\n",
       " 1.1768527030944824]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Last Epoch and test in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del dataset memory and reload\n",
    "# RAM\n",
    "del train_ds\n",
    "del val_ds\n",
    "del test_indoor_ds\n",
    "del test_outdoor_ds\n",
    "del test_belt_ds\n",
    "# VRAM\n",
    "#from numba import cuda\n",
    "#cuda.select_device(0)\n",
    "#cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1778953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1670112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1663779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1665655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1760192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1668559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1672792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1666726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1673856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1785023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1664733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1668951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1764416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1673372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1669175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1672527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1764852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1672079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1783136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1662635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1663871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1777091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1667887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1666293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1671896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1760628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_expand_activation_layer_call_and_return_conditional_losses_1664451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1774122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1763202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1664227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1662435) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1669888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1669572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1781315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1760865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1732978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1771741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1672120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1670560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1758807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1782529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1666899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1665879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1780101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1674304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_activation_layer_call_and_return_conditional_losses_1787338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1674345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1671000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1663331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1786731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1775706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1757593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1761817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1667398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1754834) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1774729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1779560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1673596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1770897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1780167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1756121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1673897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1769683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1672252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1777527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1668727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1774492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1669124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1665614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1755260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1663173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1781751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1665166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1671183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1672568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1666103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1739132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_expand_activation_layer_call_and_return_conditional_losses_1784786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1668900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1762661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1664319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1667795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_se_reduce_layer_call_and_return_conditional_losses_1787404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1671132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1759651) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1782358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1673148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1757764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1786124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1781381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1670336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1758978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1672700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1763809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1673805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1763268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1768033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1762054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1777720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1672476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1663647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1674253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1786560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1778716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_activation_layer_call_and_return_conditional_losses_1670519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1778887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1761494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1668992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1760258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1780537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1778346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1770461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1767492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1664095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1672975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1667846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1760799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1662476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1772671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1766885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1665339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_expand_activation_layer_call_and_return_conditional_losses_1668243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1673240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1670020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1785953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1755667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1759044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1768640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1758437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1665115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1666543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_expand_activation_layer_call_and_return_conditional_losses_1666011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1670692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1668335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1761428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1671804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1672751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1667174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1670468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1673647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1762424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1664942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1780774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1781144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1757830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1670244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1670908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1777786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1667571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1662809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1778109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1670295) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_activation_layer_call_and_return_conditional_losses_1776484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1759585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1666675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1673423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1755733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1668294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1763638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1669623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1786190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1664278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_se_reduce_layer_call_and_return_conditional_losses_1771134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1759414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1771675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1665563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1769076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1769247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1663382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1755326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1672344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1670959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1775336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1669348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1662983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1662768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1671407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1663830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1674029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_activation_layer_call_and_return_conditional_losses_1784957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1768469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1783809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1666767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1664983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1766041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1775270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1768706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1668467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1666950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_se_reduce_layer_call_and_return_conditional_losses_1784416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1772064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1673688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1761235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1769313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1667439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_se_reduce_layer_call_and_return_conditional_losses_1664543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1763875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_se_reduce_layer_call_and_return_conditional_losses_1776550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_expand_activation_layer_call_and_return_conditional_losses_1784179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1784350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1781988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1783572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_expand_activation_layer_call_and_return_conditional_losses_1776920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_activation_layer_call_and_return_conditional_losses_1668070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2g_activation_layer_call_and_return_conditional_losses_1664502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1671448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6l_activation_layer_call_and_return_conditional_losses_1673199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1769854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1665838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6m_se_reduce_layer_call_and_return_conditional_losses_1673464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1757204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1669664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1772908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_se_reduce_layer_call_and_return_conditional_losses_1756641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1767426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1783743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1638433) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1766819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1668518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1766212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1756575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1668676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1765023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1671855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1663115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1782965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1775877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1773449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1673016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1671672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1670750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1674080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1773278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1669399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1772235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1669216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1665207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1755089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1756187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1668111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1773515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1786797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1672924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1769920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1785393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1d_activation_layer_call_and_return_conditional_losses_1662942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1771504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1764245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1760021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1778280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1774056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1748702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1672028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1671356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1674121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_se_reduce_layer_call_and_return_conditional_losses_1770527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1767255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1763031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1779930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1669440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7d_expand_activation_layer_call_and_return_conditional_losses_1787167) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1666334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1783202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1766648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1765718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1765652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1764482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5j_se_reduce_layer_call_and_return_conditional_losses_1777157) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1664891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1781922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1779323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1662594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1772301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1674477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1665431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1669847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1664675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1773885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1775943) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1767862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1779494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1666235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1662384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1762595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1664054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1775099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1757270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1671224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1670071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1665787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_se_reduce_layer_call_and_return_conditional_losses_1765089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1671631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1785630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1787774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4j_activation_layer_call_and_return_conditional_losses_1771068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1782595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1666451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1757011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1663423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1663606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1785564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1663555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1765459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1667663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1761988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1670791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1668768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1666991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3g_activation_layer_call_and_return_conditional_losses_1666062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1766278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1672303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1664003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1667622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1667215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1772842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1780708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1669796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1770290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1774663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5i_expand_activation_layer_call_and_return_conditional_losses_1776313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1663214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1664774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1758371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1758200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1768099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1666502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1667347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1665390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4i_expand_activation_layer_call_and_return_conditional_losses_1668019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1667123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1671580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1794 files belonging to 4 classes.\n",
      "Found 3140 files belonging to 4 classes.\n",
      "Found 2206 files belonging to 4 classes.\n",
      "train_indoor num x,y : 1794,1794\n",
      "train_outdoor num x,y : 3140,3140\n",
      "train_belt num x,y : 2206,2206\n",
      "all num x,y :7140,7140\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "last_epoch_model = tf.keras.models.load_model(path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb')\n",
    "\n",
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/belt'\n",
    "\n",
    "img_height=600\n",
    "img_width=600\n",
    "batch_size=1\n",
    "\n",
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "  layers.RandomZoom(height_factor=0.1),\n",
    "  layers.RandomContrast(0.05),\n",
    "])\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  #ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)\n",
    "\n",
    "class_names = ['1-InfectionWaste', '2-BloodSecretionWaste', '3-LabWardWaste', '4-VaccineOtherWaste']\n",
    "\n",
    "N = 500\n",
    "\n",
    "x_test_indoor = np.concatenate([ x for x,y in test_indoor_ds],axis=0)\n",
    "y_test_indoor = np.concatenate([ y for x,y in test_indoor_ds],axis=0)\n",
    "print(f\"train_indoor num x,y : {len(x_test_indoor)},{len(y_test_indoor)} are predicting\")\n",
    "x_indoor_sets = np.array_split(x_test_indoor, N)\n",
    "del x_test_indoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_indoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_indoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_indoor_sets,test_indoor_ds\n",
    "\n",
    "x_test_outdoor = np.concatenate([ x for x,y in test_outdoor_ds],axis=0)\n",
    "y_test_outdoor = np.concatenate([ y for x,y in test_outdoor_ds],axis=0)\n",
    "print(f\"train_outdoor num x,y : {len(x_test_outdoor)},{len(y_test_outdoor)} are predicting\")\n",
    "x_outdoor_sets = np.array_split(x_test_outdoor, N)\n",
    "del x_test_outdoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_outdoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_outdoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_outdoor_sets,test_outdoor_ds\n",
    "\n",
    "x_test_belt = np.concatenate([ x for x,y in test_belt_ds],axis=0)\n",
    "y_test_belt = np.concatenate([ y for x,y in test_belt_ds],axis=0)\n",
    "print(f\"train_belt num x,y : {len(x_test_belt)},{len(y_test_belt)} are predicting\")\n",
    "x_belt_sets = np.array_split(x_test_belt, N)\n",
    "del x_test_belt\n",
    "y_all_sets_predicted = []\n",
    "for x in x_belt_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_belt_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_belt_sets,test_belt_ds\n",
    "\n",
    "y_all = np.concatenate([y_test_indoor,y_test_outdoor,y_test_belt],axis=0)\n",
    "y_all_predicted = np.concatenate([y_indoor_predicted,y_outdoor_predicted,y_belt_predicted],axis=0)\n",
    "print(f\"all num x,y :{len(y_all_predicted)},{len(y_all)}\")\n",
    "\n",
    "#del x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all=7140\n",
      "TP=6476\n",
      "FP=664\n",
      "acc=0.9070028011204482\n",
      "all check = 7140\n"
     ]
    }
   ],
   "source": [
    "y_all_predicted_max = np.array([],dtype=np.int)\n",
    "# acc all\n",
    "TP = 0\n",
    "FP = 0\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP = TP + 1\n",
    "    else :\n",
    "        FP = FP + 1\n",
    "    y_all_predicted_max=np.append(y_all_predicted_max,np.argmax(y_all_predicted[i]))\n",
    "print(f'all={TP+FP}')\n",
    "print(f'TP={TP}')\n",
    "print(f'FP={FP}')\n",
    "print(f'acc={TP/(TP+FP)}')\n",
    "\n",
    "# acc eachclass\n",
    "TP_eachclass = [0] * 41\n",
    "FP_eachclass = [0] * 41\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP_eachclass[y_all[i]] = TP_eachclass[y_all[i]] + 1\n",
    "    else :\n",
    "        FP_eachclass[y_all[i]] = FP_eachclass[y_all[i]] + 1\n",
    "#recheck\n",
    "print(f'all check = {sum(TP_eachclass)+sum(FP_eachclass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-InfectionWaste acc = 90.75804776739356%\n",
      "2-BloodSecretionWaste acc = 84.8414985590778%\n",
      "3-LabWardWaste acc = 93.27354260089686%\n",
      "4-VaccineOtherWaste acc = 93.78794955628211%\n",
      "\n",
      "\n",
      "\n",
      "all_avg_eachclass = 90.6652596209126%\n"
     ]
    }
   ],
   "source": [
    "avg_acc_eachclass = []\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]} acc = {TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100}%')\n",
    "    avg_acc_eachclass.append(TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100)\n",
    "all_avg_eachclass = sum(avg_acc_eachclass) / len(avg_acc_eachclass)\n",
    "print(f'\\n\\n\\nall_avg_eachclass = {all_avg_eachclass}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1748,  151,    8,   19],\n",
       "       [ 186, 1472,   37,   40],\n",
       "       [  19,   46, 1248,   25],\n",
       "       [   8,   91,   34, 2008]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# for using scikit-learn's built-in metrics\n",
    "from sklearn.metrics import *\n",
    "# for using tesnorflow/keras' built-in metrics\n",
    "import tensorflow.keras.backend as K\n",
    "''' ndarray of shape (n_classes, n_classes)\n",
    "Confusion matrix whose i-th row and j-th column entry indicates the number of samples with  {true label being i-th row class} and {predicted label being column j-th class}.\n",
    "> Example\n",
    ">>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    ">>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    ">>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    "พุดง่ายๆ แถวคือด้านความจริง\n",
    "       หลักคือด้านที่ระบบทำนาย\n",
    "'''\n",
    "# \n",
    "confusionMat = confusion_matrix(y_all, y_all_predicted_max, labels=range(len(class_names)))\n",
    "confusionMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90.75804777,  7.84008307,  0.41536864,  0.98650052],\n",
       "       [10.7204611 , 84.84149856,  2.13256484,  2.3054755 ],\n",
       "       [ 1.4200299 ,  3.43796712, 93.2735426 ,  1.86846039],\n",
       "       [ 0.37365717,  4.2503503 ,  1.58804297, 93.78794956]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatFloat = confusionMat.astype('float64')\n",
    "confusionMatFloatPercent=confusionMatFloat/confusionMatFloat.sum(axis=1)[:,None]  # divided by number of sample in each class (sum of each row)\n",
    "confusionMatFloatPercent*=100\n",
    "confusionMatFloatPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMat, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (14,14))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMatFloatPercent, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (14,14))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\".2f\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
