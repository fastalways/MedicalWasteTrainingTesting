{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteCropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset_path='D:/DatasetMedicalWasteCroppedBalanced/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Set DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/belt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=528\n",
    "img_width=528\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 files belonging to 4 classes.\n",
      "Using 3095 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-InfectionWaste', '2-BloodSecretionWaste', '3-LabWardWaste', '4-VaccineOtherWaste']\n",
      "number of class = 4\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_number = len(class_names)\n",
    "print(class_names)\n",
    "print(f'number of class = {class_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 files belonging to 4 classes.\n",
      "Using 773 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dataset_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1794 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3140 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2206 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"vertical\"),\n",
    "  layers.RandomRotation(0.100),\n",
    "  layers.RandomZoom(height_factor=0.025,width_factor=0.025),\n",
    "  #layers.RandomContrast(0.300),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  # ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 528, 528, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "# Test -> Fetching Mini Batch\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:-1]: # this is where I changed your code\n",
    "    model.add(layer)    \n",
    "\n",
    "# Freeze the layers \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add 'softmax' instead of earlier 'prediction' layer.\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input,EfficientNetB6\n",
    "\n",
    "efficientnetB0_model = keras.applications.EfficientNetB6(input_shape=(img_height,img_width,3),include_top=True,weights=\"imagenet\",classifier_activation=\"softmax\")\n",
    "\n",
    "efficientnetB0_model_nooutput = efficientnetB0_model.layers[-3].output\n",
    "custom_efficientnetB0_model = Model(inputs = efficientnetB0_model.input, outputs = efficientnetB0_model_nooutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freez Extractor+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 528, 528, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_1 (Rescaling)         (None, 528, 528, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 528, 528, 3)  7           rescaling_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 529, 529, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 264, 264, 56) 1512        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 264, 264, 56) 224         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 264, 264, 56) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 264, 264, 56) 504         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 264, 264, 56) 224         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 264, 264, 56) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 56)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 56)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 14)     798         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 56)     840         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 264, 264, 56) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 264, 264, 32) 1792        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 264, 264, 32) 128         block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 264, 264, 32) 288         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 264, 264, 32) 128         block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 264, 264, 32) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 264, 264, 32) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 264, 264, 32) 1024        block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 264, 264, 32) 128         block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 264, 264, 32) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 264, 264, 32) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 264, 264, 32) 288         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 264, 264, 32) 128         block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 264, 264, 32) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 32)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 264, 264, 32) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 264, 264, 32) 1024        block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 264, 264, 32) 128         block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (Dropout)          (None, 264, 264, 32) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 264, 264, 32) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 264, 264, 192 6144        block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 264, 264, 192 768         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 264, 264, 192 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 265, 265, 192 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 132, 132, 192 1728        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 132, 132, 192 768         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 132, 132, 192 0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 192)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 132, 132, 192 0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 132, 132, 40) 7680        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 132, 132, 40) 160         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 132, 132, 240 9600        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 132, 132, 240 960         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 132, 132, 240 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 132, 132, 240 2160        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 132, 132, 240 960         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 132, 132, 240 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 240)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 132, 132, 240 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 132, 132, 40) 9600        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 132, 132, 40) 160         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 132, 132, 40) 0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 132, 132, 40) 0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 132, 132, 240 9600        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 132, 132, 240 960         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 132, 132, 240 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 132, 132, 240 2160        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 132, 132, 240 960         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 132, 132, 240 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 240)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 132, 132, 240 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 132, 132, 40) 9600        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 132, 132, 40) 160         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 132, 132, 40) 0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 132, 132, 40) 0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 132, 132, 240 9600        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 132, 132, 240 960         block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 132, 132, 240 0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 132, 132, 240 2160        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 132, 132, 240 960         block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 132, 132, 240 0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 240)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 132, 132, 240 0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 132, 132, 40) 9600        block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 132, 132, 40) 160         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (Dropout)          (None, 132, 132, 40) 0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 132, 132, 40) 0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 132, 132, 240 9600        block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 132, 132, 240 960         block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 132, 132, 240 0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 132, 132, 240 2160        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 132, 132, 240 960         block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 132, 132, 240 0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 240)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 132, 132, 240 0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 132, 132, 40) 9600        block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 132, 132, 40) 160         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (Dropout)          (None, 132, 132, 40) 0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 132, 132, 40) 0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_conv (Conv2D)    (None, 132, 132, 240 9600        block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_bn (BatchNormali (None, 132, 132, 240 960         block2f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_activation (Acti (None, 132, 132, 240 0           block2f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_dwconv (DepthwiseConv2D (None, 132, 132, 240 2160        block2f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2f_bn (BatchNormalization) (None, 132, 132, 240 960         block2f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2f_activation (Activation) (None, 132, 132, 240 0           block2f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_squeeze (GlobalAvera (None, 240)          0           block2f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_excite (Multiply)    (None, 132, 132, 240 0           block2f_activation[0][0]         \n",
      "                                                                 block2f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_conv (Conv2D)   (None, 132, 132, 40) 9600        block2f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_bn (BatchNormal (None, 132, 132, 40) 160         block2f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2f_drop (Dropout)          (None, 132, 132, 40) 0           block2f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_add (Add)               (None, 132, 132, 40) 0           block2f_drop[0][0]               \n",
      "                                                                 block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 132, 132, 240 9600        block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 132, 132, 240 960         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 132, 132, 240 0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 135, 135, 240 0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 66, 66, 240)  6000        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 66, 66, 240)  960         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 66, 66, 240)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 240)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 66, 66, 240)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 66, 66, 72)   17280       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 66, 66, 72)   288         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 66, 66, 432)  31104       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 66, 66, 432)  1728        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 66, 66, 432)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 66, 66, 432)  10800       block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 66, 66, 432)  1728        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 66, 66, 432)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 432)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 432)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 18)     7794        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 432)    8208        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 66, 66, 432)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 66, 66, 72)   31104       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 66, 66, 72)   288         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 66, 66, 72)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 66, 66, 72)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 66, 66, 432)  31104       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 66, 66, 432)  1728        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 66, 66, 432)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 66, 66, 432)  10800       block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 66, 66, 432)  1728        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 66, 66, 432)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 432)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 432)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 18)     7794        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 432)    8208        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 66, 66, 432)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 66, 66, 72)   31104       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 66, 66, 72)   288         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 66, 66, 72)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 66, 66, 72)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 66, 66, 432)  31104       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 66, 66, 432)  1728        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 66, 66, 432)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 66, 66, 432)  10800       block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 66, 66, 432)  1728        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 66, 66, 432)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 432)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 432)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 18)     7794        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 432)    8208        block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 66, 66, 432)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 66, 66, 72)   31104       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 66, 66, 72)   288         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (Dropout)          (None, 66, 66, 72)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 66, 66, 72)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 66, 66, 432)  31104       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 66, 66, 432)  1728        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 66, 66, 432)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 66, 66, 432)  10800       block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 66, 66, 432)  1728        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 66, 66, 432)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 432)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 432)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 18)     7794        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 432)    8208        block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 66, 66, 432)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 66, 66, 72)   31104       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 66, 66, 72)   288         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (Dropout)          (None, 66, 66, 72)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 66, 66, 72)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_conv (Conv2D)    (None, 66, 66, 432)  31104       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_bn (BatchNormali (None, 66, 66, 432)  1728        block3f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_activation (Acti (None, 66, 66, 432)  0           block3f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_dwconv (DepthwiseConv2D (None, 66, 66, 432)  10800       block3f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3f_bn (BatchNormalization) (None, 66, 66, 432)  1728        block3f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3f_activation (Activation) (None, 66, 66, 432)  0           block3f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_squeeze (GlobalAvera (None, 432)          0           block3f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reshape (Reshape)    (None, 1, 1, 432)    0           block3f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reduce (Conv2D)      (None, 1, 1, 18)     7794        block3f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_expand (Conv2D)      (None, 1, 1, 432)    8208        block3f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_excite (Multiply)    (None, 66, 66, 432)  0           block3f_activation[0][0]         \n",
      "                                                                 block3f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_conv (Conv2D)   (None, 66, 66, 72)   31104       block3f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_bn (BatchNormal (None, 66, 66, 72)   288         block3f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3f_drop (Dropout)          (None, 66, 66, 72)   0           block3f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_add (Add)               (None, 66, 66, 72)   0           block3f_drop[0][0]               \n",
      "                                                                 block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 66, 66, 432)  31104       block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 66, 66, 432)  1728        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 66, 66, 432)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 67, 67, 432)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 33, 33, 432)  3888        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 33, 33, 432)  1728        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 33, 33, 432)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 432)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 432)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 18)     7794        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 432)    8208        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 33, 33, 432)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 33, 33, 144)  62208       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 33, 33, 144)  576         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 33, 33, 864)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 33, 33, 864)  7776        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 33, 33, 864)  3456        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 33, 33, 864)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 864)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 864)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 33, 33, 864)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 33, 33, 144)  124416      block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 33, 33, 144)  576         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 33, 33, 144)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 33, 33, 144)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 33, 33, 864)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 33, 33, 864)  7776        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 33, 33, 864)  3456        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 33, 33, 864)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 864)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 864)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 33, 33, 864)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 33, 33, 144)  124416      block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 33, 33, 144)  576         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 33, 33, 144)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 33, 33, 144)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 33, 33, 864)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 33, 33, 864)  7776        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 33, 33, 864)  3456        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 33, 33, 864)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 864)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 864)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 33, 33, 864)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 33, 33, 144)  124416      block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 33, 33, 144)  576         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 33, 33, 144)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 33, 33, 144)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 33, 33, 864)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 33, 33, 864)  7776        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 33, 33, 864)  3456        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 33, 33, 864)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 864)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 864)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 33, 33, 864)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 33, 33, 144)  124416      block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 33, 33, 144)  576         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 33, 33, 144)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 33, 33, 144)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 33, 33, 864)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 33, 33, 864)  7776        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 33, 33, 864)  3456        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 33, 33, 864)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 864)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 864)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 33, 33, 864)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 33, 33, 144)  124416      block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 33, 33, 144)  576         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (Dropout)          (None, 33, 33, 144)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 33, 33, 144)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 33, 33, 864)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 33, 33, 864)  7776        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 33, 33, 864)  3456        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 33, 33, 864)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 864)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 864)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 33, 33, 864)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 33, 33, 144)  124416      block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 33, 33, 144)  576         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (Dropout)          (None, 33, 33, 144)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 33, 33, 144)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block4h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_activation (Acti (None, 33, 33, 864)  0           block4h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_dwconv (DepthwiseConv2D (None, 33, 33, 864)  7776        block4h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4h_bn (BatchNormalization) (None, 33, 33, 864)  3456        block4h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4h_activation (Activation) (None, 33, 33, 864)  0           block4h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_squeeze (GlobalAvera (None, 864)          0           block4h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reshape (Reshape)    (None, 1, 1, 864)    0           block4h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block4h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block4h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_excite (Multiply)    (None, 33, 33, 864)  0           block4h_activation[0][0]         \n",
      "                                                                 block4h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_conv (Conv2D)   (None, 33, 33, 144)  124416      block4h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_bn (BatchNormal (None, 33, 33, 144)  576         block4h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4h_drop (Dropout)          (None, 33, 33, 144)  0           block4h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_add (Add)               (None, 33, 33, 144)  0           block4h_drop[0][0]               \n",
      "                                                                 block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 33, 33, 864)  124416      block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 33, 33, 864)  3456        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 33, 33, 864)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 33, 33, 864)  21600       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 33, 33, 864)  3456        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 33, 33, 864)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 864)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 864)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 36)     31140       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 864)    31968       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 33, 33, 864)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 33, 33, 200)  172800      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 33, 33, 200)  800         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 33, 33, 1200) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 33, 33, 1200) 30000       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 33, 33, 1200) 4800        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 33, 33, 1200) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1200)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 33, 33, 1200) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 33, 33, 200)  240000      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 33, 33, 200)  800         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 33, 33, 200)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 33, 33, 200)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 33, 33, 1200) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 33, 33, 1200) 30000       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 33, 33, 1200) 4800        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 33, 33, 1200) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1200)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 33, 33, 1200) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 33, 33, 200)  240000      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 33, 33, 200)  800         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 33, 33, 200)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 33, 33, 200)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 33, 33, 1200) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 33, 33, 1200) 30000       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 33, 33, 1200) 4800        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 33, 33, 1200) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1200)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 33, 33, 1200) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 33, 33, 200)  240000      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 33, 33, 200)  800         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 33, 33, 200)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 33, 33, 200)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 33, 33, 1200) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 33, 33, 1200) 30000       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 33, 33, 1200) 4800        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 33, 33, 1200) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1200)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 33, 33, 1200) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 33, 33, 200)  240000      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 33, 33, 200)  800         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 33, 33, 200)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 33, 33, 200)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 33, 33, 1200) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 33, 33, 1200) 30000       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 33, 33, 1200) 4800        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 33, 33, 1200) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1200)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 33, 33, 1200) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 33, 33, 200)  240000      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 33, 33, 200)  800         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (Dropout)          (None, 33, 33, 200)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 33, 33, 200)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 33, 33, 1200) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 33, 33, 1200) 30000       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 33, 33, 1200) 4800        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 33, 33, 1200) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1200)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 33, 33, 1200) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 33, 33, 200)  240000      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 33, 33, 200)  800         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (Dropout)          (None, 33, 33, 200)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 33, 33, 200)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block5h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_activation (Acti (None, 33, 33, 1200) 0           block5h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_dwconv (DepthwiseConv2D (None, 33, 33, 1200) 30000       block5h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5h_bn (BatchNormalization) (None, 33, 33, 1200) 4800        block5h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5h_activation (Activation) (None, 33, 33, 1200) 0           block5h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_squeeze (GlobalAvera (None, 1200)         0           block5h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block5h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block5h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block5h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_excite (Multiply)    (None, 33, 33, 1200) 0           block5h_activation[0][0]         \n",
      "                                                                 block5h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_conv (Conv2D)   (None, 33, 33, 200)  240000      block5h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_bn (BatchNormal (None, 33, 33, 200)  800         block5h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5h_drop (Dropout)          (None, 33, 33, 200)  0           block5h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_add (Add)               (None, 33, 33, 200)  0           block5h_drop[0][0]               \n",
      "                                                                 block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 33, 33, 1200) 240000      block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 33, 33, 1200) 4800        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 33, 33, 1200) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 37, 37, 1200) 0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 17, 17, 1200) 30000       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 17, 17, 1200) 4800        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 17, 17, 1200) 0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1200)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1200)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 50)     60050       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1200)   61200       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 17, 17, 1200) 0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 17, 17, 344)  412800      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 17, 17, 2064) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 17, 17, 2064) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 2064)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 17, 17, 344)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 17, 17, 344)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 17, 17, 2064) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 17, 17, 2064) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 2064)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 17, 17, 344)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 17, 17, 344)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 17, 17, 2064) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 17, 17, 2064) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 2064)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 17, 17, 344)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 17, 17, 344)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 17, 17, 2064) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 17, 17, 2064) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 2064)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 17, 17, 344)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 17, 17, 344)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 17, 17, 2064) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 17, 17, 2064) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 2064)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 17, 17, 344)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 17, 17, 344)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 17, 17, 2064) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 17, 17, 2064) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 2064)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (Dropout)          (None, 17, 17, 344)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 17, 17, 344)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 17, 17, 2064) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 17, 17, 2064) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 2064)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (Dropout)          (None, 17, 17, 344)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 17, 17, 344)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 17, 17, 2064) 0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 17, 17, 2064) 0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 2064)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (Dropout)          (None, 17, 17, 344)  0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 17, 17, 344)  0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_activation (Acti (None, 17, 17, 2064) 0           block6j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6j_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6j_activation (Activation) (None, 17, 17, 2064) 0           block6j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_squeeze (GlobalAvera (None, 2064)         0           block6j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6j_activation[0][0]         \n",
      "                                                                 block6j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6j_drop (Dropout)          (None, 17, 17, 344)  0           block6j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_add (Add)               (None, 17, 17, 344)  0           block6j_drop[0][0]               \n",
      "                                                                 block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block6k_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_activation (Acti (None, 17, 17, 2064) 0           block6k_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 51600       block6k_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6k_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block6k_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6k_activation (Activation) (None, 17, 17, 2064) 0           block6k_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_squeeze (GlobalAvera (None, 2064)         0           block6k_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block6k_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block6k_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block6k_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_excite (Multiply)    (None, 17, 17, 2064) 0           block6k_activation[0][0]         \n",
      "                                                                 block6k_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_conv (Conv2D)   (None, 17, 17, 344)  710016      block6k_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_bn (BatchNormal (None, 17, 17, 344)  1376        block6k_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6k_drop (Dropout)          (None, 17, 17, 344)  0           block6k_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_add (Add)               (None, 17, 17, 344)  0           block6k_drop[0][0]               \n",
      "                                                                 block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 17, 17, 2064) 710016      block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 17, 17, 2064) 8256        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 17, 17, 2064) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 17, 17, 2064) 18576       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 17, 17, 2064) 8256        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 17, 17, 2064) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 2064)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 2064)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 86)     177590      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 2064)   179568      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 17, 17, 2064) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 17, 17, 576)  1188864     block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 17, 17, 576)  2304        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 17, 17, 3456) 1990656     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 17, 17, 3456) 13824       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 17, 17, 3456) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 17, 17, 3456) 31104       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 17, 17, 3456) 13824       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 17, 17, 3456) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3456)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3456)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 144)    497808      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3456)   501120      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 17, 17, 3456) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 17, 17, 576)  1990656     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 17, 17, 576)  2304        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 17, 17, 576)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 17, 17, 576)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 17, 17, 3456) 1990656     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 17, 17, 3456) 13824       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 17, 17, 3456) 0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 17, 17, 3456) 31104       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 17, 17, 3456) 13824       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 17, 17, 3456) 0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3456)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3456)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 144)    497808      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3456)   501120      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 17, 17, 3456) 0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 17, 17, 576)  1990656     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 17, 17, 576)  2304        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (Dropout)          (None, 17, 17, 576)  0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 17, 17, 576)  0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 17, 17, 2304) 1327104     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 17, 17, 2304) 9216        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 17, 17, 2304) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2304)         0           top_activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 40,960,143\n",
      "Trainable params: 0\n",
      "Non-trainable params: 40,960,143\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "custom_efficientnetB0_model.trainable = False\n",
    "for layer in custom_efficientnetB0_model.layers:\n",
    "    layer.trainable = False\n",
    "## Freez\n",
    "#custom_inceptionv3_model.layers[-1].trainable = True\n",
    "#custom_inceptionv3_model.layers[-2].trainable = True\n",
    "#custom_inceptionv3_model.layers[-3].trainable = True\n",
    "print(custom_efficientnetB0_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(custom_efficientnetB0_model, to_file=\"InceptionRemoveOutput.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Feature Extractor\n",
    "model.add(custom_efficientnetB0_model)\n",
    "# Classifier\n",
    "#DeepDense\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(len(class_names), activation='softmax', trainable=True))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 2304)              40960143  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 43,324,563\n",
      "Trainable params: 2,364,420\n",
      "Non-trainable params: 40,960,143\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = ['1WayConnectorforFoley', '2WayConnectorforFoley', '2WayFoleyCatheter', '3WayConnectorforFoley', '3Waystopcock', 'AlcoholBottle', 'AlcoholPad', 'BootCover', 'CottonBall', 'CottonSwap', 'Dilator', 'DisposableInfusionSet', 'ExtensionTube', 'FaceShield', 'FrontLoadSyringe', 'GauzePad', 'Glove', 'GuideWire', 'LiquidBottle', 'Mask', 'NGTube', 'NasalCannula', 'Needle', 'OxygenMask', 'PPESuit', 'PharmaceuticalProduct', 'Pill', 'PillBottle', 'PrefilledHumidifier', 'PressureConnectingTube', 'ReusableHumidifier', 'SodiumChlorideBag', 'SterileHumidifierAdapter', 'SurgicalBlade', 'SurgicalCap', 'SurgicalSuit', 'Syringe', 'TrachealTube', 'UrineBag', 'Vaccinebottle', 'WingedInfusionSet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[-1]._name = 'Classifier'\n",
    "#model.layers[-2]._name = 'InceptionV3'\n",
    "#print(len(model.layers))\n",
    "#tf.keras.utils.plot_model(model, to_file=\"Incepv3_FreezExtractorOurOutputLayer.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = 'D:/ModelMedicalWasteCheckpoint/4G_EfficientNetB6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/2000\n",
      "49/49 [==============================] - 185s 3s/step - loss: 0.2832 - accuracy: 0.8937 - val_loss: 0.1498 - val_accuracy: 0.9340\n",
      "Epoch 2/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 0.0769 - accuracy: 0.9767 - val_loss: 0.0979 - val_accuracy: 0.9638\n",
      "Epoch 3/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 0.0731 - val_accuracy: 0.9728\n",
      "Epoch 4/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 0.0269 - accuracy: 0.9955 - val_loss: 0.1093 - val_accuracy: 0.9664\n",
      "Epoch 5/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 0.0699 - val_accuracy: 0.9793\n",
      "Epoch 6/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0870 - val_accuracy: 0.9702\n",
      "Epoch 7/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 0.0195 - accuracy: 0.9919 - val_loss: 0.1097 - val_accuracy: 0.9612\n",
      "Epoch 8/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.0522 - val_accuracy: 0.9832\n",
      "Epoch 9/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0478 - val_accuracy: 0.9858\n",
      "Epoch 10/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0622 - val_accuracy: 0.9793\n",
      "Epoch 11/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0518 - val_accuracy: 0.9806\n",
      "Epoch 12/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9845\n",
      "Epoch 13/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9832\n",
      "Epoch 14/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0413 - val_accuracy: 0.9884\n",
      "Epoch 15/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0418 - val_accuracy: 0.9897\n",
      "Epoch 16/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0502 - val_accuracy: 0.9845\n",
      "Epoch 17/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0637 - val_accuracy: 0.9780\n",
      "Epoch 18/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0519 - val_accuracy: 0.9884\n",
      "Epoch 19/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 20/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.0422 - val_accuracy: 0.9897\n",
      "Epoch 21/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3480e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 22/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 8.3591e-04 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9897\n",
      "Epoch 23/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6310e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 24/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3210e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 25/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7094e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9884\n",
      "Epoch 26/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7017e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9884\n",
      "Epoch 27/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3267e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9871\n",
      "Epoch 28/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0435 - val_accuracy: 0.9871\n",
      "Epoch 29/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 6.5018e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 30/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2293e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9884\n",
      "Epoch 31/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.5778e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9884\n",
      "Epoch 32/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.9963e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9884\n",
      "Epoch 33/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9208e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9884\n",
      "Epoch 34/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2652e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9884\n",
      "Epoch 35/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3988e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9884\n",
      "Epoch 36/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8566e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9884\n",
      "Epoch 37/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1489e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9884\n",
      "Epoch 38/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6913e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
      "Epoch 39/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0590e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 40/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8454e-04 - accuracy: 0.9997 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 41/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6243e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 42/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.5052e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
      "Epoch 43/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8424e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9897\n",
      "Epoch 44/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.0618e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9897\n",
      "Epoch 45/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3482e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 46/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0075e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 47/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9786e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 48/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6775e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 49/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8304e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9897\n",
      "Epoch 50/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.1797e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9897\n",
      "Epoch 51/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8608e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9897\n",
      "Epoch 52/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.5796e-04 - accuracy: 0.9997 - val_loss: 0.0431 - val_accuracy: 0.9897\n",
      "Epoch 53/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2114e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9897\n",
      "Epoch 54/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8065e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9897\n",
      "Epoch 55/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8012e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9897\n",
      "Epoch 56/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4168e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 57/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.3516e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9897\n",
      "Epoch 58/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.9600e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9897\n",
      "Epoch 59/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8371e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 60/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9377e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 61/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4477e-04 - accuracy: 0.9997 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 62/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7188e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9897\n",
      "Epoch 63/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.2746e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 64/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4696e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 65/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.7988e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 66/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9470e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 67/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3252e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 68/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7865e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 69/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8536e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
      "Epoch 70/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.3036e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 71/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7264e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9909\n",
      "Epoch 72/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.2350e-04 - accuracy: 0.9997 - val_loss: 0.0445 - val_accuracy: 0.9909\n",
      "Epoch 73/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2618e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9909\n",
      "Epoch 74/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2005e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 75/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8976e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9897\n",
      "Epoch 76/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.7093e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9909\n",
      "Epoch 77/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1182e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9909\n",
      "Epoch 78/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6258e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9909\n",
      "Epoch 79/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.0718e-04 - accuracy: 0.9997 - val_loss: 0.0435 - val_accuracy: 0.9909\n",
      "Epoch 80/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.4403e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 81/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.9074e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9909\n",
      "Epoch 82/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8425e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9909\n",
      "Epoch 83/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.5948e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9909\n",
      "Epoch 84/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6518e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9909\n",
      "Epoch 85/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.9231e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9909\n",
      "Epoch 86/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
      "Epoch 87/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.2214e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 88/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0453e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9909\n",
      "Epoch 89/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3163e-04 - accuracy: 0.9997 - val_loss: 0.0429 - val_accuracy: 0.9909\n",
      "Epoch 90/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0643e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9909\n",
      "Epoch 91/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7262e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9909\n",
      "Epoch 92/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0577e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9909\n",
      "Epoch 93/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3782e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9909\n",
      "Epoch 94/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2158e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9909\n",
      "Epoch 95/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6701e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9909\n",
      "Epoch 96/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0428 - val_accuracy: 0.9909\n",
      "Epoch 97/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4794e-04 - accuracy: 0.9994 - val_loss: 0.0435 - val_accuracy: 0.9909\n",
      "Epoch 98/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1776e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9909\n",
      "Epoch 99/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8087e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9909\n",
      "Epoch 100/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0278e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
      "Epoch 101/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9766e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9897\n",
      "Epoch 102/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 3.9733e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9909\n",
      "Epoch 103/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2925e-04 - accuracy: 0.9997 - val_loss: 0.0442 - val_accuracy: 0.9909\n",
      "Epoch 104/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6399e-04 - accuracy: 0.9997 - val_loss: 0.0438 - val_accuracy: 0.9909\n",
      "Epoch 105/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3875e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9909\n",
      "Epoch 106/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1493e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9909\n",
      "Epoch 107/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
      "Epoch 108/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6888e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9909\n",
      "Epoch 109/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4285e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 110/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3469e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9909\n",
      "Epoch 111/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1044e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 112/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7294e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9909\n",
      "Epoch 113/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8261e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9909\n",
      "Epoch 114/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6227e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9909\n",
      "Epoch 115/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7585e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 116/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8820e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 117/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0622e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 118/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1341e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9897\n",
      "Epoch 119/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9507e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9897\n",
      "Epoch 120/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7930e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 121/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4963e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 122/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6745e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
      "Epoch 123/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5520e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
      "Epoch 124/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6034e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9897\n",
      "Epoch 125/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0235e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9897\n",
      "Epoch 126/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2308e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9897\n",
      "Epoch 127/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8731e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9897\n",
      "Epoch 128/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9990e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9897\n",
      "Epoch 129/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9491e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9897\n",
      "Epoch 130/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5675e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9897\n",
      "Epoch 131/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9522e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9897\n",
      "Epoch 132/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.2185e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9897\n",
      "Epoch 133/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1935e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 134/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3814e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 135/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4675e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 136/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4774e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 137/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.4086e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 138/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0303e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9897\n",
      "Epoch 139/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.9720e-04 - accuracy: 0.9994 - val_loss: 0.0425 - val_accuracy: 0.9897\n",
      "Epoch 140/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2013e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 141/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7212e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9897\n",
      "Epoch 142/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9577e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9897\n",
      "Epoch 143/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4268e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9897\n",
      "Epoch 144/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5707e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9897\n",
      "Epoch 145/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4095e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9897\n",
      "Epoch 146/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1595e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 147/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9665e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9897\n",
      "Epoch 148/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8489e-04 - accuracy: 0.9997 - val_loss: 0.0433 - val_accuracy: 0.9909\n",
      "Epoch 149/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0894e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 150/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2412e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 151/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9235e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9897\n",
      "Epoch 152/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0193e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 153/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1606e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9897\n",
      "Epoch 154/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8388e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9897\n",
      "Epoch 155/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6838e-04 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9897\n",
      "Epoch 156/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9005e-04 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9897\n",
      "Epoch 157/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6329e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9897\n",
      "Epoch 158/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8856e-04 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9897\n",
      "Epoch 159/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1446e-04 - accuracy: 0.9997 - val_loss: 0.0419 - val_accuracy: 0.9897\n",
      "Epoch 160/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3805e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9897\n",
      "Epoch 161/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4964e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9909\n",
      "Epoch 162/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1730e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9897\n",
      "Epoch 163/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1281e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9897\n",
      "Epoch 164/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2060e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9897\n",
      "Epoch 165/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0915e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9897\n",
      "Epoch 166/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3500e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9897\n",
      "Epoch 167/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0705e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9897\n",
      "Epoch 168/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6321e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9897\n",
      "Epoch 169/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4674e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9909\n",
      "Epoch 170/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4043e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 171/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2723e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 172/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0469e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 173/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2232e-04 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9909\n",
      "Epoch 174/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0044e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 175/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0407e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9909\n",
      "Epoch 176/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9118e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9922\n",
      "Epoch 177/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1090e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
      "Epoch 178/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0595e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9922\n",
      "Epoch 179/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9827e-04 - accuracy: 0.9997 - val_loss: 0.0438 - val_accuracy: 0.9935\n",
      "Epoch 180/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2659e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9922\n",
      "Epoch 181/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9553e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9922\n",
      "Epoch 182/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9299e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9922\n",
      "Epoch 183/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8466e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9909\n",
      "Epoch 184/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6828e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9909\n",
      "Epoch 185/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1016e-04 - accuracy: 0.9997 - val_loss: 0.0433 - val_accuracy: 0.9935\n",
      "Epoch 186/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0255e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9935\n",
      "Epoch 187/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3389e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9922\n",
      "Epoch 188/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4259e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9935\n",
      "Epoch 189/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8894e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9922\n",
      "Epoch 190/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9652e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9922\n",
      "Epoch 191/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3901e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9909\n",
      "Epoch 192/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5985e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9909\n",
      "Epoch 193/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0329e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9922\n",
      "Epoch 194/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1878e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
      "Epoch 195/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2077e-04 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9909\n",
      "Epoch 196/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9526e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9909\n",
      "Epoch 197/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3945e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9909\n",
      "Epoch 198/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3410e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9922\n",
      "Epoch 199/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9247e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9922\n",
      "Epoch 200/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5875e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9922\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2872e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9922\n",
      "Epoch 202/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2319e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9922\n",
      "Epoch 203/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2590e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 204/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8802e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 205/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3435e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 206/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4417e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 207/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2191e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9909\n",
      "Epoch 208/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8676e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9909\n",
      "Epoch 209/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4307e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9922\n",
      "Epoch 210/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1330e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9909\n",
      "Epoch 211/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5588e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9909\n",
      "Epoch 212/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4534e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9909\n",
      "Epoch 213/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1943e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9922\n",
      "Epoch 214/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9583e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9909\n",
      "Epoch 215/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0651e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9909\n",
      "Epoch 216/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9706e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9909\n",
      "Epoch 217/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8762e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9909\n",
      "Epoch 218/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5908e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9909\n",
      "Epoch 219/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9513e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9909\n",
      "Epoch 220/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2887e-04 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9909\n",
      "Epoch 221/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2628e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9909\n",
      "Epoch 222/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6668e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9909\n",
      "Epoch 223/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2249e-04 - accuracy: 0.9997 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
      "Epoch 224/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0229e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
      "Epoch 225/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9884e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9909\n",
      "Epoch 226/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6908e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9909\n",
      "Epoch 227/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6663e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 228/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3189e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9909\n",
      "Epoch 229/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5359e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9909\n",
      "Epoch 230/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8379e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
      "Epoch 231/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7457e-04 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
      "Epoch 232/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1905e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9909\n",
      "Epoch 233/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6241e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9909\n",
      "Epoch 234/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5012e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9922\n",
      "Epoch 235/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2414e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9922\n",
      "Epoch 236/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5485e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9922\n",
      "Epoch 237/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8773e-04 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9922\n",
      "Epoch 238/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0477e-04 - accuracy: 0.9997 - val_loss: 0.0426 - val_accuracy: 0.9922\n",
      "Epoch 239/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8873e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9922\n",
      "Epoch 240/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0298e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9922\n",
      "Epoch 241/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6868e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9922\n",
      "Epoch 242/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6673e-04 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9922\n",
      "Epoch 243/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.6455e-04 - accuracy: 0.9997 - val_loss: 0.0449 - val_accuracy: 0.9909\n",
      "Epoch 244/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8967e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9909\n",
      "Epoch 245/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5976e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9909\n",
      "Epoch 246/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0056e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9909\n",
      "Epoch 247/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6067e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 248/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6748e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 249/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3338e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 250/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8633e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 251/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6968e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9909\n",
      "Epoch 252/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0515e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 253/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5715e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9922\n",
      "Epoch 254/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2918e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 255/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3769e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9922\n",
      "Epoch 256/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.2271e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9922\n",
      "Epoch 257/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2984e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 258/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5150e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 259/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7937e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 260/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 261/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3671e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 262/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4626e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 263/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5691e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 264/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2163e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 265/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0819e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 266/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6853e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 267/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4852e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9922\n",
      "Epoch 268/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4494e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 269/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3445e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 270/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5732e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 271/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4802e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 272/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9243e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 273/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7448e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 274/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0831e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 275/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3105e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 276/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1016e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
      "Epoch 277/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0676e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9922\n",
      "Epoch 278/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8657e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9922\n",
      "Epoch 279/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1269e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 280/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0886e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 281/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0634e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 282/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7559e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 283/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4465e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 284/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5462e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 285/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.2642e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 286/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1160e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 287/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2662e-04 - accuracy: 0.9997 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 288/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3289e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9922\n",
      "Epoch 289/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7573e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 290/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3126e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 291/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5367e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 292/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3290e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 293/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6954e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9922\n",
      "Epoch 294/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0820e-04 - accuracy: 0.9997 - val_loss: 0.0444 - val_accuracy: 0.9935\n",
      "Epoch 295/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3532e-04 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9935\n",
      "Epoch 296/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5890e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9935\n",
      "Epoch 297/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3790e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9935\n",
      "Epoch 298/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5486e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9935\n",
      "Epoch 299/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2699e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9935\n",
      "Epoch 300/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7729e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9935\n",
      "Epoch 301/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2158e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9935\n",
      "Epoch 302/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4377e-05 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 303/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0966e-04 - accuracy: 0.9997 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 304/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3714e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 305/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8137e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 306/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3762e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 307/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0026e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 308/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2524e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 309/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5669e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 310/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6014e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 311/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4209e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 312/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4161e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9922\n",
      "Epoch 313/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7843e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 314/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3392e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 315/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5337e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 316/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4261e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 317/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2934e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9922\n",
      "Epoch 318/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1889e-05 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 319/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3194e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9922\n",
      "Epoch 320/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1554e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
      "Epoch 321/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3188e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9922\n",
      "Epoch 322/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6676e-05 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 323/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1279e-04 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9922\n",
      "Epoch 324/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8885e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 325/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.8713e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 326/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2802e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 327/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1855e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 328/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9674e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9909\n",
      "Epoch 329/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3508e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9909\n",
      "Epoch 330/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.2597e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9909\n",
      "Epoch 331/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0409e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9909\n",
      "Epoch 332/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8621e-04 - accuracy: 0.9997 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 333/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0497e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 334/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4603e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 335/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2678e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 336/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6762e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 337/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.9925e-04 - accuracy: 0.9997 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 338/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3990e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 339/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.6292e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 340/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.5816e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 341/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6004e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 342/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.7230e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 343/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3541e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 344/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.3280e-04 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 345/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.9831e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 346/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3132e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 347/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6441e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 348/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2438e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 349/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2793e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 350/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6772e-04 - accuracy: 0.9997 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 351/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3074e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 352/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.3347e-04 - accuracy: 0.9997 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 353/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0939e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 354/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.9357e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 355/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.3781e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 356/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5439e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 357/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7433e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 358/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8838e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 359/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6491e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 360/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5302e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 361/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 362/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.3058e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 363/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.5305e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 364/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 2.4450e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 365/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 7.3788e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 366/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0056e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 367/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5421e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 368/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1160e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 369/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.4496e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 370/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.7867e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 371/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0560e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 372/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2481e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 373/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0020e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 374/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1051e-04 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 375/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8703e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 376/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.1249e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 377/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.3672e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 378/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.9132e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 379/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0195e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 380/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 9.2228e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 381/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0755e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 382/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0883e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 383/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5072e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 384/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8520e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 385/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.6790e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 386/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3742e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 387/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.2083e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 388/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0958e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 389/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2123e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 390/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8991e-05 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
      "Epoch 391/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.6689e-04 - accuracy: 0.9997 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 392/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3232e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 393/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2817e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 394/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7203e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 395/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3164e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 396/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6703e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 397/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1034e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 398/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.7794e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 399/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.5921e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 400/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0089e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0172e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 402/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6006e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 403/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7715e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 404/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4585e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 405/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6117e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 406/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.0036e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 407/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.8226e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 408/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0090e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 409/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1330e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 410/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1415e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 411/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0809e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 412/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.9259e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 413/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4945e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 414/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.8451e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 415/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9460e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 416/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1788e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 417/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.9222e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 418/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2778e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 419/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2992e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 420/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0628e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 421/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0271e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 422/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5469e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 423/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1695e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 424/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2185e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 425/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6339e-04 - accuracy: 0.9997 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 426/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5636e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 427/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1231e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 428/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9620e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 429/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1315e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 430/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2309e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 431/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3956e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 432/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0486e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 433/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6658e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 434/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0968e-04 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 435/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1289e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 436/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0761e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 437/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9201e-05 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9922\n",
      "Epoch 438/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1291e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9922\n",
      "Epoch 439/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7145e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 440/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0682e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 441/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7929e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 442/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2682e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 443/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7742e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 444/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5937e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 445/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4641e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 446/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4557e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9922\n",
      "Epoch 447/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5989e-05 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
      "Epoch 448/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0485e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 449/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0713e-05 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9922\n",
      "Epoch 450/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1603e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 451/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0037e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 452/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7318e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 453/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0268e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 454/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3029e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 455/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5338e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 456/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7240e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 457/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2720e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 458/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6567e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 459/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7839e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 460/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7849e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 461/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9332e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 462/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9596e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 463/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1440e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 464/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.8519e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 465/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6341e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 466/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3484e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 467/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5099e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 468/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7090e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 469/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4683e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 470/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9971e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9935\n",
      "Epoch 471/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5860e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 472/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4241e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9935\n",
      "Epoch 473/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3814e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 474/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2865e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 475/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.8755e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 476/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4434e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 477/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0596e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 478/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2448e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 479/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2858e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9935\n",
      "Epoch 480/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2054e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 481/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5358e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 482/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0790e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 483/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2778e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 484/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4412e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 485/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7702e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 486/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9396e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 487/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2084e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 488/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2692e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 489/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2066e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 490/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4734e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9922\n",
      "Epoch 491/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3601e-05 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9922\n",
      "Epoch 492/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8819e-05 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9922\n",
      "Epoch 493/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.0968e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9935\n",
      "Epoch 494/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7033e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 495/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1568e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9935\n",
      "Epoch 496/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.8242e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9935\n",
      "Epoch 497/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1958e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9935\n",
      "Epoch 498/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0036e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 499/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3079e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 500/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1431e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 501/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8218e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 502/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4813e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 503/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0734e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 504/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7871e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 505/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4164e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 506/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0865e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 507/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1507e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9935\n",
      "Epoch 508/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0067e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9935\n",
      "Epoch 509/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6536e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9935\n",
      "Epoch 510/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6452e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 511/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0329e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 512/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9893e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9935\n",
      "Epoch 513/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8873e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 514/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1632e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9935\n",
      "Epoch 515/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1271e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 516/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3648e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 517/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2545e-05 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9935\n",
      "Epoch 518/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4657e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9935\n",
      "Epoch 519/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9711e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 520/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4347e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 521/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8405e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 522/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8216e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 523/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8584e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 524/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0533e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9935\n",
      "Epoch 525/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1151e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9935\n",
      "Epoch 526/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1710e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 527/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5265e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 528/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1426e-04 - accuracy: 0.9997 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 529/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3365e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 530/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2345e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 531/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2346e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 532/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6421e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 533/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0855e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 534/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6673e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 535/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2862e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 536/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6976e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 537/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3604e-05 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9935\n",
      "Epoch 538/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9391e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 539/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0386e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9935\n",
      "Epoch 540/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5821e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 541/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.8734e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 542/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5668e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 543/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4673e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 544/2000\n",
      "49/49 [==============================] - 132s 3s/step - loss: 4.9731e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 545/2000\n",
      "49/49 [==============================] - 133s 3s/step - loss: 6.3110e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9922\n",
      "Epoch 546/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9707e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 547/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9342e-05 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 548/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2549e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9935\n",
      "Epoch 549/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7044e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9935\n",
      "Epoch 550/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7395e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9935\n",
      "Epoch 551/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.4398e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9935\n",
      "Epoch 552/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.7388e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 553/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.4163e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 554/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.3315e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 555/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8987e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 556/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4177e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 557/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0701e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 558/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.0173e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 559/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.1835e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 560/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.5312e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 561/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.2526e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9935\n",
      "Epoch 562/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5130e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9935\n",
      "Epoch 563/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6724e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9935\n",
      "Epoch 564/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.2364e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9935\n",
      "Epoch 565/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8745e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 566/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6451e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 567/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.6623e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 568/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7333e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 569/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8461e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 570/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.4482e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 571/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.4488e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 572/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.7830e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
      "Epoch 573/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8702e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 574/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4519e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9935\n",
      "Epoch 575/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.1254e-05 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9935\n",
      "Epoch 576/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.2454e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 577/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.1839e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 578/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.7586e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 579/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3884e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9935\n",
      "Epoch 580/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3306e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 581/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.8536e-05 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9935\n",
      "Epoch 582/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7819e-04 - accuracy: 0.9997 - val_loss: 0.0437 - val_accuracy: 0.9935\n",
      "Epoch 583/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.6929e-05 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9935\n",
      "Epoch 584/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.8388e-05 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9935\n",
      "Epoch 585/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.7092e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9922\n",
      "Epoch 586/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8790e-05 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9922\n",
      "Epoch 587/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8161e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 588/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2379e-04 - accuracy: 0.9997 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 589/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.6656e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 590/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1574e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 591/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0522e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 592/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2374e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 593/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.9308e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 594/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.2171e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 595/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0381e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9922\n",
      "Epoch 596/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.4018e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 597/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1184e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 598/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6036e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 599/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7064e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9935\n",
      "Epoch 600/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.7092e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7785e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 602/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.3490e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 603/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2878e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 604/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.0693e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 605/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.6238e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 606/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2909e-04 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 607/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.4759e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 608/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.9240e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 609/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.2744e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 610/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8597e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 611/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6442e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 612/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1609e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 613/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.4382e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 614/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5856e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 615/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.6722e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
      "Epoch 616/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.2332e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
      "Epoch 617/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.4491e-05 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9935\n",
      "Epoch 618/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.1156e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9935\n",
      "Epoch 619/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1688e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 620/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.1306e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 621/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.2585e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 622/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 5.4397e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 623/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5526e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 624/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4341e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 625/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7122e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 626/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1347e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 627/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8408e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 628/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.0283e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9935\n",
      "Epoch 629/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2669e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9935\n",
      "Epoch 630/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7215e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9935\n",
      "Epoch 631/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.0566e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 632/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8945e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 633/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.6690e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 634/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0497e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 635/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2137e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 636/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4015e-04 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9922\n",
      "Epoch 637/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1012e-04 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
      "Epoch 638/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5788e-04 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 639/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8131e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 640/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.0877e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 641/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.7559e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 642/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.9544e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 643/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6248e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 644/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.1281e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 645/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5858e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 646/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7309e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9922\n",
      "Epoch 647/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1317e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 648/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8314e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 649/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5948e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 650/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3562e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 651/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7344e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 652/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.9580e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 653/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0643e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 654/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8828e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 655/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.1845e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 656/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.5640e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 657/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8166e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 658/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2542e-04 - accuracy: 0.9997 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 659/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.4652e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 660/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.4304e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 661/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.0332e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 662/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6794e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 663/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8055e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 664/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9724e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 665/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5876e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 666/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.2331e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 667/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1477e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 668/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0968e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 669/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6272e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 670/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2697e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 671/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8725e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 672/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1404e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 673/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.7323e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 674/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3130e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 675/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2144e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 676/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.2326e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 677/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.2749e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 678/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.0497e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 679/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7970e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 680/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.4882e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 681/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5599e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 682/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7849e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 683/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.4718e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 684/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8085e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 685/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.0693e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 686/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.8811e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 687/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.9093e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 688/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.1257e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 689/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.2307e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 690/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0495e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 691/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6423e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 692/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.7710e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 693/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.0716e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 694/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0108e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 695/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4780e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 696/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.2446e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 697/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0092e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 698/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0784e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 699/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9162e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 700/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.4146e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 701/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0241e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 702/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9090e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9922\n",
      "Epoch 703/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8232e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 704/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.3507e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 705/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.4122e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 706/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.1340e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 707/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9831e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 708/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8105e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 709/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2681e-04 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 710/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2022e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
      "Epoch 711/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9978e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 712/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9318e-05 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9922\n",
      "Epoch 713/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0027e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 714/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5684e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9922\n",
      "Epoch 715/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1580e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 716/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8882e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 717/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.8023e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 718/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.5414e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9935\n",
      "Epoch 719/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7256e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 720/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8262e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 721/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1445e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 722/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.7400e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 723/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2806e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9922\n",
      "Epoch 724/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5738e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9935\n",
      "Epoch 725/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.1181e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 726/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8013e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 727/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7350e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 728/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9911e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 729/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.4204e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 730/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1920e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 731/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9126e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 732/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5799e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 733/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0559e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 734/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.5556e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 735/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4373e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 736/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8278e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 737/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1754e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 738/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.3275e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 739/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9345e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 740/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.1654e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9935\n",
      "Epoch 741/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3571e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9935\n",
      "Epoch 742/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7620e-04 - accuracy: 0.9997 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 743/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7707e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 744/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5964e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 745/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9445e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 746/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7410e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 747/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0558e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 748/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1391e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9935\n",
      "Epoch 749/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9496e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 750/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2722e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 751/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6033e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 752/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3636e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 753/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8559e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 754/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.4348e-04 - accuracy: 0.9997 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 755/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0899e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 756/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5152e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9922\n",
      "Epoch 757/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3646e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 758/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1517e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9922\n",
      "Epoch 759/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9170e-05 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9922\n",
      "Epoch 760/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.3474e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9922\n",
      "Epoch 761/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.9094e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 762/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.6081e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9922\n",
      "Epoch 763/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3588e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 764/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6761e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 765/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2574e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 766/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0725e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9935\n",
      "Epoch 767/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9327e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9935\n",
      "Epoch 768/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.0474e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9935\n",
      "Epoch 769/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.8389e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9935\n",
      "Epoch 770/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6823e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9935\n",
      "Epoch 771/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6517e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9935\n",
      "Epoch 772/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.7237e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 773/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7035e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 774/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6543e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9922\n",
      "Epoch 775/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1117e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9922\n",
      "Epoch 776/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6856e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 777/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0257e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 778/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8501e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
      "Epoch 779/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6868e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "Epoch 780/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.3075e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 781/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8367e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 782/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4065e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9935\n",
      "Epoch 783/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.7614e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9935\n",
      "Epoch 784/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1968e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 785/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4986e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 786/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5710e-05 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9935\n",
      "Epoch 787/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8688e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 788/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5287e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9935\n",
      "Epoch 789/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.6126e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 790/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0103e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 791/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9793e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 792/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.4138e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9922\n",
      "Epoch 793/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6120e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 794/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1439e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 795/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7817e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9935\n",
      "Epoch 796/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1955e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9935\n",
      "Epoch 797/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8117e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9935\n",
      "Epoch 798/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.2598e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9935\n",
      "Epoch 799/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.9614e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 800/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6584e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9922\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3152e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 802/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6197e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 803/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1500e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 804/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3234e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9935\n",
      "Epoch 805/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.6174e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9935\n",
      "Epoch 806/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.9049e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9935\n",
      "Epoch 807/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5748e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 808/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0120e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9922\n",
      "Epoch 809/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4402e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
      "Epoch 810/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5843e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 811/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1431e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 812/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7411e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 813/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9771e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 814/2000\n",
      "49/49 [==============================] - 127s 3s/step - loss: 2.6223e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9922\n",
      "Epoch 815/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.1904e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 816/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.8795e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 817/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5917e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 818/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.4375e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9935\n",
      "Epoch 819/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7576e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9935\n",
      "Epoch 820/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9468e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 821/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3596e-05 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9922\n",
      "Epoch 822/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3312e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 823/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7436e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 824/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.7837e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 825/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.5460e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9935\n",
      "Epoch 826/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3490e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9935\n",
      "Epoch 827/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8163e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9935\n",
      "Epoch 828/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0032e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9935\n",
      "Epoch 829/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4563e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
      "Epoch 830/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2913e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9935\n",
      "Epoch 831/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1011e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9935\n",
      "Epoch 832/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6726e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9935\n",
      "Epoch 833/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.2188e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9935\n",
      "Epoch 834/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1681e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9935\n",
      "Epoch 835/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.6218e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9935\n",
      "Epoch 836/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.0187e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9935\n",
      "Epoch 837/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2988e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9935\n",
      "Epoch 838/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.7921e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9935\n",
      "Epoch 839/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2597e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9935\n",
      "Epoch 840/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8606e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9935\n",
      "Epoch 841/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7208e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9935\n",
      "Epoch 842/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3064e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9935\n",
      "Epoch 843/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.3345e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9935\n",
      "Epoch 844/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4188e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 845/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0642e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 846/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8762e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 847/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3680e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9935\n",
      "Epoch 848/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.9372e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 849/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2699e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9935\n",
      "Epoch 850/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2883e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
      "Epoch 851/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0001e-05 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9935\n",
      "Epoch 852/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7719e-05 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9935\n",
      "Epoch 853/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8009e-05 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9935\n",
      "Epoch 854/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.9166e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9935\n",
      "Epoch 855/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2695e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9935\n",
      "Epoch 856/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.4643e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9935\n",
      "Epoch 857/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.6918e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
      "Epoch 858/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7351e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9935\n",
      "Epoch 859/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1903e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 860/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.7248e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9935\n",
      "Epoch 861/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9280e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9922\n",
      "Epoch 862/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0873e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 863/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2113e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9935\n",
      "Epoch 864/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5562e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9935\n",
      "Epoch 865/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1003e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 866/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.6346e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 867/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.0918e-04 - accuracy: 0.9997 - val_loss: 0.0489 - val_accuracy: 0.9935\n",
      "Epoch 868/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1034e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 869/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1622e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9935\n",
      "Epoch 870/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8976e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
      "Epoch 871/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2664e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
      "Epoch 872/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6763e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9935\n",
      "Epoch 873/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7723e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9935\n",
      "Epoch 874/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1656e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 875/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8496e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 876/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9740e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 877/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0364e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9935\n",
      "Epoch 878/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.0091e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 879/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4004e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9935\n",
      "Epoch 880/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8962e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9935\n",
      "Epoch 881/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7540e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
      "Epoch 882/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5916e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
      "Epoch 883/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1147e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
      "Epoch 884/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6116e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
      "Epoch 885/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0579e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9935\n",
      "Epoch 886/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1099e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9935\n",
      "Epoch 887/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6690e-05 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9935\n",
      "Epoch 888/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7264e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 889/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.7694e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 890/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0732e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 891/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0912e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9922\n",
      "Epoch 892/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2883e-04 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 893/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3286e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9935\n",
      "Epoch 894/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7923e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9935\n",
      "Epoch 895/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5104e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 896/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5466e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9935\n",
      "Epoch 897/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5128e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 898/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6709e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 899/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9862e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9935\n",
      "Epoch 900/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6151e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 901/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0255e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 902/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3987e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 903/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9128e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 904/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.7301e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9922\n",
      "Epoch 905/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.6953e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
      "Epoch 906/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5886e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9922\n",
      "Epoch 907/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5246e-05 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9922\n",
      "Epoch 908/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.1317e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 909/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6714e-04 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9922\n",
      "Epoch 910/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.4801e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 911/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7486e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 912/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.2726e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 913/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3497e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 914/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.9298e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9922\n",
      "Epoch 915/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.5885e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 916/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.7361e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 917/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3306e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9922\n",
      "Epoch 918/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9227e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9922\n",
      "Epoch 919/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1040e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9922\n",
      "Epoch 920/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.5445e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 921/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5367e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 922/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.7789e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 923/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9003e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 924/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0531e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 925/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0863e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 926/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.2656e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 927/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0767e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 928/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7867e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 929/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.5233e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 930/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.3642e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 931/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7967e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 932/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.4254e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9922\n",
      "Epoch 933/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3990e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9922\n",
      "Epoch 934/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9681e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9922\n",
      "Epoch 935/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8070e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 936/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5019e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 937/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.2230e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9922\n",
      "Epoch 938/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.5150e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 939/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1398e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 940/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.6778e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 941/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3978e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 942/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4043e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 943/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.8410e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 944/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1519e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 945/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2198e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 946/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.5975e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 947/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8490e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 948/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.5075e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9922\n",
      "Epoch 949/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4834e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 950/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6454e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 951/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7440e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 952/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6925e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 953/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6962e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 954/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3434e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9922\n",
      "Epoch 955/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0505e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 956/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1644e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9922\n",
      "Epoch 957/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9229e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9922\n",
      "Epoch 958/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9134e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 959/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0074e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 960/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5841e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 961/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7834e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9922\n",
      "Epoch 962/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4196e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 963/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0773e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9935\n",
      "Epoch 964/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.7491e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9935\n",
      "Epoch 965/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3317e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9922\n",
      "Epoch 966/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0106e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 967/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8156e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 968/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.1808e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 969/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8217e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 970/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3946e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 971/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3312e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 972/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.2688e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 973/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5114e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9922\n",
      "Epoch 974/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8881e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
      "Epoch 975/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1332e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9922\n",
      "Epoch 976/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5957e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 977/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8394e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9922\n",
      "Epoch 978/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0140e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9922\n",
      "Epoch 979/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0138e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
      "Epoch 980/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5467e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 981/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1155e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
      "Epoch 982/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2718e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9922\n",
      "Epoch 983/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.4629e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9922\n",
      "Epoch 984/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5441e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 985/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3179e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 986/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4444e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 987/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.7114e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 988/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6151e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 989/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9263e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9922\n",
      "Epoch 990/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3493e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 991/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8320e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 992/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.9662e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 993/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4537e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 994/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3042e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 995/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7645e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 996/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6997e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 997/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.1372e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 998/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.5064e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9922\n",
      "Epoch 999/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4945e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9922\n",
      "Epoch 1000/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4047e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9922\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9295e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9922\n",
      "Epoch 1002/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2892e-05 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9922\n",
      "Epoch 1003/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0792e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 1004/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0703e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
      "Epoch 1005/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2574e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9922\n",
      "Epoch 1006/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8124e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 1007/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7465e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9935\n",
      "Epoch 1008/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1910e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 1009/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1330e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9922\n",
      "Epoch 1010/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7409e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 1011/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3049e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 1012/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1512e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9922\n",
      "Epoch 1013/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0147e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
      "Epoch 1014/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7932e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9922\n",
      "Epoch 1015/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7447e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 1016/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6484e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 1017/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3042e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1018/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1629e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
      "Epoch 1019/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7852e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1020/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4892e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1021/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9502e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1022/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9519e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1023/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5829e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1024/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1987e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1025/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0041e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
      "Epoch 1026/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7205e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 1027/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3289e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1028/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0460e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1029/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6082e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1030/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1742e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1031/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7831e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1032/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9579e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1033/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8920e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9922\n",
      "Epoch 1034/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4137e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 1035/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5558e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9922\n",
      "Epoch 1036/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8316e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 1037/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9218e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
      "Epoch 1038/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2171e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9935\n",
      "Epoch 1039/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3105e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9935\n",
      "Epoch 1040/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9921e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
      "Epoch 1041/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5684e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 1042/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7026e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9922\n",
      "Epoch 1043/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4447e-05 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9935\n",
      "Epoch 1044/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5818e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9935\n",
      "Epoch 1045/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3120e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9922\n",
      "Epoch 1046/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2862e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9922\n",
      "Epoch 1047/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5169e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9935\n",
      "Epoch 1048/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6003e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1049/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8513e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1050/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2833e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1051/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4418e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1052/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4400e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1053/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1993e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 1054/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1006e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 1055/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6644e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1056/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4038e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1057/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4441e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9935\n",
      "Epoch 1058/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6463e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9935\n",
      "Epoch 1059/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2913e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 1060/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4823e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 1061/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1504e-05 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9922\n",
      "Epoch 1062/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7761e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
      "Epoch 1063/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7283e-05 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9935\n",
      "Epoch 1064/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6574e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
      "Epoch 1065/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8869e-05 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9922\n",
      "Epoch 1066/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0526e-05 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9935\n",
      "Epoch 1067/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2109e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9935\n",
      "Epoch 1068/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2855e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1069/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9548e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1070/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3978e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9922\n",
      "Epoch 1071/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3683e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 1072/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3767e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 1073/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9072e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9922\n",
      "Epoch 1074/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4318e-05 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9922\n",
      "Epoch 1075/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5328e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1076/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3380e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 1077/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0960e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1078/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6862e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
      "Epoch 1079/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1746e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9922\n",
      "Epoch 1080/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0694e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 1081/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5132e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9922\n",
      "Epoch 1082/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8319e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 1083/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4387e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 1084/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9514e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 1085/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9178e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1086/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8963e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9922\n",
      "Epoch 1087/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0526e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 1088/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2414e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 1089/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4392e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9935\n",
      "Epoch 1090/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5660e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 1091/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4570e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 1092/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4760e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 1093/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8071e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9935\n",
      "Epoch 1094/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9021e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9935\n",
      "Epoch 1095/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9009e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9935\n",
      "Epoch 1096/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0726e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 1097/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8918e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 1098/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6025e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9922\n",
      "Epoch 1099/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0569e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9922\n",
      "Epoch 1100/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2604e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9922\n",
      "Epoch 1101/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7575e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9922\n",
      "Epoch 1102/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9796e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9922\n",
      "Epoch 1103/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4044e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 1104/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5111e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
      "Epoch 1105/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9394e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 1106/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0528e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 1107/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6549e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 1108/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0343e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9922\n",
      "Epoch 1109/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0190e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9922\n",
      "Epoch 1110/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0297e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 1111/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5456e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 1112/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5580e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9922\n",
      "Epoch 1113/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3945e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 1114/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2775e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9922\n",
      "Epoch 1115/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5930e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
      "Epoch 1116/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4110e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1117/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6162e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9922\n",
      "Epoch 1118/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6679e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 1119/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3585e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 1120/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0171e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 1121/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0404e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 1122/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2040e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 1123/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9586e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9935\n",
      "Epoch 1124/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2582e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 1125/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5908e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 1126/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3966e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9935\n",
      "Epoch 1127/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0248e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9922\n",
      "Epoch 1128/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.5334e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9935\n",
      "Epoch 1129/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0296e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1130/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2733e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1131/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4266e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9935\n",
      "Epoch 1132/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3791e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9935\n",
      "Epoch 1133/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7575e-06 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9935\n",
      "Epoch 1134/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7793e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9935\n",
      "Epoch 1135/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2330e-05 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9935\n",
      "Epoch 1136/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1738e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9935\n",
      "Epoch 1137/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4011e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9935\n",
      "Epoch 1138/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0766e-05 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 1139/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8461e-05 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9935\n",
      "Epoch 1140/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9847e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9935\n",
      "Epoch 1141/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5011e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9922\n",
      "Epoch 1142/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9885e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9935\n",
      "Epoch 1143/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8452e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 1144/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7980e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 1145/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7650e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9935\n",
      "Epoch 1146/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2284e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922\n",
      "Epoch 1147/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4660e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9922\n",
      "Epoch 1148/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2043e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9922\n",
      "Epoch 1149/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1052e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9922\n",
      "Epoch 1150/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4476e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9922\n",
      "Epoch 1151/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5584e-06 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9922\n",
      "Epoch 1152/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3969e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
      "Epoch 1153/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8018e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 1154/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3500e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 1155/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9943e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9922\n",
      "Epoch 1156/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4272e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 1157/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.1370e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9922\n",
      "Epoch 1158/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1547e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9922\n",
      "Epoch 1159/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2455e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9922\n",
      "Epoch 1160/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2561e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9922\n",
      "Epoch 1161/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6902e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9922\n",
      "Epoch 1162/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8880e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1163/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3055e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1164/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6116e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9909\n",
      "Epoch 1165/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.4567e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9922\n",
      "Epoch 1166/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9972e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9922\n",
      "Epoch 1167/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3391e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9922\n",
      "Epoch 1168/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.8423e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9922\n",
      "Epoch 1169/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.7798e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9922\n",
      "Epoch 1170/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7793e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9922\n",
      "Epoch 1171/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.1716e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1172/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8384e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1173/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6965e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9922\n",
      "Epoch 1174/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.0940e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1175/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.3236e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1176/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.7393e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1177/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5906e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9922\n",
      "Epoch 1178/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.3300e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9922\n",
      "Epoch 1179/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5663e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9922\n",
      "Epoch 1180/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.5500e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1181/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2002e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1182/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.3130e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1183/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.3872e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1184/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3949e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1185/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5813e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1186/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1862e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1187/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.3990e-06 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 1188/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6358e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 1189/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.1376e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1190/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6052e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1191/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.9373e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1192/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9239e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1193/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5792e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1194/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5018e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9922\n",
      "Epoch 1195/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.1822e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9922\n",
      "Epoch 1196/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.0880e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9922\n",
      "Epoch 1197/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6773e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1198/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4330e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1199/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.7300e-04 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1200/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 2.6142e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5925e-04 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1202/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1980e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1203/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8908e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1204/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1724e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1205/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.7077e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1206/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6156e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1207/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1899e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1208/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1168e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9922\n",
      "Epoch 1209/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1307e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9922\n",
      "Epoch 1210/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.2291e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9922\n",
      "Epoch 1211/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1063e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9922\n",
      "Epoch 1212/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1760e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9922\n",
      "Epoch 1213/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8123e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1214/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2082e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9922\n",
      "Epoch 1215/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2760e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1216/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9150e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1217/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0797e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1218/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1960e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1219/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0518e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1220/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8361e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9922\n",
      "Epoch 1221/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8462e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1222/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2726e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9922\n",
      "Epoch 1223/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6254e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9922\n",
      "Epoch 1224/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0635e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1225/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8435e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9922\n",
      "Epoch 1226/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0781e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1227/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1315e-06 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1228/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1274e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1229/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2468e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1230/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7464e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1231/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2444e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1232/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8210e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1233/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6168e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1234/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5212e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1235/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0063e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1236/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2619e-06 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1237/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5439e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1238/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8560e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1239/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0929e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1240/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0063e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1241/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3782e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1242/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0851e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1243/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0483e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1244/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1571e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1245/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6196e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1246/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.0802e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1247/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5887e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1248/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9784e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1249/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7790e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1250/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0736e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1251/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1339e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1252/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5445e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1253/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0962e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1254/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5816e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1255/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4520e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1256/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1788e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1257/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2457e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1258/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1361e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1259/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2187e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1260/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4653e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9922\n",
      "Epoch 1261/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3023e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9922\n",
      "Epoch 1262/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9200e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1263/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5279e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9922\n",
      "Epoch 1264/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2015e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1265/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2045e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9922\n",
      "Epoch 1266/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.8316e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1267/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3204e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9922\n",
      "Epoch 1268/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5446e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1269/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8467e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1270/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2157e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1271/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7215e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1272/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7373e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1273/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0220e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1274/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.4109e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1275/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7268e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1276/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1107e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9922\n",
      "Epoch 1277/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.9706e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9922\n",
      "Epoch 1278/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9411e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9922\n",
      "Epoch 1279/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3517e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9922\n",
      "Epoch 1280/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4967e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1281/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8195e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1282/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1823e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1283/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2459e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1284/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4922e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1285/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6370e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1286/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1038e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1287/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9049e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9922\n",
      "Epoch 1288/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5189e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1289/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0861e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9922\n",
      "Epoch 1290/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0110e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9922\n",
      "Epoch 1291/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3210e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9922\n",
      "Epoch 1292/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5097e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9922\n",
      "Epoch 1293/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3915e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1294/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1400e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1295/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2588e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1296/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.7953e-06 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9935\n",
      "Epoch 1297/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2128e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1298/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3661e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1299/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0623e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1300/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0388e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1301/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4470e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1302/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9325e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1303/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6806e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9935\n",
      "Epoch 1304/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6537e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1305/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5869e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1306/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0378e-06 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9935\n",
      "Epoch 1307/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8925e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1308/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2430e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9922\n",
      "Epoch 1309/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2685e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9922\n",
      "Epoch 1310/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2068e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9922\n",
      "Epoch 1311/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7916e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9922\n",
      "Epoch 1312/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1172e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1313/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4946e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1314/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5980e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9922\n",
      "Epoch 1315/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1840e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9922\n",
      "Epoch 1316/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0174e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9922\n",
      "Epoch 1317/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0696e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9922\n",
      "Epoch 1318/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8083e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9922\n",
      "Epoch 1319/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4847e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1320/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5025e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9922\n",
      "Epoch 1321/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0514 - val_accuracy: 0.9922\n",
      "Epoch 1322/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0989e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9922\n",
      "Epoch 1323/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9826e-06 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9922\n",
      "Epoch 1324/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 8.6894e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9922\n",
      "Epoch 1325/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2817e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1326/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7738e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9922\n",
      "Epoch 1327/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5989e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9922\n",
      "Epoch 1328/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7468e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9922\n",
      "Epoch 1329/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2558e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9922\n",
      "Epoch 1330/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2045e-04 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9922\n",
      "Epoch 1331/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0413e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9922\n",
      "Epoch 1332/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0235e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9922\n",
      "Epoch 1333/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0354e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1334/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6482e-05 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1335/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.1766e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1336/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9691e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1337/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4272e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1338/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2121e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1339/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3573e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1340/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0872e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1341/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1308e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1342/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8776e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1343/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2331e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1344/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1177e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1345/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1568e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1346/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1543e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1347/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3723e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1348/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1299e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1349/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1377e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1350/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 8.0082e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1351/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3340e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1352/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8840e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1353/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4730e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1354/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8798e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1355/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5616e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9922\n",
      "Epoch 1356/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0711e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9922\n",
      "Epoch 1357/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0704e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9922\n",
      "Epoch 1358/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9339e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9922\n",
      "Epoch 1359/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3939e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9922\n",
      "Epoch 1360/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4434e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1361/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.4843e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1362/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0207e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9922\n",
      "Epoch 1363/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9297e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1364/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5899e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1365/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3597e-06 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1366/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4726e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1367/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4535e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9922\n",
      "Epoch 1368/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2119e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9922\n",
      "Epoch 1369/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0592e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1370/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6197e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
      "Epoch 1371/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1172e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9922\n",
      "Epoch 1372/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5330e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9922\n",
      "Epoch 1373/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6617e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9922\n",
      "Epoch 1374/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3132e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9922\n",
      "Epoch 1375/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1652e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9922\n",
      "Epoch 1376/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3293e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9922\n",
      "Epoch 1377/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1673e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9922\n",
      "Epoch 1378/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2960e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9922\n",
      "Epoch 1379/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0199e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1380/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1766e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1381/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6012e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1382/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7175e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1383/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7046e-06 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1384/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0532e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9935\n",
      "Epoch 1385/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1421e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9935\n",
      "Epoch 1386/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1569e-06 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9935\n",
      "Epoch 1387/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3638e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1388/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3532e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1389/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4737e-04 - accuracy: 0.9997 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1390/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0045e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1391/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5643e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1392/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0777e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1393/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1877e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1394/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1824e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1395/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2980e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1396/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3504e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1397/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1648e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1398/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1619e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1399/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1277e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1400/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7264e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1401/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.6559e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1402/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3136e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9935\n",
      "Epoch 1403/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8054e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9922\n",
      "Epoch 1404/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0185e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9922\n",
      "Epoch 1405/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7845e-06 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9922\n",
      "Epoch 1406/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3985e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1407/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2118e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1408/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0328e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1409/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9686e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1410/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1254e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1411/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0232e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1412/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1605e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1413/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1134e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1414/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1869e-04 - accuracy: 0.9997 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1415/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1618e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1416/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5973e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1417/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5942e-06 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1418/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.8546e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1419/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2934e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1420/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2611e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1421/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8395e-06 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1422/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5696e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1423/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8390e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1424/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1467e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1425/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3052e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1426/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0091e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1427/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.6043e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1428/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.9521e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1429/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0802e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1430/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7293e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1431/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0647e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1432/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3958e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1433/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2043e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1434/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2077e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1435/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1276e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1436/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0295e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1437/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0751e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1438/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0772e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1439/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5917e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1440/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5596e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1441/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2416e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1442/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.6000e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1443/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6130e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1444/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0305e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1445/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.5473e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1446/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7865e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1447/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4446e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1448/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8250e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1449/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.5747e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1450/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0826e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1451/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0065e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1452/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2634e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1453/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6831e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1454/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9882e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1455/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5483e-06 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1456/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7468e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1457/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.6064e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1458/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9155e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1459/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3679e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1460/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6307e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1461/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2488e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1462/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6471e-06 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9935\n",
      "Epoch 1463/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1899e-06 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9935\n",
      "Epoch 1464/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1392e-04 - accuracy: 0.9997 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1465/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1020e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9935\n",
      "Epoch 1466/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1263e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1467/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3748e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1468/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8154e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1469/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1942e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1470/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1030e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1471/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5575e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1472/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.9473e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1473/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0586e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1474/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3547e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1475/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1797e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1476/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0849e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1477/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6244e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1478/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8734e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1479/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2728e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1480/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.7005e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9922\n",
      "Epoch 1481/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8287e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9922\n",
      "Epoch 1482/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8761e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9922\n",
      "Epoch 1483/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.2424e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9922\n",
      "Epoch 1484/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1751e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9922\n",
      "Epoch 1485/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3448e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9922\n",
      "Epoch 1486/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0025e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1487/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.3626e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1488/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.8639e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1489/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6007e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1490/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7557e-05 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1491/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2345e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1492/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1174e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9922\n",
      "Epoch 1493/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0894e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1494/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4425e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1495/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0271e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1496/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4148e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1497/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8481e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1498/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9526e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1499/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3473e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9922\n",
      "Epoch 1500/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4319e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9922\n",
      "Epoch 1501/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0252e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9922\n",
      "Epoch 1502/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9458e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9922\n",
      "Epoch 1503/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7304e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1504/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1815e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1505/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2741e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1506/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6839e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1507/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0152e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1508/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5707e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1509/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2526e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1510/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6548e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1511/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1064e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1512/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4853e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1513/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0143e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1514/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0015e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1515/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6009e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1516/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2223e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1517/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.8956e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1518/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7443e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1519/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1757e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1520/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9760e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1521/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9643e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1522/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9406e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1523/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5585e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1524/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.8052e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1525/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.6333e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1526/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9926e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1527/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.6737e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1528/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1417e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1529/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9322e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1530/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1233e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1531/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2765e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1532/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9588e-05 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1533/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6528e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1534/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3101e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1535/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3776e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1536/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6754e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1537/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8212e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1538/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6686e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1539/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0801e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1540/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0192e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1541/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8377e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1542/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9179e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1543/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4942e-06 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1544/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4252e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1545/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9232e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1546/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.8946e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1547/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2535e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1548/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4308e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1549/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6922e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1550/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8384e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1551/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7465e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1552/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1364e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1553/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1948e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1554/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0088e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1555/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0406e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1556/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8220e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1557/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6405e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1558/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0708e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1559/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6160e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1560/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.5708e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9935\n",
      "Epoch 1561/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4504e-06 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9935\n",
      "Epoch 1562/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9324e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9935\n",
      "Epoch 1563/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4784e-06 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9935\n",
      "Epoch 1564/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0619e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9935\n",
      "Epoch 1565/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3174e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
      "Epoch 1566/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0841e-06 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9935\n",
      "Epoch 1567/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2280e-06 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 1568/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7974e-06 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9935\n",
      "Epoch 1569/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2152e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1570/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4779e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1571/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2216e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1572/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2594e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1573/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6607e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1574/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6418e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1575/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0302e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1576/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5418e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1577/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8722e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1578/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4316e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1579/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4054e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1580/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7416e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1581/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9723e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1582/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4680e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1583/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5366e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1584/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9769e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1585/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4614e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1586/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3731e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1587/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8551e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1588/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7311e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1589/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2719e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1590/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6862e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1591/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8556e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1592/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4706e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1593/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8900e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1594/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.8761e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1595/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5683e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1596/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0138e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1597/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7505e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1598/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1022e-05 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1599/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3091e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1600/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5061e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1601/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7725e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1602/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4829e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1603/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2309e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1604/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6981e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1605/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6946e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1606/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8574e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1607/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3833e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1608/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2242e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1609/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3381e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1610/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6994e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1611/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2855e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1612/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3092e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1613/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6418e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1614/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9379e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1615/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1157e-06 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1616/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2757e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1617/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1290e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1618/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3401e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1619/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5301e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1620/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6838e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1621/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2114e-05 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1622/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8085e-05 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1623/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2071e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1624/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3125e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1625/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1489e-04 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1626/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8925e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1627/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1486e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1628/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0612e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1629/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2327e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1630/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6819e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1631/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1491e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1632/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.9306e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1633/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 6.5061e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1634/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1315e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1635/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1924e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1636/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2392e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1637/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5590e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1638/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.0392e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1639/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3688e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1640/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 7.5356e-06 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 1641/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2321e-06 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1642/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0966e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1643/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8687e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
      "Epoch 1644/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 1.9688e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9935\n",
      "Epoch 1645/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5219e-06 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9935\n",
      "Epoch 1646/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3482e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9935\n",
      "Epoch 1647/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3770e-06 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1648/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0604e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1649/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0732e-06 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1650/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9122e-06 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9935\n",
      "Epoch 1651/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7696e-06 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9935\n",
      "Epoch 1652/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 2.9090e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1653/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9061e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1654/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2007e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1655/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6150e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1656/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0565e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1657/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9506e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1658/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1083e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1659/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0463e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1660/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 7.5027e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1661/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7186e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1662/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2992e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1663/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1939e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1664/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8718e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1665/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5938e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1666/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5767e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1667/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0343e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1668/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.5323e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1669/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0810e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1670/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5927e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1671/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6736e-06 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1672/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1705e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1673/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.1636e-05 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1674/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.4940e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1675/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 1.7059e-04 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1676/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2611e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1677/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9564e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1678/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.2101e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1679/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.5454e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1680/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8199e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1681/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 5.0584e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1682/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2755e-04 - accuracy: 0.9997 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1683/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.6906e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1684/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.2475e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1685/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4915e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1686/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.8457e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1687/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 1.8626e-04 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1688/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2211e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1689/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2601e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1690/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6270e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1691/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2051e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1692/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 8.5051e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1693/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4352e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1694/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.8475e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1695/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7680e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1696/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7190e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1697/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.0647e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1698/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 1.0374e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1699/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5141e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1700/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 8.4529e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1701/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5725e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1702/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5760e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9935\n",
      "Epoch 1703/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0113e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1704/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2928e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1705/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0543e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9935\n",
      "Epoch 1706/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 8.8655e-06 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9935\n",
      "Epoch 1707/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 6.4405e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9935\n",
      "Epoch 1708/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 5.5485e-06 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
      "Epoch 1709/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5507e-06 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9935\n",
      "Epoch 1710/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2247e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1711/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 8.5478e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1712/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1663e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9935\n",
      "Epoch 1713/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5388e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1714/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8324e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1715/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6027e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1716/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9574e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1717/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1723e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1718/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0638e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1719/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8832e-06 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1720/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8531e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
      "Epoch 1721/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4136e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1722/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0949e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1723/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1250e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1724/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.3540e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1725/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6957e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1726/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1672e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1727/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 2.5248e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1728/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1289e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1729/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8452e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1730/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6873e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1731/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.8812e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1732/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8757e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1733/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.2456e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1734/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.8934e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1735/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6559e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1736/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.9162e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1737/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.5415e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1738/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 8.0994e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1739/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.5506e-06 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1740/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.4244e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1741/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.4416e-04 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1742/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5935e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1743/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5434e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1744/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8720e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1745/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 4.8654e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1746/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 6.4934e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9935\n",
      "Epoch 1747/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0064e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1748/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 5.9948e-06 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
      "Epoch 1749/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6216e-06 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9935\n",
      "Epoch 1750/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9626e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9935\n",
      "Epoch 1751/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3917e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1752/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1895e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1753/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0460e-04 - accuracy: 0.9997 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1754/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 7.7597e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1755/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 6.1942e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1756/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5001e-05 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1757/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9660e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1758/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0221e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1759/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1151e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1760/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0708e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1761/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2861e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1762/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4995e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1763/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7319e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1764/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 1.2417e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1765/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.3154e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1766/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.9070e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1767/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.9021e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1768/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7544e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1769/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6898e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1770/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.7534e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1771/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9937e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1772/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7074e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1773/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1100e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1774/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 5.3938e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1775/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.7330e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1776/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4956e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1777/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8854e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1778/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6576e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1779/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1747e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1780/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.0489e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1781/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7215e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1782/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3224e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1783/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3293e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1784/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1783e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1785/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.1206e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1786/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9287e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1787/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0049e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1788/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3186e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1789/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.6289e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1790/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0673e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1791/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6552e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1792/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2951e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1793/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2224e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1794/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3190e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1795/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0539e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9935\n",
      "Epoch 1796/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.2345e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1797/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0098e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1798/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5497e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1799/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 6.9964e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9935\n",
      "Epoch 1800/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6180e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0374e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1802/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3038e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9935\n",
      "Epoch 1803/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4976e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1804/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5381e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1805/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6941e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1806/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1946e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1807/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7010e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1808/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5690e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1809/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9679e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1810/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9301e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1811/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6901e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1812/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5649e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1813/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1870e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1814/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0161e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1815/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 1.2692e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1816/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4857e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1817/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2037e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1818/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5563e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1819/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4945e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1820/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5361e-05 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1821/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1616e-06 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9935\n",
      "Epoch 1822/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7528e-06 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9935\n",
      "Epoch 1823/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4028e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1824/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3752e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9935\n",
      "Epoch 1825/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4427e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1826/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8623e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1827/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0481e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1828/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8947e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1829/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.5630e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1830/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5511e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1831/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1832/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7601e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1833/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.5836e-05 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9935\n",
      "Epoch 1834/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7074e-06 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9935\n",
      "Epoch 1835/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.0561e-06 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9935\n",
      "Epoch 1836/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3387e-06 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9935\n",
      "Epoch 1837/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.1599e-05 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1838/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0671e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1839/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7396e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1840/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6674e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1841/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8014e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1842/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.4753e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1843/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0599e-05 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1844/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7217e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1845/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8333e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1846/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3299e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1847/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3563e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1848/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3509e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1849/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2556e-06 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9935\n",
      "Epoch 1850/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0575e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1851/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5843e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1852/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5176e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1853/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8022e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1854/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4619e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1855/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8407e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1856/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0924e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1857/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2368e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
      "Epoch 1858/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1923e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9935\n",
      "Epoch 1859/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8659e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9935\n",
      "Epoch 1860/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.4781e-06 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 1861/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.4813e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1862/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 4.7859e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1863/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4885e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1864/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3937e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9935\n",
      "Epoch 1865/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8715e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1866/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4441e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1867/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7293e-06 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
      "Epoch 1868/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7172e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9935\n",
      "Epoch 1869/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2144e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1870/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 9.8119e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1871/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.6680e-06 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9935\n",
      "Epoch 1872/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0471e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1873/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.5574e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1874/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8573e-06 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1875/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0175e-05 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9935\n",
      "Epoch 1876/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 5.0754e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1877/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7595e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1878/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.0865e-05 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9935\n",
      "Epoch 1879/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 5.2404e-06 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9935\n",
      "Epoch 1880/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9628e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1881/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 7.8254e-05 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9922\n",
      "Epoch 1882/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0764e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9922\n",
      "Epoch 1883/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0526e-06 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9922\n",
      "Epoch 1884/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.8773e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1885/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.8106e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1886/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2025e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1887/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2695e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1888/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5947e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1889/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4674e-05 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1890/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0780e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1891/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9755e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1892/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3221e-05 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1893/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1803e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1894/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.1946e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1895/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3661e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1896/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5868e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1897/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.4738e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1898/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2000e-05 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1899/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4954e-06 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1900/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.5229e-06 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1901/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.5279e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1902/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.3816e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1903/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8792e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1904/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5887e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1905/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7660e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
      "Epoch 1906/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.2934e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1907/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8716e-06 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9935\n",
      "Epoch 1908/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9496e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9935\n",
      "Epoch 1909/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.9422e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1910/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.5364e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9935\n",
      "Epoch 1911/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 8.3073e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1912/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9373e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1913/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.7802e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1914/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9805e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1915/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.0654e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1916/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 5.7053e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1917/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.0171e-05 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9935\n",
      "Epoch 1918/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.3207e-06 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9935\n",
      "Epoch 1919/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2907e-06 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9935\n",
      "Epoch 1920/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.9502e-06 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9935\n",
      "Epoch 1921/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5081e-06 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9935\n",
      "Epoch 1922/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5227e-04 - accuracy: 0.9997 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1923/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6234e-06 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1924/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.2696e-06 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1925/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5142e-06 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1926/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9000e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9935\n",
      "Epoch 1927/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 9.3832e-06 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9935\n",
      "Epoch 1928/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8991e-05 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1929/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4308e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1930/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.4056e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1931/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.1674e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1932/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.1311e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1933/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1621e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1934/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.2862e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1935/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7292e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1936/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8348e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1937/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.1369e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1938/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8528e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1939/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.3654e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9935\n",
      "Epoch 1940/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0142e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1941/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4086e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1942/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.4010e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1943/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6577e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1944/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.4580e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1945/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5114e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1946/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.6552e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1947/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.5907e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1948/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.0179e-06 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9935\n",
      "Epoch 1949/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.6421e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1950/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.6271e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1951/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.6496e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1952/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.6426e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1953/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.3574e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1954/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.9335e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1955/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7274e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1956/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.8969e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1957/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 9.8830e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1958/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.7138e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1959/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5897e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1960/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1336e-06 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
      "Epoch 1961/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.2296e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1962/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4702e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1963/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.8286e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1964/2000\n",
      "49/49 [==============================] - 128s 3s/step - loss: 3.5280e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1965/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.8761e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1966/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.0851e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1967/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9256e-04 - accuracy: 0.9997 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1968/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.1958e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1969/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7387e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1970/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.9285e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1971/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 8.3673e-06 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
      "Epoch 1972/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6089e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1973/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6721e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1974/2000\n",
      "49/49 [==============================] - 130s 3s/step - loss: 7.2596e-06 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1975/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.4250e-06 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9935\n",
      "Epoch 1976/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 1.0159e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
      "Epoch 1977/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.7986e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1978/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.6516e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1979/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.3342e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1980/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.9186e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9935\n",
      "Epoch 1981/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 6.7743e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1982/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 3.9019e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1983/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 7.3949e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1984/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.2973e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1985/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2925e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1986/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.4150e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1987/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.0263e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1988/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.7092e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
      "Epoch 1989/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 2.1656e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9935\n",
      "Epoch 1990/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.7681e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1991/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.2016e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1992/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 5.1070e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 1993/2000\n",
      "49/49 [==============================] - 131s 3s/step - loss: 4.5621e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1994/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.5488e-06 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9935\n",
      "Epoch 1995/2000\n",
      "49/49 [==============================] - 129s 3s/step - loss: 4.9935e-05 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
      "Epoch 1996/2000\n",
      "49/49 [==============================] - 133s 3s/step - loss: 4.2319e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "Epoch 1997/2000\n",
      "49/49 [==============================] - 133s 3s/step - loss: 6.4350e-06 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9935\n",
      "Epoch 1998/2000\n",
      "49/49 [==============================] - 132s 3s/step - loss: 5.9239e-06 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9935\n",
      "Epoch 1999/2000\n",
      "49/49 [==============================] - 132s 3s/step - loss: 8.4852e-06 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9935\n",
      "Epoch 2000/2000\n",
      "49/49 [==============================] - 133s 3s/step - loss: 6.3147e-06 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9935\n",
      "INFO:tensorflow:Assets written to: D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6\\OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "save_model_interval = 200\n",
    "checkpoint_filepath = path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch{epoch:04d}.pb' # -val_acc{val_accuracy:.2f}\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    period=save_model_interval,\n",
    "    save_best_only=False)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                  patience=5, min_lr=0.00001,cooldown=1, verbose=1)\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "history = model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS, callbacks=[model_checkpoint_callback,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.subplot(1, 2, 2)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 66s 2s/step - loss: 0.2814 - accuracy: 0.9487\n",
      "test_indoor_ds_results:test loss, test acc: [0.2813616991043091, 0.9487179517745972]\n"
     ]
    }
   ],
   "source": [
    "#indoor testset\n",
    "test_indoor_ds_results = model.evaluate(test_indoor_ds)\n",
    "print(\"test_indoor_ds_results:test loss, test acc:\", test_indoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 112s 2s/step - loss: 0.4012 - accuracy: 0.9424\n",
      "test_outdoor_ds_results:test loss, test acc: [0.40117618441581726, 0.9423567056655884]\n"
     ]
    }
   ],
   "source": [
    "#outdoor testset\n",
    "test_outdoor_ds_results = model.evaluate(test_outdoor_ds)\n",
    "print(\"test_outdoor_ds_results:test loss, test acc:\", test_outdoor_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 77s 2s/step - loss: 1.0626 - accuracy: 0.8364\n",
      "test_belt_ds_results:test loss, test acc: [1.062603235244751, 0.8363553881645203]\n"
     ]
    }
   ],
   "source": [
    "#belt testset\n",
    "test_belt_ds_results = model.evaluate(test_belt_ds)\n",
    "print(\"test_belt_ds_results:test loss, test acc:\", test_belt_ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch0800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1000.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1200.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1400.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1800.pb',\n",
       " 'D:/ModelMedicalWasteCheckpoint/5G_EfficientNetB6/OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch2000.pb']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read path of trained model\n",
    "import os, os.path\n",
    "trained_path = path_to_model\n",
    "models_paths = []\n",
    "for name_folder in os.listdir(trained_path):\n",
    "    if os.path.isdir(os.path.join(trained_path, name_folder)):\n",
    "        models_paths.append(os.path.join(trained_path, name_folder))\n",
    "models_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_98518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_195734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_100798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_101231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_97854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_104476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_176261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_185923) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_184880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_176498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_181263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_105647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_175331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_102916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_174248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_183495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_191946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_98467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_190969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_178689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_97562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_175825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_199936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_106767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_177105) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_98243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_176432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_195563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_104568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_99363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_97680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_103904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_107149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_105820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_179508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_190903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_105240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_192528) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_97521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_178082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_98027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_98126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_186530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_105688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_103639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_177475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_178882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_180722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_189148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_197555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_192765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_190296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_182499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_104792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_101862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_103863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_98085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_187697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_184339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_195127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_98915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_196170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_102483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_104087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_103812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_100119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_181092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_100966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_190125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_103415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_184102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_104036) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_174182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_105912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_103456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_102035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_105464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_100567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_179271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_102534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_106044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_186701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_107200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_106319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_187374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_103232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_103140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_194956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_102692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_195800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_187934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_177039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_102784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_99231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_173604) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_101363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_183125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_102259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_188475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_194586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_196341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_101679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_199329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_182565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_198769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_180049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_186767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_102575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_191576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_175891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_99421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_104700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_184946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_105871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_77753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_182888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_104359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_106808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_187868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_101811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_99895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_193913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_200372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_107241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_106543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_106925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_189755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_103588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_189689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_195193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_99190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_106976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_97470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_106716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_101903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_101190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_98783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_182306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_97895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_98966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_174702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_183059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_106360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_100699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_100915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_102351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_173775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_104318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_175072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_105596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_178253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_105016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_177646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_193979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_192139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_155434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_103191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_198835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_174636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_184273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_179878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_175654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_190362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_197991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_102743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_180485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_99854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_178319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_186160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_196948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_188304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_104924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_101414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_175265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_100757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_102310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_100526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_99579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_105199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_105372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_183732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_160471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_197384) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_99671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_186094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_101455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_191339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_104975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_190732) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_198228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_99007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_98742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_106268) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_193742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_199158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_104527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_189518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_173841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_168334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_197014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_199765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_196407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_197621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_181936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_185316) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_191510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_188541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_193135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_187137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_192699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_106492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_105423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_100027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_183666) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_100302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_107373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_181699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_189082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_106095) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_100475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_193372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_177712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_200002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_98691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_185553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_97721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_101587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_100251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_180656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_99462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_106584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_98294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_176868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_178948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_104751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_102127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_199395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_180115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_196777) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_99803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_173349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_100343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_99139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_103364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_102086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_100078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_185487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_193306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_104260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_105148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_194349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_194520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_192205) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_102967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_187308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_107017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_101638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_104128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_188911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_179442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_98559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_103008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_198598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_184709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_103680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_198162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_101139) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_181329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_99630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_181870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_106136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_98335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_101007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 62s 2s/step - loss: 0.2376 - accuracy: 0.9448\n",
      "50/50 [==============================] - 103s 2s/step - loss: 0.2823 - accuracy: 0.9404\n",
      "35/35 [==============================] - 73s 2s/step - loss: 0.8432 - accuracy: 0.8332\n",
      "Epoch200 \n",
      " test_indoor_acc=0.9448160529136658 \n",
      " test_outdoor_acc=0.9404458403587341 \n",
      " test_belt_acc=0.8331822156906128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_267689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_348230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_270094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_350592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_263057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_345590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_358411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_262219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_363656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_360668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_343380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_338746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_339763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_345827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_262741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_346804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_363893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_267190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_363096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_264617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_268402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_357197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_270593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_363267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_360298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_351199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_266533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_270858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_262583) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_350421) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_346434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_267638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_342817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_263861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_263464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_262393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_267730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_271515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_270186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_362489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_361512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_353409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_271265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_265861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_345220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_265637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_267073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_265024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_268534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_269422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_358847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_265464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_362119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_264973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_337847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_338339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_348837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_346197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_264749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_268585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_359454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_364434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_342751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_359084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_352366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_350658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_263413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_351872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_340152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_267913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_266584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_341537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_264169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_351806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_352432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_344613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_262525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_268137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_363333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_271423) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_267954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_351265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_355401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_266757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_342580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_266136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_349814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_347623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_345154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_343187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_338273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_361446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_360061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_352195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_269198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_339829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_271698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_347993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_359691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_351635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_268178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_341603) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_262965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_270369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_348164) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_345761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_242251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_271214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_339570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_269697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_269025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_357633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_356637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_262060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_271739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_355837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_347386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_264077) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_346368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_267282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_265688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_341366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_264841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_263919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_361275) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_262178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_341973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_356444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_349985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_354016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_353039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_362726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_267506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_340323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_355467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_359018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_266849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_343769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_265197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_270410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_269646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_352973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_349207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_339200) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_265065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_354187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_340389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_359625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_355230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_267241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_270542) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_262792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_348771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_270817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_271871) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_270318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_263281) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_268086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_346997) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_271306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_269249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_262019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_347063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_265912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_261968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_340996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_269870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_271082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_265953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_269962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_363827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_358240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_364500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_343446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_266808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_342210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_268626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_269066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_270634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_271647) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_353580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_344547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_270990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_348600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_349378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_263240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_266401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_271474) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_263637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_356074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_264301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_264800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_364263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_364870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_264352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_338102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_351028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_356008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_263505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_267862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_360839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_354253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_357026) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_344006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_343940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_349444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_361882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_268816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_339134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_263016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_267465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_269290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_266309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_265505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_362660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_354623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_263960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_267414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_340759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_344983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_357804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_268857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_319932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_264576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_344376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_354794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_266085) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_270766) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_262833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_266625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_268758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_270145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_332832) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_264393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_269514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_362053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_352802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_263189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_262624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_265296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_268361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_358477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_269921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_347557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_262352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_265255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_265729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_357870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_268974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_354860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_357263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_269473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_267032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_264128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_338680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_342144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_356703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_271041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_360905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_265413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_360232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_266981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_340930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_268310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_350051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_324969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_269738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_266360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_264525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_353646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_266177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_263729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_263688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 63s 2s/step - loss: 0.2537 - accuracy: 0.9454\n",
      "50/50 [==============================] - 103s 2s/step - loss: 0.3155 - accuracy: 0.9395\n",
      "35/35 [==============================] - 72s 2s/step - loss: 0.8988 - accuracy: 0.8350\n",
      "Epoch400 \n",
      " test_indoor_acc=0.9453734755516052 \n",
      " test_outdoor_acc=0.9394904375076294 \n",
      " test_belt_acc=0.834995448589325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_519121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_427911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_427290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_429471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_427463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_508874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_426676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_429522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_435804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_426891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_528154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_431571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_431688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_515090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_431530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_433314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_509481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_524730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_432360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_432411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_428135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_514312) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_432136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_515697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_510088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_435972) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_523516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_503178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_525403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_431347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_427122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_431306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_436013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_524189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_507315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_520572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_432187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_430583) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_428891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_434012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_435580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_432808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_516930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_512121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_517907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_430186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_428850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_435539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_512728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_509718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_434592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_431780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_516693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_514919) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_528391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_521201) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_433032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_431479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_528932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_510932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_432004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_432676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_511302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_509652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_431912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_523582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_514549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_428799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_432584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_428626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_524559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_428227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_528998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_518144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_431082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_518685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_505494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_429753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_433696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_507944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_430899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_516304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_511561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_516133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_430858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_431031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_502345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_517471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_518078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_509111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_522975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_427779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_513269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_429962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_433355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_434684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_515156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_526380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_507878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_426466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_506471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_433788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_509045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_434460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_521695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_427239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_430634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_525773) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_513876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_502600) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_516864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_518751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_434643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_435488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_522909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_430359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_426850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_502837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_510325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_429339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_428186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_427555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_428359) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_512491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_519292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_428417) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_506642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_430227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_508267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_406749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_428003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_431963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_433124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_526010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_513942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_525944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_430807) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_503244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_506708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_505864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_429911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_427962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_507685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_435356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_513335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_525166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_430410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_520335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_517537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_433564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_521761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_429115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_510695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_504327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_525337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_506035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_497330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_434908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_432859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_526987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_522302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_515526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_523952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_527594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_527831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_507078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_431123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_436196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_433971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_529368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_505257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_429563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_518514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_435264) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_427687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_436237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_526617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_527158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_428667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_522368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_429247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_429695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_434144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_426558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_523345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_427081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_435315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_435132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_434368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_519358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_513705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_520506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_512662) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_484430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_516370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_504261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_515763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_511884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_433747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_429298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_503698) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_503632) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_427738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_434236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_527224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_528325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_426717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_522131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_427514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_433083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_432635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_433256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_427331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_526551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_426517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_435091) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_519965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_511495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_433523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_512055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_524796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_430135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_435921) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_519728) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_432900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_507249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_434816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_513098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_519899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_429794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_435040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_510866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_436145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_427023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_504821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_508504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_524123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_521135) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_434867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_527765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_429023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_504650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_435763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_506101) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_508438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_505428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_504068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_431739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_430451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_434195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_528761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_429074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_430003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_510259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_432452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_502771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_432228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_433472) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_520942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_431255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_434419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_489467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_521524) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_428458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_517300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_428575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_504887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_522738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_436369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_514483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_435712) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_433920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_430675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 67s 2s/step - loss: 0.2564 - accuracy: 0.9470\n",
      "50/50 [==============================] - 103s 2s/step - loss: 0.3302 - accuracy: 0.9408\n",
      "35/35 [==============================] - 72s 2s/step - loss: 0.9294 - accuracy: 0.8332\n",
      "Epoch600 \n",
      " test_indoor_acc=0.9470456838607788 \n",
      " test_outdoor_acc=0.940764307975769 \n",
      " test_belt_acc=0.8331822156906128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_600867) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_676059) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_591620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_691049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_596909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_592501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_599538) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_596461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_599182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_675193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_672936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_595397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_673543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_677226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_596502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_688687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_689228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_679588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_671813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_595580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_674757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_673002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_599365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_676382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_591579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_597306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_693430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_595845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_674216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_681428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_683012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_692823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_689901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_598866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_592915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_594020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_684833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_597082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_674586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_593796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_598194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_674150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_595081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_597357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_593389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_686022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_683856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_592956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_677160) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_681798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_599090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_686629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_597398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_682405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_596028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_667335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_672183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_591215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_678981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_681191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_591348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_592277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_600419) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_685004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_682642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_591174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_687407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_675364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_679417) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_596069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_685699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_667742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_598734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_595305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_689294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_668759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_684463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_593521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_593348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_598418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_684226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_595173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_669148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_593572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_593613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_681362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_680024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_678203) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_591015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_594409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_592857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_596634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_594908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_596278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_596685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_592725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_600078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_591389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_677767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_594501) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_681969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_596726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_686800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_594292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_599854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_691115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_653965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_598062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_690271) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_593073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_597853) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_691722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_679047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_680195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_600694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_691656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_671576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_596950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_599762) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_669926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_690878) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_597812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_684397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_672765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_591737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_594857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_692889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_591521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_668566) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_692652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_592684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_600735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_678810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_592185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_692263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_685440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_682576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_600261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_594633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_595529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_683790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_670362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_594251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_592633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_668196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_689664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_594684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_669755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_594061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_594949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_690508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_670533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_596237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_675800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_593124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_596410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_594725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_692329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_693259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_599141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_598286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_689057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_672442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_666843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_675993) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_671140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_688014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_673979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_600037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_688080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_593969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_597174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_600302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_599813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_595621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_688621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_598245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_687843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_593297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_595977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_598469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_600511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_670599) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_598642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_600643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_571247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_685070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_685633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_597581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_680261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_600470) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_596858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_597530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_692092) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_595132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_671747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_678374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_594193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_591788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_678440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_673372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_594460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_670969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_591961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_600210) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_661828) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_686193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_669385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_591829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_599630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_687236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_676553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_688450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_593837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_683183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_598510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_597133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_673609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_686259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_675430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_592409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_592236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_690442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_689835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_598958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_667098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_592012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_596186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_693496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_680868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_677596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_599986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_599314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_677833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_593745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_598917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_592053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_680802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_590964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_648928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_687473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_674823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_598693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_667269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_591056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_599406) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_683619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_597754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_599589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_683249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_672376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_595753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_669992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_676989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_595356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_597970) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_682035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_667676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_693866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_593165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_686866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_598021) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_595804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_668130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_597622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_669319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_680631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_671206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_668825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_676619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_691485) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_679654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_592460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 62s 2s/step - loss: 0.2570 - accuracy: 0.9509\n",
      "50/50 [==============================] - 104s 2s/step - loss: 0.3278 - accuracy: 0.9411\n",
      "35/35 [==============================] - 72s 2s/step - loss: 0.9475 - accuracy: 0.8345\n",
      "Epoch800 \n",
      " test_indoor_acc=0.9509475827217102 \n",
      " test_outdoor_acc=0.941082775592804 \n",
      " test_belt_acc=0.8345421552658081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_763904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_850131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_843308) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_760343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_832628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_760027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_758467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_759131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_840298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_755462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_857928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_762519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_755846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_759854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_761448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_755887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_848961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_760078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_764036) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_756958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_762252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_856154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_759630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_756510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_760684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_844152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_756551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_761804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_756235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_764800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_760119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_840557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_755554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_760251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_758111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_842701) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_846533) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_847140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_848724) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_762692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_833323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_844693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_852948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_759895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_756118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_762079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_758019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_826326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_841487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_756019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_843479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_836311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_761407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_844759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_836874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_762784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_851127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_842094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_847747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_849502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_758907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_761631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_839255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_764260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_848288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_854769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_759355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_847510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_762310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_839862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_841724) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_853792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_759406) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_756999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_757223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_757571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_756286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_761580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_856590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_848354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_836940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_854162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_763639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_763680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_818463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_844522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_760908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_757131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_843915) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_835704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_764968) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_761855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_760567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_764087) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_757887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_756327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_761132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_852512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_756775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_756077) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_834253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_758335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_762351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_760776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_831341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_855983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_837500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_761356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_757663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_762468) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_757413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_832694) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_765141) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_759803) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_857150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_832174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_759579) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_758070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_763191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_848895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_844086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_835031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_856761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_857321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_834424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_763456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_760526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_833817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_839084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_765233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_843545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_757182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_858364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_835638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_852341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_759182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_846903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_763008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_848117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_760475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_756734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_841051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_856827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_842872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_756683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_759447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_762560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_842265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_857387) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_831596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_835097) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_850757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_837870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_846296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_841117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_842331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_847681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_758518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_763232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_757622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_833257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_851971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_840491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_763588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_831833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_857994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_764128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_833646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_853555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_758691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_764352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_759671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_834490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_839321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_757454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_764708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_758559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_855006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_762916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_764535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_760959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_757355) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_849938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_838107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_764484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_856220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_764311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_845129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_758749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_832240) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_853185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_855376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_836245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_831767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_762120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_762028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_834860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_761183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_857757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_755513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_851905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_761000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_847074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_850197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_833064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_841658) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_845926) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_757795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_853726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_838477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_846467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_761224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_763415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_845860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_833883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_763364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_755672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_854333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_839691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_757846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_762743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_835467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_845689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_836681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_854940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_851734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_763812) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_838648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_839928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_758294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_761896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_813426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_853119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_758958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_764576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_842938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_837263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_765365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_765009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_854399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_761672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_855613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_758790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_756907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_764917) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_850691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_758999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_836074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_838041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_764759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_759223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_763863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_765192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_855547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_851298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_837434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_763140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_840880) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_760735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_838714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_758243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_849568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_852578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_851364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_762967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_735745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_760302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_850520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_845300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_849331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_756459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_845366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_755713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 72s 2s/step - loss: 0.2533 - accuracy: 0.9487\n",
      "50/50 [==============================] - 103s 2s/step - loss: 0.3692 - accuracy: 0.9389\n",
      "35/35 [==============================] - 72s 2s/step - loss: 0.9631 - accuracy: 0.8359\n",
      "Epoch1000 \n",
      " test_indoor_acc=0.9487179517745972 \n",
      " test_outdoor_acc=0.9388535022735596 \n",
      " test_belt_acc=0.8359020948410034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_924301) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_925946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1009864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_977924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_924077) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_929257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_927638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_922385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_927190) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_922792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_926750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_927730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1001932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_927282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_920616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_925024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1014066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1014695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1001372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1006592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_923189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_922609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_997562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1018290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_921008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_922120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_925498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1015796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1005615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_919960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_999595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_927954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_929206) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1021819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1022255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1017617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1016839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1012615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1013829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_927414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_998751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1007436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_927506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_999965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_921629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1000572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1018053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_928809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_926526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1014629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1018831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_923288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1010424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_928402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_990824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1000809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_926618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_996094) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_925182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1008584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1020481) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_928086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_923721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_925630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_926966) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1019504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_926170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1004360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_997821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1008650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_929033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1000202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1005985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_920344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_925233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1016403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1020718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_929074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1005055) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_920170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1010965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1015625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_926577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1012245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1008043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_923945) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1020111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_929298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_929690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_924749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_999358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_928534) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1001179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_922344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1004426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_924128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1011638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_928982) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_923904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_922293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_920385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_996265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_927058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1021325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_920011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_924576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1013222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_920517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_927241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1012008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_922568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_929863) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_924800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1018660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1001998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1011572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_925681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1010358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_928137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1003753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_922965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_923497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_929507) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_923680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_924169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_997192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1003819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1002539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_927017) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1013393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_924525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_924841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_920733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1002368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_921952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_921049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_929639) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_999529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_926849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_928178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1009191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1006156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1007199) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1005549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_921456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1002975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1012786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1014436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1003582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1017683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_927862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_920575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1007806) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1011401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_920957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_922069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1006763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_925065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1019267) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1016232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_997755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1011031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_921232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1018897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_920784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_924352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1007977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_926353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_921853) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_927913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_982961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_925905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_924973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_997126) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_929466) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_998922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_924393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_921181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_921405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1015018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1009020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1006222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1019874) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_996738) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_923057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_900243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_921911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_996672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_925274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_995839) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_928310) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_920211) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1006829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1021885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1007370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1002605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1001438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1004796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_921721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_920825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1019438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_998381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_928585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_998315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_920052) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_923456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_923247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1022862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1021259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_928758) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1009627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1018224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_922161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_928626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1004989) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1020652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_922517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_923016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_927689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_924617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_926808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1012852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1010794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_923405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1003212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_925457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1000136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_926078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1003146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_921273) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1005378) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1013459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1000743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1021088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1021648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_925406) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1017010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1017076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1009257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1015255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_929415) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_928361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1010187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_996331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1015862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1014000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_921497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1012179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_921680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_928850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_923853) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1009798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_998988) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1004189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1022426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_929731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_998144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_922833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_926129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_922741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1022492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1017446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_926394) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_926302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_925722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1001761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1015189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_923629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1020045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_925854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_927465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1008413) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1016469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 62s 2s/step - loss: 0.2692 - accuracy: 0.9487\n",
      "50/50 [==============================] - 103s 2s/step - loss: 0.3662 - accuracy: 0.9427\n",
      "35/35 [==============================] - 72s 2s/step - loss: 0.9921 - accuracy: 0.8377\n",
      "Epoch1200 \n",
      " test_indoor_acc=0.9487179517745972 \n",
      " test_outdoor_acc=0.9426751732826233 \n",
      " test_belt_acc=0.8377153277397156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1177113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1090668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1089904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1177957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1168080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1091248) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1089298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1088443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1180123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1182551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1160763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1089247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1164463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1089023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1088219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1085323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1180901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1166496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1090220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1170483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1085954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1185757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1183765) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1084458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1093755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1168924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1174922) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1085231) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1181508) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1176677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1172911) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1185586) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1093796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1161170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1085455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1162319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1178934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1086409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1174296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1086567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1093032) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1165936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1087290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1174125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1087239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1091912) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1092676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1085073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1093307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1165241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1089563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1084842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1090179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1179753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1093256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1161624) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1090128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1180294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1092136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1094005) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1167710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1183395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1155322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1086219) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1186924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1167103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1091464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1181944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1162253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1173689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1087015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1168687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1093964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1094229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1087107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1093531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1176743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1161236) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1165070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1173148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1177350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1175292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1084509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1092411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1085114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1164093) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1179516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1162642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1186990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1088850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1090576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1089731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1091024) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1086178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1185216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1092859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1089115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1092004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1186146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1184543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1182788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1085015) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1086659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1173082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1092900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1084709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1088891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1166430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1084550) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1184002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1186317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1170113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1089074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1087331) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1088351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1092228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1186383) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1178498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1160337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1090892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1089772) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1085730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1087745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1089339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1086842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1094188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1171934) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1088402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1166866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1166259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1088127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1176136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1163420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1176506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1165870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1142422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1093083) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1091306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1088178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1171090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1171261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1184609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1167644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1181574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1085903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1171327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1172475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1182181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1092808) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1086883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1164634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1163249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1091780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1089471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1170654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1084883) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1085282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1164027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1092635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1091116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1094137) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1170720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1172304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1173755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1170047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1175463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1164700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1092187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1182722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1160829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1086618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1177720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1088799) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1090352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1091556) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1090403) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1183329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1183936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1089955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1186753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1087786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1167473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1085506) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1147459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1088667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1187360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1178327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1177891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1092360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1173518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1092584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1165307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1174856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1084668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1091963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1169487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1086450) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1089996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1182115) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1091347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1162879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1089522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1091515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1088575) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1180360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1090444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1089680) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1178564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1093348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1163856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1180967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1171868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1093913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1176070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1087954) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1162060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1165677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1161690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1179193) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1181337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1064741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1175529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1179127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1086351) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1169553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1090800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1093704) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1093572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1090627) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1093124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1174685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1087514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1093480) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1174362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1087903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1175899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1085679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1163486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1087066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1183158) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1090851) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1091688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1177284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1169876) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1160592) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1168317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1094361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1168858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1087555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1162813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1085995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1091739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1086791) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1087687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1087463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1087995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1172541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1091075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1085771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1168251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1179687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1086127) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1167037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1085547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1169294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1171697) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1092452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1184979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1180730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1184372) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1088626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1185150) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1185823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 63s 2s/step - loss: 0.2769 - accuracy: 0.9459\n",
      "50/50 [==============================] - 104s 2s/step - loss: 0.3817 - accuracy: 0.9408\n",
      "35/35 [==============================] - 72s 2s/step - loss: 1.0170 - accuracy: 0.8336\n",
      "Epoch1400 \n",
      " test_indoor_acc=0.9459308981895447 \n",
      " test_outdoor_acc=0.940764307975769 \n",
      " test_belt_acc=0.8336355686187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1251289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1257622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1251340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1255522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1257581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1258859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1344621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1340397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1338253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1254850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1257846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1258503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1252717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1332208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1342825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1255614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1325734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1255166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1254942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1256950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1347893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1254453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1249207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1330434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1250948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1342389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1255845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1335152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1330994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1329739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1254626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1343062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1344014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1257978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1249048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1255746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1337646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1253124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1250177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1253297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1334611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1329198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1341611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1306920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1339420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1340568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1252284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1257357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1333185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1337409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1251605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1257082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1256186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1258462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1254677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1337580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1343691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1328525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1341004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1257306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1327747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1343432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1324835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1249007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1249571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1332815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1342996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1329132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1327377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1255804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1351488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1351251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1349107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1258727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1248956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1249729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1253613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1334051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1254402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1328354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1331971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1326188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1327311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1330368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1329805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1249166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1326122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1342218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1348500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1250452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1253796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1254061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1339183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1338860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1249340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1342455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1229239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1253348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1256685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1255298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1256461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1252493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1250676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1341175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1249953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1250269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1254178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1256909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1251788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1325261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1249381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1252243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1252941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1348263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1257133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1328961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1257754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1252452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1351858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1254718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1255074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1251829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1252185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1332578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1250849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1340634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1350881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1335588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1327918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1255390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1258029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1326751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1345399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1330757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1249612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1336195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1343625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1257398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1347286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1251513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1330928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1253572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1350321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1257805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1252849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1252676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1349477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1349041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1258411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1256410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1257174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1338016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1250717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1249821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1335759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1253389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1334981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1255125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1344185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1256237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1252053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1345228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1346613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1346679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1329568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1339354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1350084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1344858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1255573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1328591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1251116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1252012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1258253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1341782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1254020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1256278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1252401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1253837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1345465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1325327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1348434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1338187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1254229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1254901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1336973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1249513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1249780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1336366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1331364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1319820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1337039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1332142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1347220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1250004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1334374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1255962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1347827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1251737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1350644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1251157) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1325090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1253745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1255349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1253165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1335218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1332749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1250228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1253969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1256502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1253521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1257530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1253073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1333985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1256858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1333792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1250493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1336802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1346006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1336432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1330175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1256726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1348870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1351422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1334545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1250907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1350815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1341848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1254270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1327140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1349714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1258070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1338794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1331601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1333356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1258635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1254494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1252900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1325668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1345835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1346442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1339961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1338623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1326558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1327984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1258686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1251564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1347656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1340027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1251961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1347049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1256054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1258294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1335825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1333422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1256634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1350255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1250625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1341241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1250045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1251065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1311957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1339790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1256013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1251381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1250401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1252625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1344251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1349648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1346072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1258202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1326817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1344792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1331535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 71s 2s/step - loss: 0.2646 - accuracy: 0.9515\n",
      "50/50 [==============================] - 105s 2s/step - loss: 0.3892 - accuracy: 0.9424\n",
      "35/35 [==============================] - 73s 2s/step - loss: 1.0242 - accuracy: 0.8377\n",
      "Epoch1600 \n",
      " test_indoor_acc=0.9515050053596497 \n",
      " test_outdoor_acc=0.9423567056655884 \n",
      " test_belt_acc=0.8377153277397156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1510504) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1513975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1421132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1420244) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1416683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1419623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1415563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1509290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1418111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1492416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1505739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1501537) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1423133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1507494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1512761) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1413664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1418676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1421580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1421183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1414899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1496469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1499043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1499716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1491809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1414227) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1421000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1419175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1417439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1418070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1505066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1512154) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1496033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1414011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1509356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1509726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1415174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1490166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1418518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1393737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1489759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1497854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1420112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1512932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1420908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1503852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1508749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1418243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1415347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1415215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1505673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1498483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1418559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1506716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1511111) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1417215) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1422960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1497920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1491875) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1489333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1421356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1419124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1494303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1496640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1514819) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1502078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1505132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1421224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1515986) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1504459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1413879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1491056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1420735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1504525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1423357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1492482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1414543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1423225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1416011) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1419847) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1421448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1419348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1476455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1510940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1493696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1413505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1421407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1502685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1418467) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1492852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1420511) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1423001) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1490620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1415879) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1416991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1414991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1421804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1500864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1493089) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1499479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1416103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1514582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1494237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1491638) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1501300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1414451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1497683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1415123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1503121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1414675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1417174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1414110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1422028) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1490232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1494866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1415655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1514146) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1495255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1471418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1504895) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1484318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1418019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1511547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1417571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1506953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1508683) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1508512) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1416899) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1416510) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1511718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1510570) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1500086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1491315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1499109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1418951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1417846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1500323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1418294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1494673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1414767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1495862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1420302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1514753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1515920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1498549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1414319) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1506109) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1512391) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1415614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1498872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1422909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1515142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1413546) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1496099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1419216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1491249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1417347) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1420552) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1413838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1506887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1417123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1504288) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1414502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1515749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1508189) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1417663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1421855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1493459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1502514) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1495426) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1422700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1509119) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1493023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1417795) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1503292) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1489825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1497313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1415838) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1495492) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1512325) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1422568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1418992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1419664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1514212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1415405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1421896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1497076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1416286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1509963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1500693) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1422792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1508123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1422476) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1503681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1414950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1421631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1506280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1490686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1416062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1420020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1422344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1507560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1422303) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1492245) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1417398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1489588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1422751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1497247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1502751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1415446) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1502144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1513368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1414069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1501907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1421672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1507930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1418727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1420071) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1419888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1418335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1500257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1499650) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1503918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1414726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1422120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1420959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1506346) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1510333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1500930) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1493630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1419796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1417622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1496706) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1416235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1512998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1418900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1511177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1416782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1420776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1420343) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1420684) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1498290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1501471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1516356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1419399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1414278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1416459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1515379) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1416950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1423184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1509897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1507323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1515313) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1513539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1503358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1422079) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1413454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1416741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1505502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1513605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1494932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1416327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1416551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1417887) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1418768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1413705) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1494066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1422252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1420460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1422527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1419572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1511784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1419440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1415787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 63s 2s/step - loss: 0.2633 - accuracy: 0.9498\n",
      "50/50 [==============================] - 105s 2s/step - loss: 0.4138 - accuracy: 0.9398\n",
      "35/35 [==============================] - 73s 2s/step - loss: 1.0321 - accuracy: 0.8354\n",
      "Epoch1800 \n",
      " test_indoor_acc=0.9498327970504761 \n",
      " test_outdoor_acc=0.9398089051246643 \n",
      " test_belt_acc=0.8354488015174866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1585182) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1580957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1655118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1662352) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1578044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1585681) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1583398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1679251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1675609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1673181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1580336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1678103) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1583057) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1581397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1668179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1676045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1583714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1659430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1676652) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1580560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1584386) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1580285) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1661745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1667183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1656914) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1582609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1580825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1676282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1585233) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1579041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1587458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1578003) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1674224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1665798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1583174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1667619) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1585905) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1667790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1673617) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1581896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1585050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1666405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1665428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1583266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1579265) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1582965) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1658128) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1678473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1585406) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1584841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1659171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1587682) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1578336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1586577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1655747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1661574) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1582069) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1587198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1671821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1676889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1581489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1665362) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1670171) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1584958) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1635916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1587723) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1680854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1667249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1664148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1654257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1578509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1582833) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1653831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1674831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1583673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1679640) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1677259) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1674395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1585854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1655813) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1583225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1673854) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1584345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1582517) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1579672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1580733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1680484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1660967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1582792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1677430) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1661811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1654323) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1583897) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1657521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1674461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1677496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1667856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1583016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1662418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1587249) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1671451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1666576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1670607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1676823) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1585630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1581713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1579000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1583490) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1585009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1670844) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1665191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1578817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1663047) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1579489) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1658735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1578949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1579845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1640953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1669564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1578567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1656373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1672428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1678710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1579448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1577952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1587855) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1665969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1661204) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1666035) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1669023) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1656743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1579224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1578776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1654086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1675675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1584569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1657587) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1672058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1578377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1583449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1659364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1672687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1677866) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1581672) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1586302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1578608) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1670237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1679811) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1586974) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1664214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1670778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1655554) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1580112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1673010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1585498) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1656980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1579903) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1581008) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1581448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1585722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1580377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1657350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1586129) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1582120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1587025) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1585457) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1678644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1678037) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1657957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1662181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1655184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1558235) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1581621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1680418) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1587407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1668350) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1580061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1656307) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1664584) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1659924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1586394) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1584800) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1660597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1578203) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1668416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1671992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1675068) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1584742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1582568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1584518) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1654664) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1671385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1656136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1586801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1581937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1580509) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1586078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1587499) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1586618) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1660531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1679080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1672621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1582161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1584121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1579173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1585274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1586170) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1579944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1673247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1581049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1582293) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1579621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1662788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1679317) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1659990) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1680247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1580784) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1668786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1581181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1582741) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1664755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1584070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1663977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1658564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1581239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1581845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1669393) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1663541) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1663370) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1679877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1663607) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1654730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1668957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1586353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1581280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1586526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1584294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1586842) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1648816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1580601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1578162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1675002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1669630) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1587290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1578725) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1666642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1587631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1583846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1671214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1664821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1582344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1583622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1579397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1658194) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1659753) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1582385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1667012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1661138) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1586750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1675438) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1585946) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1584610) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1673788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1587066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1579713) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1660360) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1658801) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1584162) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1583938) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1662981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1676216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1580153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1670000) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 62s 2s/step - loss: 0.2814 - accuracy: 0.9487\n",
      "50/50 [==============================] - 103s 2s/step - loss: 0.4012 - accuracy: 0.9424\n",
      "35/35 [==============================] - 72s 2s/step - loss: 1.0626 - accuracy: 0.8364\n",
      "Epoch2000 \n",
      " test_indoor_acc=0.9487179517745972 \n",
      " test_outdoor_acc=0.9423567056655884 \n",
      " test_belt_acc=0.8363553881645203\n"
     ]
    }
   ],
   "source": [
    "test_indoor_acc = []\n",
    "test_outdoor_acc = []\n",
    "test_belt_acc = []\n",
    "test_indoor_loss = []\n",
    "test_outdoor_loss = []\n",
    "test_belt_loss = []\n",
    "\n",
    "for lm_idx,plmodel in enumerate(models_paths):\n",
    "    loaded_model=tf.keras.models.load_model(plmodel)\n",
    "    ## -> keep loss / acc in each epoch\n",
    "    #indoor\n",
    "    test_indoor_results = loaded_model.evaluate(test_indoor_ds)\n",
    "    test_indoor_loss.append(test_indoor_results[0]) # append loss\n",
    "    test_indoor_acc.append(test_indoor_results[1]) # append acc\n",
    "    #outdoor\n",
    "    test_outdoor_results = loaded_model.evaluate(test_outdoor_ds)\n",
    "    test_outdoor_loss.append(test_outdoor_results[0]) # append loss\n",
    "    test_outdoor_acc.append(test_outdoor_results[1]) # append acc\n",
    "    #belt\n",
    "    test_belt_results = loaded_model.evaluate(test_belt_ds)\n",
    "    test_belt_loss.append(test_belt_results[0]) # append loss\n",
    "    test_belt_acc.append(test_belt_results[1]) # append acc\n",
    "    # printout\n",
    "    lm_idx_show = (lm_idx+1) * save_model_interval\n",
    "    print(f\"Epoch{lm_idx_show:03d} \\n test_indoor_acc={test_indoor_acc[lm_idx]} \\n test_outdoor_acc={test_outdoor_acc[lm_idx]} \\n test_belt_acc={test_belt_acc[lm_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "test_avg_acc = []\n",
    "for i in range(len(test_indoor_acc)):\n",
    "    tmp_avg = (test_indoor_acc[i] + test_outdoor_acc[i] + test_belt_acc[i]) / 3.0\n",
    "    test_avg_acc.append(tmp_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(200, 2200, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Testing(EvaluationModel) Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss / acc in each epoch graph ploting\n",
    "#EPOCHS = 400\n",
    "import matplotlib.pyplot as plt\n",
    "epochs_range = range(save_model_interval,EPOCHS+save_model_interval,save_model_interval)\n",
    "print(epochs_range)\n",
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, test_indoor_acc, label='IndoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_outdoor_acc, label='OutdoorDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_belt_acc, label='OnConveyorBeltDS Tesing Accuracy')\n",
    "plt.plot(epochs_range, test_avg_acc, label='Average Tesing Accuracy',linewidth=3)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Testing(EvaluationModel) Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max acc -> 0.9105256795883179\n",
      "max index -> 7\n",
      "The [Epoch] of max acc -> 1600\n"
     ]
    }
   ],
   "source": [
    "#Find Max Index and Value\n",
    "print(f\"max acc -> {max(test_avg_acc)}\")\n",
    "max_index = test_avg_acc.index(max(test_avg_acc))\n",
    "print(f\"max index -> {max_index}\")\n",
    "print(f\"The [Epoch] of max acc -> {(max_index+1)*save_model_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1584 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 22))\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, test_indoor_loss, label='IndoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_outdoor_loss, label='OutdoorDS Tesing Loss')\n",
    "plt.plot(epochs_range, test_belt_loss, label='OnConveyorBeltDS Tesing Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Testing(EvaluationModel) Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9448160529136658,\n",
       " 0.9453734755516052,\n",
       " 0.9470456838607788,\n",
       " 0.9509475827217102,\n",
       " 0.9487179517745972,\n",
       " 0.9487179517745972,\n",
       " 0.9459308981895447,\n",
       " 0.9515050053596497,\n",
       " 0.9498327970504761,\n",
       " 0.9487179517745972]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9404458403587341,\n",
       " 0.9394904375076294,\n",
       " 0.940764307975769,\n",
       " 0.941082775592804,\n",
       " 0.9388535022735596,\n",
       " 0.9426751732826233,\n",
       " 0.940764307975769,\n",
       " 0.9423567056655884,\n",
       " 0.9398089051246643,\n",
       " 0.9423567056655884]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8331822156906128,\n",
       " 0.834995448589325,\n",
       " 0.8331822156906128,\n",
       " 0.8345421552658081,\n",
       " 0.8359020948410034,\n",
       " 0.8377153277397156,\n",
       " 0.8336355686187744,\n",
       " 0.8377153277397156,\n",
       " 0.8354488015174866,\n",
       " 0.8363553881645203]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23764771223068237,\n",
       " 0.2537245452404022,\n",
       " 0.2564055919647217,\n",
       " 0.2569805383682251,\n",
       " 0.2533060312271118,\n",
       " 0.2692112624645233,\n",
       " 0.2769225537776947,\n",
       " 0.2645891010761261,\n",
       " 0.26325055956840515,\n",
       " 0.2813616991043091]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28227707743644714,\n",
       " 0.3154850900173187,\n",
       " 0.3302208483219147,\n",
       " 0.3278005123138428,\n",
       " 0.3692135810852051,\n",
       " 0.36615490913391113,\n",
       " 0.38172075152397156,\n",
       " 0.3892059028148651,\n",
       " 0.4138079881668091,\n",
       " 0.40117618441581726]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outdoor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8432019948959351,\n",
       " 0.898787796497345,\n",
       " 0.9293904304504395,\n",
       " 0.9474848508834839,\n",
       " 0.9631191492080688,\n",
       " 0.9920915365219116,\n",
       " 1.0169670581817627,\n",
       " 1.0242289304733276,\n",
       " 1.0321036577224731,\n",
       " 1.062603235244751]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_belt_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Last Epoch and test in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del dataset memory and reload\n",
    "# RAM\n",
    "del train_ds\n",
    "del val_ds\n",
    "del test_indoor_ds\n",
    "del test_outdoor_ds\n",
    "del test_belt_ds\n",
    "# VRAM\n",
    "#from numba import cuda\n",
    "#cuda.select_device(0)\n",
    "#cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1251289) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1257622) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1251340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1255522) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1257581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1258859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1344621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1340397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1338253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1254850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1257846) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1258503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1252717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1332208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_expand_activation_layer_call_and_return_conditional_losses_1342825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1255614) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1325734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1255166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1254942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1256950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1347893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1254453) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_1249207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1330434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_1250948) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1342389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1255845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1335152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1330994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1329739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_1254626) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_se_reduce_layer_call_and_return_conditional_losses_1343062) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1344014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1257978) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1249048) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1255746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1337646) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1253124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1250177) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1253297) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1334611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1329198) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1341611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1306920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1339420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1340568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1252284) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1257357) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1333185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1337409) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_se_reduce_layer_call_and_return_conditional_losses_1251605) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1257082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_1256186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1258462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_1254677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1337580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_1343691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1328525) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_expand_activation_layer_call_and_return_conditional_losses_1341004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1257306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1327747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_1343432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1324835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1249007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1249571) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1332815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1342996) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1329132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1327377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1255804) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1351488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1351251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_se_reduce_layer_call_and_return_conditional_losses_1349107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_se_reduce_layer_call_and_return_conditional_losses_1258727) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1248956) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1249729) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_se_reduce_layer_call_and_return_conditional_losses_1253613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_1334051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1254402) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_expand_activation_layer_call_and_return_conditional_losses_1328354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1331971) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1326188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1327311) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1330368) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1329805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1249166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1326122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1342218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_se_reduce_layer_call_and_return_conditional_losses_1348500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_activation_layer_call_and_return_conditional_losses_1250452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1253796) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1254061) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1339183) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_1338860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_activation_layer_call_and_return_conditional_losses_1249340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1342455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1229239) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1253348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1256685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_expand_activation_layer_call_and_return_conditional_losses_1255298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1256461) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_1252493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_activation_layer_call_and_return_conditional_losses_1250676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1341175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_1249953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1250269) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_1254178) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1256909) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1251788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_1325261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1c_se_reduce_layer_call_and_return_conditional_losses_1249381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1252243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1252941) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1348263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1257133) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1328961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1257754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1252452) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_1351858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1254718) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_expand_activation_layer_call_and_return_conditional_losses_1255074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_se_reduce_layer_call_and_return_conditional_losses_1251829) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1252185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1332578) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1250849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_1340634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_1350881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1335588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1327918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_se_reduce_layer_call_and_return_conditional_losses_1255390) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1258029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_1326751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_1345399) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1330757) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1249612) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1336195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_1343625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_se_reduce_layer_call_and_return_conditional_losses_1257398) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1347286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_expand_activation_layer_call_and_return_conditional_losses_1251513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1330928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_activation_layer_call_and_return_conditional_losses_1253572) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1350321) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1257805) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_1252849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_1252676) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_expand_activation_layer_call_and_return_conditional_losses_1349477) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_activation_layer_call_and_return_conditional_losses_1349041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1258411) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1256410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_se_reduce_layer_call_and_return_conditional_losses_1257174) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1338016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_se_reduce_layer_call_and_return_conditional_losses_1250717) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_1249821) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1335759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1253389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1334981) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1255125) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1344185) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1256237) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1252053) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_1345228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_activation_layer_call_and_return_conditional_losses_1346613) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_se_reduce_layer_call_and_return_conditional_losses_1346679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1329568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1339354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1350084) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1344858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5h_activation_layer_call_and_return_conditional_losses_1255573) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_se_reduce_layer_call_and_return_conditional_losses_1328591) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_1251116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1252012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1258253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_activation_layer_call_and_return_conditional_losses_1341782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1254020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_1256278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1252401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_se_reduce_layer_call_and_return_conditional_losses_1253837) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1345465) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_1325327) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_activation_layer_call_and_return_conditional_losses_1348434) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_activation_layer_call_and_return_conditional_losses_1338187) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_1254229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_activation_layer_call_and_return_conditional_losses_1254901) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_activation_layer_call_and_return_conditional_losses_1336973) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1249513) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_1249780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_activation_layer_call_and_return_conditional_losses_1336366) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_1331364) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_1319820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_se_reduce_layer_call_and_return_conditional_losses_1337039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1332142) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_activation_layer_call_and_return_conditional_losses_1347220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_1250004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_1334374) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_1255962) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_activation_layer_call_and_return_conditional_losses_1347827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_expand_activation_layer_call_and_return_conditional_losses_1251737) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_1350644) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_1251157) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_1325090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4h_expand_activation_layer_call_and_return_conditional_losses_1253745) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5g_activation_layer_call_and_return_conditional_losses_1255349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1253165) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_1335218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3e_activation_layer_call_and_return_conditional_losses_1332749) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2d_activation_layer_call_and_return_conditional_losses_1250228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1253969) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_1256502) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4g_expand_activation_layer_call_and_return_conditional_losses_1253521) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6i_expand_activation_layer_call_and_return_conditional_losses_1257530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_expand_activation_layer_call_and_return_conditional_losses_1253073) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_1333985) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1256858) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_1333792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_se_reduce_layer_call_and_return_conditional_losses_1250493) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4f_expand_activation_layer_call_and_return_conditional_losses_1336802) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_1346006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4e_se_reduce_layer_call_and_return_conditional_losses_1336432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_1330175) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1256726) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6j_expand_activation_layer_call_and_return_conditional_losses_1348870) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1351422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_1334545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_1250907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_1350815) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5f_se_reduce_layer_call_and_return_conditional_losses_1341848) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_1254270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_1327140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1349714) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_se_reduce_layer_call_and_return_conditional_losses_1258070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_1338794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1331601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_activation_layer_call_and_return_conditional_losses_1333356) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_expand_activation_layer_call_and_return_conditional_losses_1258635) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1254494) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_1252900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_1325668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1345835) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6f_expand_activation_layer_call_and_return_conditional_losses_1346442) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_1339961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_1338623) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_1326558) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1327984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7c_activation_layer_call_and_return_conditional_losses_1258686) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3d_activation_layer_call_and_return_conditional_losses_1251564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6h_expand_activation_layer_call_and_return_conditional_losses_1347656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_1340027) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_expand_activation_layer_call_and_return_conditional_losses_1251961) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6g_expand_activation_layer_call_and_return_conditional_losses_1347049) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1256054) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_1258294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_1335825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3f_se_reduce_layer_call_and_return_conditional_losses_1333422) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_1256634) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_1350255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2f_expand_activation_layer_call_and_return_conditional_losses_1250625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5e_se_reduce_layer_call_and_return_conditional_losses_1341241) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_1250045) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_1251065) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_1_layer_call_and_return_conditional_losses_1311957) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_1339790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_1256013) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_1251381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2e_expand_activation_layer_call_and_return_conditional_losses_1250401) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_1252625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_1344251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6k_activation_layer_call_and_return_conditional_losses_1349648) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_1346072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_1258202) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_1326817) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_1344792) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_1331535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1794 files belonging to 4 classes.\n",
      "Found 3140 files belonging to 4 classes.\n",
      "Found 2206 files belonging to 4 classes.\n",
      "train_indoor num x,y : 1794,1794 are predicting\n",
      "train_outdoor num x,y : 3140,3140 are predicting\n",
      "train_belt num x,y : 2206,2206 are predicting\n",
      "all num x,y :7140,7140\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "last_epoch_model = tf.keras.models.load_model(path_to_model+'OurOutputLayer_DeepDense-NoClassImbalanced-NoAug-epoch1600.pb')\n",
    "\n",
    "test_indoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/indoor'\n",
    "test_outdoor_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/outdoor'\n",
    "test_belt_dataset_path='D:/DatasetMedicalWaste_4Groups/DatasetMedicalWasteTestLabeledCropped/belt'\n",
    "\n",
    "img_height=528\n",
    "img_width=528\n",
    "batch_size=2\n",
    "\n",
    "test_indoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_indoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_outdoor_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_outdoor_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test_belt_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_belt_dataset_path,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "  layers.RandomZoom(height_factor=0.1),\n",
    "  layers.RandomContrast(0.05),\n",
    "])\n",
    "\n",
    "#Apply the preprocessing layers to your dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#train_ds = train_ds.cache().shuffle(2000).prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Normalize by 255 all datasets.\n",
    "  #ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(2000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  #ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_indoor_ds = prepare(test_indoor_ds)\n",
    "test_outdoor_ds = prepare(test_outdoor_ds)\n",
    "test_belt_ds = prepare(test_belt_ds)\n",
    "\n",
    "class_names = ['1-InfectionWaste', '2-BloodSecretionWaste', '3-LabWardWaste', '4-VaccineOtherWaste']\n",
    "\n",
    "N = 400\n",
    "\n",
    "x_test_indoor = np.concatenate([ x for x,y in test_indoor_ds],axis=0)\n",
    "y_test_indoor = np.concatenate([ y for x,y in test_indoor_ds],axis=0)\n",
    "print(f\"train_indoor num x,y : {len(x_test_indoor)},{len(y_test_indoor)} are predicting\")\n",
    "x_indoor_sets = np.array_split(x_test_indoor, N)\n",
    "del x_test_indoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_indoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_indoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_indoor_sets,test_indoor_ds\n",
    "\n",
    "x_test_outdoor = np.concatenate([ x for x,y in test_outdoor_ds],axis=0)\n",
    "y_test_outdoor = np.concatenate([ y for x,y in test_outdoor_ds],axis=0)\n",
    "print(f\"train_outdoor num x,y : {len(x_test_outdoor)},{len(y_test_outdoor)} are predicting\")\n",
    "x_outdoor_sets = np.array_split(x_test_outdoor, N)\n",
    "del x_test_outdoor\n",
    "y_all_sets_predicted = []\n",
    "for x in x_outdoor_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_outdoor_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_outdoor_sets,test_outdoor_ds\n",
    "\n",
    "x_test_belt = np.concatenate([ x for x,y in test_belt_ds],axis=0)\n",
    "y_test_belt = np.concatenate([ y for x,y in test_belt_ds],axis=0)\n",
    "print(f\"train_belt num x,y : {len(x_test_belt)},{len(y_test_belt)} are predicting\")\n",
    "x_belt_sets = np.array_split(x_test_belt, N)\n",
    "del x_test_belt\n",
    "y_all_sets_predicted = []\n",
    "for x in x_belt_sets:\n",
    "  y_all_sets_predicted.append(last_epoch_model.predict(x,batch_size=batch_size))\n",
    "y_belt_predicted = np.concatenate(y_all_sets_predicted)\n",
    "del x_belt_sets,test_belt_ds\n",
    "\n",
    "y_all = np.concatenate([y_test_indoor,y_test_outdoor,y_test_belt],axis=0)\n",
    "y_all_predicted = np.concatenate([y_indoor_predicted,y_outdoor_predicted,y_belt_predicted],axis=0)\n",
    "print(f\"all num x,y :{len(y_all_predicted)},{len(y_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all=7140\n",
      "TP=6514\n",
      "FP=626\n",
      "acc=0.9123249299719888\n",
      "all check = 7140\n"
     ]
    }
   ],
   "source": [
    "y_all_predicted_max = np.array([],dtype=np.int)\n",
    "# acc all\n",
    "TP = 0\n",
    "FP = 0\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP = TP + 1\n",
    "    else :\n",
    "        FP = FP + 1\n",
    "    y_all_predicted_max=np.append(y_all_predicted_max,np.argmax(y_all_predicted[i]))\n",
    "print(f'all={TP+FP}')\n",
    "print(f'TP={TP}')\n",
    "print(f'FP={FP}')\n",
    "print(f'acc={TP/(TP+FP)}')\n",
    "\n",
    "# acc eachclass\n",
    "TP_eachclass = [0] * 41\n",
    "FP_eachclass = [0] * 41\n",
    "for i in range(len(y_all)):\n",
    "    if(y_all[i]==np.argmax(y_all_predicted[i])):\n",
    "        TP_eachclass[y_all[i]] = TP_eachclass[y_all[i]] + 1\n",
    "    else :\n",
    "        FP_eachclass[y_all[i]] = FP_eachclass[y_all[i]] + 1\n",
    "#recheck\n",
    "print(f'all check = {sum(TP_eachclass)+sum(FP_eachclass)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-InfectionWaste acc = 89.35617860851505%\n",
      "2-BloodSecretionWaste acc = 85.87896253602305%\n",
      "3-LabWardWaste acc = 94.69357249626307%\n",
      "4-VaccineOtherWaste acc = 95.0957496496964%\n",
      "\n",
      "\n",
      "\n",
      "all_avg_eachclass = 91.2561158226244%\n"
     ]
    }
   ],
   "source": [
    "avg_acc_eachclass = []\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]} acc = {TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100}%')\n",
    "    avg_acc_eachclass.append(TP_eachclass[i]/(TP_eachclass[i]+FP_eachclass[i])*100)\n",
    "all_avg_eachclass = sum(avg_acc_eachclass) / len(avg_acc_eachclass)\n",
    "print(f'\\n\\n\\nall_avg_eachclass = {all_avg_eachclass}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1721,  171,   10,   24],\n",
       "       [ 178, 1490,   30,   37],\n",
       "       [  18,   43, 1267,   10],\n",
       "       [   7,   60,   38, 2036]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# for using scikit-learn's built-in metrics\n",
    "from sklearn.metrics import *\n",
    "# for using tesnorflow/keras' built-in metrics\n",
    "import tensorflow.keras.backend as K\n",
    "''' ndarray of shape (n_classes, n_classes)\n",
    "Confusion matrix whose i-th row and j-th column entry indicates the number of samples with  {true label being i-th row class} and {predicted label being column j-th class}.\n",
    "> Example\n",
    ">>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    ">>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    ">>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    "พุดง่ายๆ แถวคือด้านความจริง\n",
    "       หลักคือด้านที่ระบบทำนาย\n",
    "'''\n",
    "# \n",
    "confusionMat = confusion_matrix(y_all, y_all_predicted_max, labels=range(len(class_names)))\n",
    "confusionMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89.35617861,  8.87850467,  0.5192108 ,  1.24610592],\n",
       "       [10.25936599, 85.87896254,  1.72910663,  2.13256484],\n",
       "       [ 1.34529148,  3.21375187, 94.6935725 ,  0.74738416],\n",
       "       [ 0.32695002,  2.80242877,  1.77487156, 95.09574965]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatFloat = confusionMat.astype('float64')\n",
    "confusionMatFloatPercent=confusionMatFloat/confusionMatFloat.sum(axis=1)[:,None]  # divided by number of sample in each class (sum of each row)\n",
    "confusionMatFloatPercent*=100\n",
    "confusionMatFloatPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMat, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (14,14))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusionMatFloatPercent, index = class_names,\n",
    "                  columns = class_names)\n",
    "plt.figure(figsize = (14,14))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt=\".2f\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
